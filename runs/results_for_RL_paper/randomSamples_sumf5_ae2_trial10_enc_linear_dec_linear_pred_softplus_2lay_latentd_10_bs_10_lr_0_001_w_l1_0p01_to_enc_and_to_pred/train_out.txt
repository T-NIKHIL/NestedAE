 --> User provided command line run_dir argument : ../runs/results_for_RL_paper
 --> User provided command line ae argument : 2
 --> Setting global random seed 0.
 --> Running on cpu.
 --> Number of threads : 10
 --> Number of interop threads : 10
 --> PyTorch configurations


 --> Submodule encoder layers :
ModuleList(
  (0): Linear(in_features=12, out_features=10, bias=True)
)


 --> Submodule predictor layers :
ModuleList(
  (0): Linear(in_features=10, out_features=10, bias=True)
  (1): Softplus(beta=5, threshold=20)
)


 --> Submodule predictor_ext layers :
ModuleList(
  (0): Linear(in_features=10, out_features=1, bias=True)
  (1): Softplus(beta=5, threshold=20)
)


 --> Submodule decoder layers :
ModuleList(
  (0): Linear(in_features=10, out_features=12, bias=True)
)
 --> Model Compilation step complete.
┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name       ┃ Type       ┃ Params ┃
┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ submodules │ ModuleDict │    383 │
└───┴────────────┴────────────┴────────┘
Trainable params: 383                                                                       
Non-trainable params: 0                                                                     
Total params: 383                                                                           
Total estimated model params size (MB): 0                                                   
 --> Example Input : 
{'f1tof4_w_ae1_latent': tensor([-0.7824,  0.4173,  0.2019, -0.1245, -1.6541,  0.9229, -0.4490,  0.2310,
        -0.5154, -1.2063, -0.7939,  1.0829]), 'f5': tensor([-1.2556])}


--> Model Trace : 


 ---------------------------------- 
module_name:encoder
input id:['f1tof4_w_ae1_latent']
input to submodule :
tensor([-0.7824,  0.4173,  0.2019, -0.1245, -1.6541,  0.9229, -0.4490,  0.2310,
        -0.5154, -1.2063, -0.7939,  1.0829])
output id:encoder
output from submodule :
tensor([-0.9169,  0.0898,  0.0210,  0.8186, -1.2331, -0.6017, -0.1215,  0.3496,
        -0.3346,  0.4766], grad_fn=<AddBackward0>)
Submodule output dictionary :
{'encoder': tensor([-0.9169,  0.0898,  0.0210,  0.8186, -1.2331, -0.6017, -0.1215,  0.3496,
        -0.3346,  0.4766], grad_fn=<AddBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:predictor
input id:['encoder']
input to submodule :
tensor([-0.9169,  0.0898,  0.0210,  0.8186, -1.2331, -0.6017, -0.1215,  0.3496,
        -0.3346,  0.4766], grad_fn=<CatBackward0>)
output id:predictor
output from submodule :
tensor([1.0886, 0.4109, 1.1000, 0.0814, 0.0102, 0.0779, 0.3463, 0.1703, 0.2959,
        0.3213], grad_fn=<SoftplusBackward0>)
Submodule output dictionary :
{'encoder': tensor([-0.9169,  0.0898,  0.0210,  0.8186, -1.2331, -0.6017, -0.1215,  0.3496,
        -0.3346,  0.4766], grad_fn=<AddBackward0>),
 'predictor': tensor([1.0886, 0.4109, 1.1000, 0.0814, 0.0102, 0.0779, 0.3463, 0.1703, 0.2959,
        0.3213], grad_fn=<SoftplusBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:predictor_ext
input id:['predictor']
input to submodule :
tensor([1.0886, 0.4109, 1.1000, 0.0814, 0.0102, 0.0779, 0.3463, 0.1703, 0.2959,
        0.3213], grad_fn=<CatBackward0>)
output id:predictor_ext
output from submodule :
tensor([0.0038], grad_fn=<SoftplusBackward0>)
Submodule output dictionary :
{'encoder': tensor([-0.9169,  0.0898,  0.0210,  0.8186, -1.2331, -0.6017, -0.1215,  0.3496,
        -0.3346,  0.4766], grad_fn=<AddBackward0>),
 'predictor': tensor([1.0886, 0.4109, 1.1000, 0.0814, 0.0102, 0.0779, 0.3463, 0.1703, 0.2959,
        0.3213], grad_fn=<SoftplusBackward0>),
 'predictor_ext': tensor([0.0038], grad_fn=<SoftplusBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:decoder
input id:['encoder']
input to submodule :
tensor([-0.9169,  0.0898,  0.0210,  0.8186, -1.2331, -0.6017, -0.1215,  0.3496,
        -0.3346,  0.4766], grad_fn=<CatBackward0>)
output id:decoder
output from submodule :
tensor([-0.6223,  0.3492, -0.2535,  0.6733, -0.3098, -0.1715, -1.7192,  0.0170,
         0.5124, -0.6461, -0.7045,  0.5535], grad_fn=<AddBackward0>)
Submodule output dictionary :
{'decoder': tensor([-0.6223,  0.3492, -0.2535,  0.6733, -0.3098, -0.1715, -1.7192,  0.0170,
         0.5124, -0.6461, -0.7045,  0.5535], grad_fn=<AddBackward0>),
 'encoder': tensor([-0.9169,  0.0898,  0.0210,  0.8186, -1.2331, -0.6017, -0.1215,  0.3496,
        -0.3346,  0.4766], grad_fn=<AddBackward0>),
 'predictor': tensor([1.0886, 0.4109, 1.1000, 0.0814, 0.0102, 0.0779, 0.3463, 0.1703, 0.2959,
        0.3213], grad_fn=<SoftplusBackward0>),
 'predictor_ext': tensor([0.0038], grad_fn=<SoftplusBackward0>)}
 ---------------------------------- 


