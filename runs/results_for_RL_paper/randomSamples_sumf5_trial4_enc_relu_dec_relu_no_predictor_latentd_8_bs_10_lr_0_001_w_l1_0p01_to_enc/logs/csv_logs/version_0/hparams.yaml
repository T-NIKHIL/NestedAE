nn_datasets_dict:
  train:
    X1:
      header: null
      path: ../datasets/synthetic_dataset/synthetic_data_randomSamples_200_sumf5.csv
      skiprows: 1
      variables:
        f1tof4:
          cols:
          - 8
          - 9
          - 10
          - 11
          preprocess: std
        f5:
          cols:
          - 12
          preprocess: std
        x1tox8:
          cols:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 5
          - 6
          - 7
          preprocess: std
nn_params_dict:
  model_type: randomSamples_sumf5_trial4_enc_relu_dec_relu_no_predictor_latentd_8_bs_10_lr_0_001_w_l1_0p01_to_enc
  submodules:
    decoder:
      connect_to:
      - encoder
      layer_activation:
      - relu
      layer_bias_init:
      - zeros
      layer_kernel_init:
      - kaiming_normal
      layer_kernel_init_gain:
      - 1
      layer_type:
      - linear
      layer_weight_reg:
        l1: 0
        l2: 0
      loss:
        target: x1tox8
        type: mae
        wt: 1
      num_nodes_per_layer:
      - 8
      save_params: true
    encoder:
      connect_to:
      - x1tox8
      layer_activation:
      - relu
      layer_bias_init:
      - zeros
      layer_kernel_init:
      - kaiming_normal
      layer_kernel_init_gain:
      - 1
      layer_type:
      - linear
      layer_weight_reg:
        l1: 0.01
        l2: 0
      num_nodes_per_layer:
      - 8
      save_output_on_fit_end: true
      save_params: true
nn_save_dir: ../runs/results_for_RL_paper/randomSamples_sumf5_trial4_enc_relu_dec_relu_no_predictor_latentd_8_bs_10_lr_0_001_w_l1_0p01_to_enc
nn_train_params_dict:
  batch_size: 10
  callbacks:
    early_stopping:
      min_delta: 1.0e-05
      mode: min
      monitor: total_val_loss
      patience: 200
    model_checkpoint:
      mode: min
      monitor: total_val_loss
      save_top_k: 1
  epochs: 1000
  global_seed: 0
  optimizer:
    lr: 0.001
    type: adam
  shuffle_data_between_epochs: true
  test_split: 0.2
