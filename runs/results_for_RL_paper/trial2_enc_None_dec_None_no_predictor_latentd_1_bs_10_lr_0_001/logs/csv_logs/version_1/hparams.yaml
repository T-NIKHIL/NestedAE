nn_datasets_dict:
  predict:
    X1:
      header: null
      path: ../datasets/synthetic_dataset/synthetic_data_gridSamples_200_sumf5.csv
      skiprows: 1
      variables:
        f1tof4:
          cols:
          - 8
          - 9
          - 10
          - 11
          preprocess: std
        f5:
          cols:
          - 12
          preprocess: std
        x1tox8:
          cols:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 5
          - 6
          - 7
          preprocess: std
  train:
    X1:
      header: null
      path: ../datasets/synthetic_dataset/synthetic_data_gridSamples_200_sumf5.csv
      skiprows: 1
      variables:
        f1tof4:
          cols:
          - 8
          - 9
          - 10
          - 11
          preprocess: std
        f5:
          cols:
          - 12
          preprocess: std
        x1tox8:
          cols:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 5
          - 6
          - 7
          preprocess: std
nn_params_dict:
  model_type: trial2_enc_None_dec_None_no_predictor_latentd_1_bs_10_lr_0_001
  submodules:
    decoder:
      connect_to:
      - encoder
      layer_activation:
      - null
      layer_bias_init:
      - zeros
      layer_kernel_init:
      - xavier_normal
      layer_kernel_init_gain:
      - 1
      layer_type:
      - linear
      layer_weight_reg:
        l1: 0
        l2: 0.0001
      loss:
        target: x1tox8
        type: mae
        wt: 1
      num_nodes_per_layer:
      - 8
      save_params: true
    encoder:
      connect_to:
      - x1tox8
      layer_activation:
      - null
      layer_bias_init:
      - zeros
      layer_kernel_init:
      - xavier_normal
      layer_kernel_init_gain:
      - 1
      layer_type:
      - linear
      layer_weight_reg:
        l1: 0
        l2: 0.0001
      num_nodes_per_layer:
      - 1
      save_output_on_fit_end: true
      save_params: true
nn_save_dir: ../runs/results_for_RL_paper/trial2_enc_None_dec_None_no_predictor_latentd_1_bs_10_lr_0_001
nn_train_params_dict:
  batch_size: 10
  callbacks:
    model_checkpoint:
      mode: min
      monitor: total_val_loss
      save_top_k: 1
  epochs: 500
  global_seed: 0
  optimizer:
    lr: 0.001
    type: adam
  shuffle_data_between_epochs: true
  test_split: 0.2
