 --> User provided command line run_dir argument : ../runs/perovskite_multiscale_dataset_3
 --> User provided command line ae argument : 2
 --> Setting global random seed 0.
 --> Running on cpu.
 --> Number of threads : 10
 --> Number of interop threads : 10
 --> PyTorch configurations


 --> Submodule encoder layers :
ModuleList(
  (0): Linear(in_features=23, out_features=2, bias=True)
  (1): Tanh()
)


 --> Submodule PCE_pred layers :
ModuleList(
  (0): Linear(in_features=2, out_features=100, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.1, inplace=False)
  (3): Linear(in_features=100, out_features=1, bias=True)
  (4): ReLU()
)


 --> Submodule latents_pred layers :
ModuleList(
  (0): Linear(in_features=2, out_features=12, bias=True)
)


 --> Submodule etm_pred layers :
ModuleList(
  (0): Linear(in_features=2, out_features=7, bias=True)
)


 --> Submodule htm_pred layers :
ModuleList(
  (0): Linear(in_features=2, out_features=4, bias=True)
)
 --> Model Compilation step complete.
┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name       ┃ Type       ┃ Params ┃
┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ submodules │ ModuleDict │    518 │
└───┴────────────┴────────────┴────────┘
Trainable params: 518                                                                                                                                                            
Non-trainable params: 0                                                                                                                                                          
Total params: 518                                                                                                                                                                
Total estimated model params size (MB): 0                                                                                                                                        
 --> Example Input : 
{'etm': tensor([0., 0., 0., 0., 0., 1., 0.]), 'htm': tensor([0., 0., 0., 1.]), 'PCE': tensor([13.3000]), 'latents': tensor([ 0.2329,  0.1746, -0.2738, -0.6384, -0.6832,  0.6089, -0.1625, -0.8064,
        -0.5583,  0.5516, -0.0570,  0.5469])}


--> Model Trace : 


 ---------------------------------- 
module_name:encoder
input id:['latents', 'etm', 'htm']
input to submodule :
tensor([ 0.2329,  0.1746, -0.2738, -0.6384, -0.6832,  0.6089, -0.1625, -0.8064,
        -0.5583,  0.5516, -0.0570,  0.5469,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000])
output id:encoder
output from submodule :
tensor([0.6310, 0.1617], grad_fn=<TanhBackward0>)
Submodule output dictionary :
{'encoder': tensor([0.6310, 0.1617], grad_fn=<TanhBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:PCE_pred
input id:['encoder']
input to submodule :
tensor([0.6310, 0.1617], grad_fn=<CatBackward0>)
output id:PCE_pred
output from submodule :
tensor([0.], grad_fn=<ReluBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([0.6310, 0.1617], grad_fn=<TanhBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:latents_pred
input id:['encoder']
input to submodule :
tensor([0.6310, 0.1617], grad_fn=<CatBackward0>)
output id:latents_pred
output from submodule :
tensor([ 0.1655,  0.0718,  0.5186,  0.2198, -0.3088, -0.1574, -0.0244,  0.0933,
        -0.4625, -0.1866, -0.1637,  0.0299], grad_fn=<ViewBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([0.6310, 0.1617], grad_fn=<TanhBackward0>),
 'latents_pred': tensor([ 0.1655,  0.0718,  0.5186,  0.2198, -0.3088, -0.1574, -0.0244,  0.0933,
        -0.4625, -0.1866, -0.1637,  0.0299], grad_fn=<ViewBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:etm_pred
input id:['encoder']
input to submodule :
tensor([0.6310, 0.1617], grad_fn=<CatBackward0>)
output id:etm_pred
output from submodule :
tensor([ 0.1916, -0.1596, -0.3963, -0.1134, -0.2750,  0.3539,  0.0476],
       grad_fn=<ViewBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([0.6310, 0.1617], grad_fn=<TanhBackward0>),
 'etm_pred': tensor([ 0.1916, -0.1596, -0.3963, -0.1134, -0.2750,  0.3539,  0.0476],
       grad_fn=<ViewBackward0>),
 'latents_pred': tensor([ 0.1655,  0.0718,  0.5186,  0.2198, -0.3088, -0.1574, -0.0244,  0.0933,
        -0.4625, -0.1866, -0.1637,  0.0299], grad_fn=<ViewBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:htm_pred
input id:['encoder']
input to submodule :
tensor([0.6310, 0.1617], grad_fn=<CatBackward0>)
output id:htm_pred
output from submodule :
tensor([ 0.2372, -1.1237, -0.2575, -0.1482], grad_fn=<ViewBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([0.6310, 0.1617], grad_fn=<TanhBackward0>),
 'etm_pred': tensor([ 0.1916, -0.1596, -0.3963, -0.1134, -0.2750,  0.3539,  0.0476],
       grad_fn=<ViewBackward0>),
 'htm_pred': tensor([ 0.2372, -1.1237, -0.2575, -0.1482], grad_fn=<ViewBackward0>),
 'latents_pred': tensor([ 0.1655,  0.0718,  0.5186,  0.2198, -0.3088, -0.1574, -0.0244,  0.0933,
        -0.4625, -0.1866, -0.1637,  0.0299], grad_fn=<ViewBackward0>)}
 ---------------------------------- 


