 --> User provided command line run_dir argument : ../runs/perovskite_multiscale_dataset_3
 --> User provided command line ae argument : 2
 --> Setting global random seed 0.
 --> Running on cpu.
 --> Number of threads : 10
 --> Number of interop threads : 10
 --> PyTorch configurations


 --> Submodule encoder layers :
ModuleList(
  (0): Linear(in_features=23, out_features=18, bias=True)
  (1): Tanh()
)


 --> Submodule PCE_pred layers :
ModuleList(
  (0): Linear(in_features=18, out_features=100, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.1, inplace=False)
  (3): Linear(in_features=100, out_features=1, bias=True)
  (4): ReLU()
)


 --> Submodule latents_pred layers :
ModuleList(
  (0): Linear(in_features=18, out_features=12, bias=True)
)


 --> Submodule etm_pred layers :
ModuleList(
  (0): Linear(in_features=18, out_features=7, bias=True)
)


 --> Submodule htm_pred layers :
ModuleList(
  (0): Linear(in_features=18, out_features=4, bias=True)
)
 --> Model Compilation step complete.
┏━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name       ┃ Type       ┃ Params ┃
┡━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ submodules │ ModuleDict │  2.9 K │
└───┴────────────┴────────────┴────────┘
Trainable params: 2.9 K                                                                                                                                                          
Non-trainable params: 0                                                                                                                                                          
Total params: 2.9 K                                                                                                                                                              
Total estimated model params size (MB): 0                                                                                                                                        
 --> Example Input : 
{'etm': tensor([0., 0., 0., 0., 0., 1., 0.]), 'htm': tensor([0., 0., 0., 1.]), 'PCE': tensor([13.3000]), 'latents': tensor([ 0.2329,  0.1746, -0.2738, -0.6384, -0.6832,  0.6089, -0.1625, -0.8064,
        -0.5583,  0.5516, -0.0570,  0.5469])}


--> Model Trace : 


 ---------------------------------- 
module_name:encoder
input id:['latents', 'etm', 'htm']
input to submodule :
tensor([ 0.2329,  0.1746, -0.2738, -0.6384, -0.6832,  0.6089, -0.1625, -0.8064,
        -0.5583,  0.5516, -0.0570,  0.5469,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000])
output id:encoder
output from submodule :
tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<TanhBackward0>)
Submodule output dictionary :
{'encoder': tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<TanhBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:PCE_pred
input id:['encoder']
input to submodule :
tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<CatBackward0>)
output id:PCE_pred
output from submodule :
tensor([0.], grad_fn=<ReluBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<TanhBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:latents_pred
input id:['encoder']
input to submodule :
tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<CatBackward0>)
output id:latents_pred
output from submodule :
tensor([-0.4255, -1.5493, -0.3892, -0.3693, -1.2913,  0.0279, -0.0700,  0.2635,
        -0.0244,  0.0787, -0.0923,  1.2721], grad_fn=<ViewBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<TanhBackward0>),
 'latents_pred': tensor([-0.4255, -1.5493, -0.3892, -0.3693, -1.2913,  0.0279, -0.0700,  0.2635,
        -0.0244,  0.0787, -0.0923,  1.2721], grad_fn=<ViewBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:etm_pred
input id:['encoder']
input to submodule :
tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<CatBackward0>)
output id:etm_pred
output from submodule :
tensor([ 1.0103, -1.0115,  0.5987,  0.6866, -0.6138,  0.8470,  0.1906],
       grad_fn=<ViewBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<TanhBackward0>),
 'etm_pred': tensor([ 1.0103, -1.0115,  0.5987,  0.6866, -0.6138,  0.8470,  0.1906],
       grad_fn=<ViewBackward0>),
 'latents_pred': tensor([-0.4255, -1.5493, -0.3892, -0.3693, -1.2913,  0.0279, -0.0700,  0.2635,
        -0.0244,  0.0787, -0.0923,  1.2721], grad_fn=<ViewBackward0>)}
 ---------------------------------- 




 ---------------------------------- 
module_name:htm_pred
input id:['encoder']
input to submodule :
tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<CatBackward0>)
output id:htm_pred
output from submodule :
tensor([-0.4414,  0.5921,  0.6713, -0.3789], grad_fn=<ViewBackward0>)
Submodule output dictionary :
{'PCE_pred': tensor([0.], grad_fn=<ReluBackward0>),
 'encoder': tensor([-0.1898, -0.7376, -0.4997,  0.4798,  0.4208, -0.2000, -0.7645,  0.5414,
        -0.1839, -0.2432,  0.1003, -0.5111, -0.6915, -0.0596,  0.6274,  0.4181,
         0.2208, -0.7055], grad_fn=<TanhBackward0>),
 'etm_pred': tensor([ 1.0103, -1.0115,  0.5987,  0.6866, -0.6138,  0.8470,  0.1906],
       grad_fn=<ViewBackward0>),
 'htm_pred': tensor([-0.4414,  0.5921,  0.6713, -0.3789], grad_fn=<ViewBackward0>),
 'latents_pred': tensor([-0.4255, -1.5493, -0.3892, -0.3693, -1.2913,  0.0279, -0.0700,  0.2635,
        -0.0244,  0.0787, -0.0923,  1.2721], grad_fn=<ViewBackward0>)}
 ---------------------------------- 


