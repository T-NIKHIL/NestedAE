{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fc96aa-67d8-4aca-8ff5-77f162088b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "# Login to wandb. Create a wandb account and get the api key from the user settings tab\n",
    "user_name = 'nthota2'\n",
    "project_name = 'perovskite_dataset_v2'\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = 'generative_models.ipynb'\n",
    "os.environ[\"WANDB_API_KEY\"] = \"2ebe7f940d7b84cdc3be6588851e30d5c34d201d\"\n",
    "# dryrun = Does not store any weights and bias data locally\n",
    "# online = enables cloud syncing\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "\n",
    "seed = 10\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5a329",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ccd275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(2245, 1)\n",
      "(2245, 1)\n",
      "(2245, 1)\n",
      "(2245, 4)\n",
      "OHE Categories : [array(['DMF', 'DMF; DMSO', 'DMSO', 'DMSO; GBL', 'GBL'], dtype=object)]\n",
      "X1_final shape : (2245, 5)\n",
      "OHE Categories : [array(['1', '3; 7', '4; 1', '7; 3', '9; 1'], dtype=object)]\n",
      "X2_final shape : (2245, 5)\n",
      "OHE Categories : [array(['Chlorobenzene', 'Diethyl ether', 'Ethyl acetate', 'Toluene',\n",
      "       'Unknown'], dtype=object)]\n",
      "X3_final shape : (2245, 5)\n",
      "X4 Scaling done accurately ? : True\n",
      "X4_final shape : (2245, 4)\n",
      "2245\n"
     ]
    }
   ],
   "source": [
    "## ------------------------ USER INPUT START ------------------------\n",
    "\n",
    "dataset1_to_train = 'PSC_eff_v2'\n",
    "dataset2_to_train = 'latents_from_SupAE1'\n",
    "\n",
    "# For RL dataset\n",
    "# descriptors = ['z1', 'z2', 'z3', 'z4', \n",
    "#                'z5', 'z6', 'z7', 'z8']\n",
    "# descriptors = ['f1', 'f2', 'f3', 'f4', 'AE1_latent_0']\n",
    "# descriptors = ['f1', 'f2', 'f3', 'f4', \n",
    "#                'AE1_latent_0', 'AE1_latent_1', 'AE1_latent_2', 'AE1_latent_3', \n",
    "#                'AE1_latent_4', 'AE1_latent_5', 'AE1_latent_6', 'AE1_latent_7']\n",
    "# For perovskite dataset v2\n",
    "# descriptors1 = ['A_ion_rad', 'A_at_wt', 'A_EA', 'A_IE', 'A_En',\n",
    "#                 'B_ion_rad', 'B_at_wt', 'B_EA', 'B_IE', 'B_En',\n",
    "#                 'X_ion_rad', 'X_at_wt', 'X_EA', 'X_IE', 'X_En']\n",
    "descriptors1 = ['Perovskite_deposition_solvents'] \n",
    "descriptors2 = ['Perovskite_deposition_solvents_mixing_ratios']\n",
    "descriptors3 = ['Perovskite_deposition_quenching_media']\n",
    "descriptors4 = ['AE1_latent_0', 'AE1_latent_1', 'AE1_latent_2', 'AE1_latent_3']\n",
    "# descriptors2 = ['Cubic', 'Tetra', 'Ortho', 'Hex']\n",
    "\n",
    "standardize1 = False\n",
    "ohe1 = True\n",
    "load_scaler1 = False\n",
    "scaler1_loc = None\n",
    "\n",
    "standardize2 = False\n",
    "ohe2 = True\n",
    "load_scaler2 = False\n",
    "scaler2_loc = None\n",
    "\n",
    "standardize3 = False\n",
    "ohe3 = True\n",
    "load_scaler3 = False\n",
    "scaler3_loc = None\n",
    "\n",
    "standardize4 = True\n",
    "ohe4 = False\n",
    "load_scaler4 = False\n",
    "scaler4_loc = None\n",
    "\n",
    "label = None\n",
    "standardizelabel = False\n",
    "\n",
    "# Dictionary containing paths to datasets\n",
    "dataset_path_dict = {\n",
    "    'gridSamples_200_nonlinf5': '../datasets/synthetic_dataset/synthetic_data_gridSamples_200_with_ae1_latents_concat.csv',\n",
    "    'gridSamples_200_sumf5': '../datasets/synthetic_dataset/synthetic_data_gridSamples_200_sumf5_with_ae1_latents_concat.csv',\n",
    "    'randomSamples_200_nonlinf5': '../datasets/synthetic_dataset/synthetic_data_randomSamples_200_with_ae1_latents_concat.csv',\n",
    "    'randomSamples_200_sumf5': '../datasets/synthetic_dataset/synthetic_data_randomSamples_200_sumf5_with_ae1_latents_concat.csv',\n",
    "    'PSC_bandgaps_v1': '../datasets/PSC_bandgaps/PSC_bandgaps_dataset.csv',\n",
    "    'PSC_eff_v1': '../datasets/PSC_efficiencies/PSC_efficiencies_dataset.csv',\n",
    "    'PSC_eff_v2': '../datasets/PSC_efficiencies/PSC_efficiencies_dataset_2.csv',\n",
    "    'HSE_arun2022': '../datasets/PSC_bandgaps/HSE_data_arun2022.csv',\n",
    "    'HSE_arun2024': '../datasets/PSC_bandgaps/HSE_data_arun2024.csv',\n",
    "    'latents_from_SupAE1':'../runs/perovskite_multiscale_dataset_v2/best_SupSimpleAE_1_ldim4_arun2024/latents_from_PSC_efficiencies_dataset_2.csv',\n",
    "}\n",
    "\n",
    "data1 = pd.read_csv(dataset_path_dict[dataset1_to_train])\n",
    "X1 = pd.DataFrame(data1, columns=descriptors1)\n",
    "# Check if the dataset has any nan values\n",
    "print(X1.isnull().values.any())\n",
    "print(X1.shape)\n",
    "\n",
    "if descriptors2 is not None:\n",
    "    data2 = pd.read_csv(dataset_path_dict[dataset1_to_train])\n",
    "    X2 = pd.DataFrame(data2, columns=descriptors2)\n",
    "    print(X2.shape)\n",
    "\n",
    "if descriptors3 is not None:\n",
    "    data3 = pd.read_csv(dataset_path_dict[dataset1_to_train])\n",
    "    X3 = pd.DataFrame(data3, columns=descriptors3)\n",
    "    print(X3.shape)\n",
    "\n",
    "if descriptors4 is not None:\n",
    "    data4 = pd.read_csv(dataset_path_dict[dataset2_to_train])\n",
    "    X4 = pd.DataFrame(data4, columns=descriptors4)\n",
    "    print(X4.shape)\n",
    "\n",
    "if label:\n",
    "    y_copy = copy.deepcopy(data1[label].to_numpy())\n",
    "    y = y_copy.reshape(-1,1)\n",
    "    print(y.shape)\n",
    "\n",
    "## ------------------------ USER INPUT END ------------------------\n",
    "\n",
    "# Creating a pytorch dataset\n",
    "class XsandYDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, y, X1, X2):\n",
    "        self.y = y\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.y[idx], self.X1[idx], self.X2[idx]\n",
    "\n",
    "class XandYDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, y, X):\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.y[idx], self.X[idx]\n",
    "    \n",
    "class XsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X1, X2, X3, X4):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.X3 = X3\n",
    "        self.X4 = X4\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.X3[idx], self.X4[idx]\n",
    "\n",
    "class XDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "    \n",
    "# Standardize the dataset\n",
    "if standardize1:\n",
    "    if load_scaler1:\n",
    "        scaler_X1 = joblib.load(scaler1_loc)\n",
    "    else:\n",
    "        scaler_X1 = StandardScaler().fit(X1)\n",
    "    X1_scaled_np = scaler_X1.transform(X1)\n",
    "    X1_np = scaler_X1.inverse_transform(X1_scaled_np)\n",
    "    X1_final = X1_scaled_np.astype(np.float32)\n",
    "    print(f'X1 Scaling done accurately ? : {np.allclose(X1_np, X1.to_numpy())}')\n",
    "elif ohe1:\n",
    "    ohe_X1 = OneHotEncoder(sparse_output=False).fit(X1)\n",
    "    X1_final = ohe_X1.transform(X1).astype(np.float32)\n",
    "    # print(ohe_X1.inverse_transform(X1_final))\n",
    "    print(f'OHE Categories : {ohe_X1.categories_}')\n",
    "else:\n",
    "    X1_final = X1.to_numpy().astype(np.float32)\n",
    "print(f'X1_final shape : {X1_final.shape}')\n",
    "\n",
    "if standardize2:\n",
    "    if load_scaler2:\n",
    "        scaler_X2 = joblib.load(scaler2_loc)\n",
    "    else:\n",
    "        scaler_X2 = StandardScaler().fit(X2)\n",
    "    X2_scaled_np = scaler_X2.transform(X2)\n",
    "    X2_np = scaler_X2.inverse_transform(X2_scaled_np)\n",
    "    X2_final = X2_scaled_np.astype(np.float32)\n",
    "    print(f'X2 Scaling done accurately ? : {np.allclose(X2_np, X2.to_numpy())}')\n",
    "elif ohe2:\n",
    "    ohe_X2 = OneHotEncoder(sparse_output=False).fit(X2)\n",
    "    X2_final = ohe_X2.transform(X2).astype(np.float32)\n",
    "    print(f'OHE Categories : {ohe_X2.categories_}')\n",
    "else:\n",
    "    X2_final = X2.to_numpy().astype(np.float32)\n",
    "print(f'X2_final shape : {X2_final.shape}')\n",
    "\n",
    "if standardize3:\n",
    "    if load_scaler3:\n",
    "        scaler_X3 = joblib.load(scaler3_loc)\n",
    "    else:\n",
    "        scaler_X3 = StandardScaler().fit(X3)\n",
    "    X3_scaled_np = scaler_X3.transform(X3)\n",
    "    X3_np = scaler_X3.inverse_transform(X3_scaled_np)\n",
    "    X3_final = X3_scaled_np.astype(np.float32)\n",
    "    print(f'X3 Scaling done accurately ? : {np.allclose(X3_np, X3.to_numpy())}')\n",
    "elif ohe3:\n",
    "    ohe_X3 = OneHotEncoder(sparse_output=False).fit(X3)\n",
    "    X3_final = ohe_X3.transform(X3).astype(np.float32)\n",
    "    print(f'OHE Categories : {ohe_X3.categories_}')\n",
    "else:\n",
    "    X3_final = X3.to_numpy().astype(np.float32)\n",
    "print(f'X3_final shape : {X3_final.shape}')\n",
    "\n",
    "if standardize4:\n",
    "    if load_scaler4:\n",
    "        scaler_X4 = joblib.load(scaler4_loc)\n",
    "    else:\n",
    "        scaler_X4 = StandardScaler().fit(X4)\n",
    "    X4_scaled_np = scaler_X4.transform(X4)\n",
    "    X4_np = scaler_X4.inverse_transform(X4_scaled_np)\n",
    "    X4_final = X4_scaled_np.astype(np.float32)\n",
    "    print(f'X4 Scaling done accurately ? : {np.allclose(X4_np, X4.to_numpy())}')\n",
    "elif ohe4:\n",
    "    ohe_X4 = OneHotEncoder(sparse_output=False).fit(X4)\n",
    "    X4_final = ohe_X4.transform(X4).astype(np.float32)\n",
    "    print(f'OHE Categories : {ohe_X4.categories_}')\n",
    "else:\n",
    "    X4_final = X4.to_numpy().astype(np.float32)\n",
    "print(f'X4_final shape : {X4_final.shape}')\n",
    "\n",
    "if label is not None:\n",
    "    if standardizelabel:\n",
    "        scaler_y = StandardScaler().fit(y)\n",
    "        y_scaled_np = scaler_y.transform(y)\n",
    "        y_np = scaler_y.inverse_transform(y_scaled_np)\n",
    "        y_final = y_scaled_np.astype(np.float32)\n",
    "        print(f'y Scaling done accurately ? : {np.allclose(y_np, y)}')\n",
    "    else:\n",
    "        y_final = y.astype(np.float32)\n",
    "\n",
    "if label is not None:\n",
    "    if descriptors2 is not None:\n",
    "        dataset = XsandYDataset(torch.from_numpy(y_final), torch.from_numpy(X1_final), torch.from_numpy(X2_final))\n",
    "    else:\n",
    "        dataset = XandYDataset(torch.from_numpy(y_final), torch.from_numpy(X1_final))\n",
    "else:\n",
    "    if descriptors2 is not None:\n",
    "        dataset = XsDataset(torch.from_numpy(X1_final), torch.from_numpy(X2_final), torch.from_numpy(X3_final), torch.from_numpy(X4_final))\n",
    "    else:\n",
    "        dataset = XDataset(torch.from_numpy(X1_final))\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd690517",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04622125",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------------ USER INPUT START ------------------------\n",
    "activation_fns = {'relu': torch.nn.ReLU(), \n",
    "                  'elu': torch.nn.ELU(),\n",
    "                  'tanh': torch.nn.Tanh(), \n",
    "                  'sigmoid': torch.nn.Sigmoid(),\n",
    "                  'softmax': torch.nn.Softmax(dim=1),\n",
    "                   None: None}\n",
    "\n",
    "custom_arch = False\n",
    "# If true mention the feature dimensions for each input in the decoder.\n",
    "multiple_outputs = True\n",
    "## ------------------------ USER INPUT END ------------------------\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "        try:\n",
    "            self.activation_fn = activation_fns[activation_fn]\n",
    "        except KeyError:\n",
    "            raise ValueError('Invalid activation function')\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            self.layers.append(torch.nn.Linear(self.input_dim, self.latent_dim))\n",
    "            if self.activation_fn is not None:\n",
    "                self.layers.append(self.activation_fn)\n",
    "        else:\n",
    "            for i in range(self.num_layers):\n",
    "                if i == 0:\n",
    "                    self.layers.append(torch.nn.Linear(self.input_dim, self.hidden_dim))\n",
    "                    if self.activation_fn is not None:\n",
    "                        self.layers.append(self.activation_fn)\n",
    "                    self.layers.append(torch.nn.Dropout(self.dropout))\n",
    "                elif i == self.num_layers - 1:\n",
    "                    self.layers.append(torch.nn.Linear(self.hidden_dim, self.latent_dim))\n",
    "                else:\n",
    "                    self.layers.append(torch.nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "                    if self.activation_fn is not None:\n",
    "                        self.layers.append(self.activation_fn)\n",
    "                    self.layers.append(torch.nn.Dropout(self.dropout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                z = layer(x)\n",
    "            else:\n",
    "                z = layer(z)\n",
    "        return z\n",
    "    \n",
    "class Predictor(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, output_activation_fn):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "        try:\n",
    "            self.activation_fn = activation_fns[activation_fn]\n",
    "            self.output_activation_fn = activation_fns[output_activation_fn]\n",
    "        except KeyError:\n",
    "            raise ValueError('Invalid activation function')\n",
    "        self.custom_arch = False\n",
    "    \n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        \n",
    "        if custom_arch:\n",
    "            self.layers.append(torch.nn.Linear(self.latent_dim, self.hidden_dim))\n",
    "            self.layers.append(torch.nn.Tanh())\n",
    "            self.layers.append(torch.nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "            self.layers.append(torch.nn.Tanh())\n",
    "            self.layers.append(torch.nn.Linear(self.hidden_dim, 1))\n",
    "        else:\n",
    "            if self.num_layers == 1:\n",
    "                self.layers.append(torch.nn.Linear(self.latent_dim, 1))\n",
    "                if self.output_activation_fn is not None:\n",
    "                    self.layers.append(self.output_activation_fn)\n",
    "            else:\n",
    "                for i in range(self.num_layers):\n",
    "                    if i == 0:\n",
    "                        self.layers.append(torch.nn.Linear(self.latent_dim, self.hidden_dim))\n",
    "                        if self.activation_fn is not None:\n",
    "                            self.layers.append(self.activation_fn)\n",
    "                        self.layers.append(torch.nn.Dropout(self.dropout))\n",
    "                    elif i == self.num_layers - 1:\n",
    "                        self.layers.append(torch.nn.Linear(self.hidden_dim, 1))\n",
    "                        if self.output_activation_fn is not None:\n",
    "                            self.layers.append(self.output_activation_fn)\n",
    "                    else:\n",
    "                        self.layers.append(torch.nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "                        if self.activation_fn is not None:\n",
    "                            self.layers.append(self.activation_fn)\n",
    "                        self.layers.append(torch.nn.Dropout(self.dropout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                pred = layer(x)\n",
    "            else:\n",
    "                pred = layer(pred)\n",
    "        return pred\n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, output_activation_fn):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "        try:\n",
    "            self.activation_fn = activation_fns[activation_fn]\n",
    "            self.output_activation_fn = activation_fns[output_activation_fn]\n",
    "        except KeyError:\n",
    "            raise ValueError('Invalid activation function')\n",
    "        self.multiple_outputs = True\n",
    "        \n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            if self.multiple_outputs:\n",
    "                self.layers.append(torch.nn.Linear(self.latent_dim, self.hidden_dim))\n",
    "                if self.output_activation_fn is not None:\n",
    "                    self.layers.append(self.output_activation_fn)\n",
    "            else:\n",
    "                self.layers.append(torch.nn.Linear(self.latent_dim, self.input_dim))\n",
    "                if self.output_activation_fn is not None:\n",
    "                    self.layers.append(self.output_activation_fn)\n",
    "\n",
    "        else:\n",
    "            for i in range(self.num_layers):\n",
    "                if i == 0:\n",
    "                    self.layers.append(torch.nn.Linear(self.latent_dim, self.hidden_dim))\n",
    "                    if self.activation_fn is not None:\n",
    "                        self.layers.append(self.activation_fn)\n",
    "                    self.layers.append(torch.nn.Dropout(self.dropout))\n",
    "                elif i == self.num_layers - 1:\n",
    "                    if self.multiple_outputs:\n",
    "                        self.layers.append(torch.nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "                        if self.output_activation_fn is not None:\n",
    "                            self.layers.append(self.output_activation_fn)\n",
    "                    else:\n",
    "                        self.layers.append(torch.nn.Linear(self.hidden_dim, self.input_dim))\n",
    "                        if self.output_activation_fn is not None:\n",
    "                            self.layers.append(self.output_activation_fn)\n",
    "                else:\n",
    "                    self.layers.append(torch.nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "                    if self.activation_fn is not None:\n",
    "                        self.layers.append(self.activation_fn)\n",
    "                    self.layers.append(torch.nn.Dropout(self.dropout))\n",
    "\n",
    "        if multiple_outputs:\n",
    "            self.output1_layer = torch.nn.Linear(self.hidden_dim, 5)\n",
    "            self.output2_layer = torch.nn.Linear(self.hidden_dim, 5)  \n",
    "            self.output3_layer = torch.nn.Linear(self.hidden_dim, 5)      \n",
    "            self.output4_layer = torch.nn.Linear(self.hidden_dim, 4)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                recon = layer(x)\n",
    "            else:\n",
    "                recon = layer(recon)\n",
    "        if multiple_outputs:\n",
    "            recon1 = self.output1_layer(recon)\n",
    "            recon2 = self.output2_layer(recon)\n",
    "            recon3 = self.output3_layer(recon)\n",
    "            recon4 = self.output4_layer(recon)\n",
    "            return recon1, recon2, recon3, recon4\n",
    "        else:\n",
    "            return recon\n",
    "\n",
    "class SupervisedSimpleAE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, pred_activation_fn, dec_activation_fn):\n",
    "        super(SupervisedSimpleAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "        self.predictor = Predictor(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, pred_activation_fn)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn)\n",
    "        # If multiple outputs then define the layers here ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        pred = self.predictor(z)\n",
    "        if multiple_outputs:\n",
    "            recon1, recon2 = self.decoder(z)\n",
    "            return z, pred, recon1, recon2\n",
    "        else:\n",
    "            recon = self.decoder(z)\n",
    "            return z, pred, recon\n",
    "    \n",
    "class UnsupervisedSimpleAE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn):\n",
    "        super(UnsupervisedSimpleAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn)\n",
    "        # If multiple outputs then define the layers here ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        if multiple_outputs:\n",
    "            recon1, recon2, recon3, recon4  = self.decoder(z)\n",
    "            return z, recon1, recon2, recon3, recon4 \n",
    "        else:\n",
    "            recon = self.decoder(z)\n",
    "            return z, recon\n",
    "    \n",
    "class SupervisedVAE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, pred_activation_fn, dec_activation_fn):\n",
    "        super(SupervisedVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "        self.predictor = Predictor(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, pred_activation_fn)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn)\n",
    "        self.mu = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.sqrt(torch.exp(logvar))\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.mu(h)\n",
    "        logvar = self.logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        pred = self.predictor(z)\n",
    "        reconst = self.decoder(z)\n",
    "        return z, pred, reconst, mu, logvar\n",
    "    \n",
    "class UnsupervisedVAE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn):\n",
    "        super(UnsupervisedVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn)\n",
    "        self.mu = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.sqrt(torch.exp(logvar))\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.mu(h)\n",
    "        logvar = self.logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconst = self.decoder(z)\n",
    "        return z, reconst, mu, logvar\n",
    "    \n",
    "# Check out these github repos for how to code the model and the loss function :\n",
    "\n",
    "# 1. https://github.com/jariasf/GMVAE/tree/master\n",
    "# 2. https://github.com/RuiShu/vae-clustering\n",
    "    \n",
    "class GMVAE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, y_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn):\n",
    "        super(GMVAE, self).__init__()\n",
    "        \"\"\"\n",
    "        A GMVAE has three main modules:\n",
    "        q(y|x) : Predict the class label based on X\n",
    "        q(z|y,x) : Predict the latent variable based on X and the class label\n",
    "        \"\"\"\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn)\n",
    "        try:\n",
    "            self.activation_fn = activation_fns[activation_fn]\n",
    "        except KeyError:\n",
    "            raise ValueError('Invalid activation function')\n",
    "        self.activation_fn = activation_fns[activation_fn]\n",
    "        self.input_dim = input_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.qy_logit_x_layers = torch.nn.ModuleList()\n",
    "        if self.num_layers == 1:\n",
    "            self.qy_logit_x_layers.append(torch.nn.Linear(self.input_dim, self.y_dim))\n",
    "            self.qy_logit_x_layers.append(self.activation_fn)\n",
    "        else:\n",
    "            for i in range(self.num_layers):\n",
    "                if i == 0:\n",
    "                    self.qy_logit_x_layers.append(torch.nn.Linear(self.input_dim, self.hidden_dim))\n",
    "                    self.qy_logit_x_layers.append(self.activation_fn)\n",
    "                    self.qy_logit_x_layers.append(torch.nn.Dropout(self.dropout))\n",
    "                elif i == self.num_layers - 1:\n",
    "                    self.qy_logit_x_layers.append(torch.nn.Linear(self.hidden_dim, self.y_dim))\n",
    "                else:\n",
    "                    self.qy_logit_x_layers.append(torch.nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "                    self.qy_logit_x_layers.append(self.activation_fn)\n",
    "                    self.qy_logit_x_layers.append(torch.nn.Dropout(self.dropout))\n",
    "\n",
    "        self.mu = torch.nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "        self.logvar = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.latent_dim),\n",
    "            torch.nn.Softplus()\n",
    "        )\n",
    "        self.mu_prior = torch.nn.Linear(self.y_dim, self.latent_dim)\n",
    "        self.logvar_prior = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.y_dim, self.latent_dim),\n",
    "            torch.nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.sqrt(torch.exp(logvar))\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, qy_logit_x_layer in enumerate(self.qy_logit_x_layers):\n",
    "            if i == 0:\n",
    "                qy_logit = qy_logit_x_layer(x)\n",
    "            else:\n",
    "                qy_logit = qy_logit_x_layer(qy_logit)\n",
    "        qy = torch.nn.Softmax(dim=1)(qy_logit)\n",
    "\n",
    "        # Defining a tensor that will store the fixed class label for all members of the batch\n",
    "        y_ = torch.zeros([x.shape[0], self.y_dim])\n",
    "        z, pred, reconst, mu, logvar, mu_prior, logvar_prior = [[None] * 10 for i in range(7)]\n",
    "        for i in range(self.y_dim):\n",
    "            # Add the class label to the tensor\n",
    "            y = y_ + torch.eye(self.y_dim)[i]\n",
    "            # Note to self : The generative model can take the predicted class label as input. This is what is done in the GMVAE repo\n",
    "            # Note to self : In the Rui Shu repo the class label (y) is provided as a one hot vector. \n",
    "            h = torch.cat([x, y], dim=1)\n",
    "            for j, encoder_layer in enumerate(self.encoder_layers):\n",
    "                if j == 0:\n",
    "                    h = encoder_layer(h)\n",
    "                else:\n",
    "                    h = encoder_layer(h)\n",
    "            mu[i] = self.mu(h)\n",
    "            logvar[i] = self.logvar(h)\n",
    "            # Note to self : Can use the reparameterization trick here instead. This gives modified M2 in Rui Shu's repo.\n",
    "            # Using the predicted mean and logvar sample from a gaussian distribution.\n",
    "            # z[i] = torch.normal(mu[i], logvar[i].exp().sqrt())\n",
    "            z[i] = self.reparameterize(mu[i], logvar[i])\n",
    "            for j, pred_layer in enumerate(self.predictor_layers):\n",
    "                if j == 0:\n",
    "                    pred[i] = pred_layer(z[i])\n",
    "                else:\n",
    "                    pred[i] = pred_layer(pred[i])    \n",
    "            mu_prior[i] = self.mu_prior(y)\n",
    "            logvar_prior[i] = self.logvar_prior(y)\n",
    "            for j, decoder_layer in enumerate(self.decoder_layers):\n",
    "                if j == 0:\n",
    "                    reconst[i] = decoder_layer(z[i])\n",
    "                else:\n",
    "                    reconst[i] = decoder_layer(reconst[i])\n",
    "        return z, pred, reconst, mu, logvar, mu_prior, logvar_prior, qy_logit, qy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a700ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.1194,  0.0835, -0.2836,  0.1417,  0.0063],\n",
      "        [-0.1277,  0.0807, -0.2891,  0.1496,  0.0049]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.1037,  0.2275,  0.3310,  0.1295,  0.2166],\n",
      "        [-0.0951,  0.2288,  0.3349,  0.1155,  0.2255]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.1771, -0.0429, -0.1416,  0.1270,  0.1181],\n",
      "        [-0.1824, -0.0526, -0.1386,  0.1236,  0.1124]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.4547,  0.1833,  0.3178,  0.0128],\n",
      "        [-0.4551,  0.1840,  0.3242,  0.0161]], grad_fn=<AddmmBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# Test the simple autoencoder\n",
    "randX = torch.rand(2, 2)\n",
    "# self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn\n",
    "simple_ae = UnsupervisedSimpleAE(15, 10, 0.01, 2, 3, 'tanh', None)\n",
    "print(simple_ae.decoder(randX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d1ec",
   "metadata": {},
   "source": [
    "### Deriving the KL divergence loss for unit normal prior\n",
    "\n",
    "- Lets start with any arbitrary distribution Q(z) and minimize the KL divergence of it with a distribution P(z|X)\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    D_{KL}(Q(z) || P(z|X)) & = \\int Q(z) \\log \\frac{Q(z)}{P(z|X)} dz \\\\ \\\\\n",
    "    D_{KL}(Q(z) || P(z|X)) & = E_{Q(z)}[ \\log \\frac{Q(z)}{P(z|X)} ] \\\\ \\\\\n",
    "    D_{KL}(Q(z) || P(z|X)) & = E_{Q(z)}[ \\log Q(z) - \\log P(z|X) ] \\\\ \\\\\n",
    "    D_{KL}(Q(z) || P(z|X)) & = E_{Q(z)}[ \\log Q(z) - \\log P(X|z) - \\log P(z) + \\log P(X) ] \\\\ \\\\\n",
    "    D_{KL}(Q(z) || P(z|X)) & = E_{Q(z)}[ \\log Q(z) - \\log P(X|z) - \\log P(z)] + \\log P(X) \\\\ \\\\\n",
    "    \\log P(X) - D_{KL}(Q(z) || P(z|X)) & =  E_{Q(z)}[\\log P(X|z)] - D_{KL}(Q(z) || P(z)) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- Now instead of choosing any distribution for Q(z), it makes sense to choose a distribution for the z variables that depends on X. Hence we can replace Q(z) with Q(z|X).\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\log P(X) - D_{KL}(Q(z|X) || P(z|X)) & =  E_{Q(z|X)}[\\log P(X|z)] - D_{KL}(Q(z|X) || P(z))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- The left hand side contains the terms that we want to maximize. The log probability density of X and an error term that measures the deviation between the approximate distribution (Q(z|X)) and the true probability distribution (P(z|X)). To note P(X) is a high dimensional intractable distribution and we don't have access to P(z|X). By having a large enough capacity for Q(z|X) we are pulling it closer to P(z|X), lower the KL divergence term until we are only optimizing for the log probability density of X. \n",
    "- The right hand side contains terms that can be optimized via gradient descent. The first term is the expected value of the log likelihood of the data given the latent variables. The second term is the KL divergence between the approximate distribution and the prior distribution. \n",
    "- Stochastic gradient descent can be performed on the right hand side by assuming some forms of the distribution. The most common form for the posterior and liklihood is a multivariate Gaussian distribution and for the prior is unit normal distribution. \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    D_{KL}(N(\\mu_0, \\Sigma_0) || N(\\mu_1, \\Sigma_1)) = \\frac{1}{2} ( \\text{tr}(\\Sigma_1^{-1} \\Sigma_0) + (\\mu_1 - \\mu_0)^T \\Sigma_1^{-1} (\\mu_1 - \\mu_0) - k + \\log \\frac{\\det \\Sigma_1}{\\det \\Sigma_0} )\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- 'k' is the dimensionality of the distribution. Substituting the prior as unit normal distribution, we get the KL divergence loss as\n",
    "$$\n",
    "\\begin{align*}\n",
    "    D_{KL}(N(\\mu (X), \\Sigma (X)) || N(O, I)) = \\frac{1}{2} ( \\text{tr}(\\Sigma (X)) + (\\mu (X))^T (\\mu (X)) - k - \\log \\det \\Sigma (X) )\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- To back propagate the errors to the the neural network that approximates Q(z|X), so that we get z's that correctly reproduce the data, we need to find a way that allows backpropagation to work. This is where the reparameterization trick comes in. It allows us to sample for 'z' while giving access to the neural networks that approximate the mean and covariance functions for  Q(z|X). $ z = \\mu (X) + \\Sigma (X) * \\epsilon $. Here $\\mu (X) and \\Sigma (X)$ are approximated by using neural networks and $\\epsilon$ is sampled from the unit normal distribution.\n",
    "- If any other distribution is to be modelled then the KL divergnce term must be modified accordingly and the appropriate reparameterization trick must be used.\n",
    "\n",
    "Reference:\n",
    "- Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014 https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "- Doersch, C. Tutorial on Variational Autoencoders. arXiv January 3, 2021. http://arxiv.org/abs/1606.05908.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cfc68",
   "metadata": {},
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf96a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: qlalchu1\n",
      "Sweep URL: https://wandb.ai/nthota2/perovskite_dataset_v2/sweeps/qlalchu1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ilh31zun with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_activation_fn: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_reg: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_reg: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpred_activation_fn: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ty_dim: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnthota2\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: il9xkni0\n",
      "Sweep URL: https://wandb.ai/nthota2/perovskite_dataset_v2/sweeps/il9xkni0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikhilthota/Desktop/lab/projects/SPIRAL/codes_and_datasets/T-NIKHIL/NestedAE/code/wandb/run-20240316_010451-ilh31zun</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nthota2/perovskite_dataset_v2/runs/ilh31zun' target=\"_blank\">splendid-sweep-1</a></strong> to <a href='https://wandb.ai/nthota2/perovskite_dataset_v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nthota2/perovskite_dataset_v2/sweeps/qlalchu1' target=\"_blank\">https://wandb.ai/nthota2/perovskite_dataset_v2/sweeps/qlalchu1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nthota2/perovskite_dataset_v2' target=\"_blank\">https://wandb.ai/nthota2/perovskite_dataset_v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nthota2/perovskite_dataset_v2/sweeps/qlalchu1' target=\"_blank\">https://wandb.ai/nthota2/perovskite_dataset_v2/sweeps/qlalchu1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nthota2/perovskite_dataset_v2/runs/ilh31zun' target=\"_blank\">https://wandb.ai/nthota2/perovskite_dataset_v2/runs/ilh31zun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Thread(Thread-6, stopped 11492470784)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/threading.py\", line 937, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/threading.py\", line 982, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/threading.py\", line 1264, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/ipykernel/iostream.py\", line 559, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/ipykernel/iostream.py\", line 559, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/ipykernel/iostream.py\", line 251, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cn9h4kr8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_activation_fn: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_reg: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_reg: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpred_activation_fn: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ty_dim: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1172, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 233, in setup\n",
      "    tel.feature.set_init_tags = True\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 759, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 770, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1172, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 233, in setup\n",
      "    tel.feature.set_init_tags = True\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 759, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 770, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "    self._function()\n",
      "  File \"/var/folders/k2/lw7ggcln7zx_cnkbk2zbgvm80000gn/T/ipykernel_43056/2437333668.py\", line 376, in <lambda>\n",
      "  File \"/var/folders/k2/lw7ggcln7zx_cnkbk2zbgvm80000gn/T/ipykernel_43056/2437333668.py\", line 18, in train\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1214, in init\n",
      "    raise Error(\"An unexpected error occurred\") from error_seen\n",
      "wandb.errors.Error: An unexpected error occurred\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 313, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 4119, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1961, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1969, in _finish\n",
      "    tel.feature.finish = True\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 759, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 770, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ud9itcd9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_activation_fn: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_reg: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_reg: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpred_activation_fn: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ty_dim: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1172, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 233, in setup\n",
      "    tel.feature.set_init_tags = True\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 759, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 770, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1172, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 233, in setup\n",
      "    tel.feature.set_init_tags = True\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 759, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 770, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n",
      "    self._function()\n",
      "  File \"/var/folders/k2/lw7ggcln7zx_cnkbk2zbgvm80000gn/T/ipykernel_43056/2437333668.py\", line 376, in <lambda>\n",
      "  File \"/var/folders/k2/lw7ggcln7zx_cnkbk2zbgvm80000gn/T/ipykernel_43056/2437333668.py\", line 18, in train\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1214, in init\n",
      "    raise Error(\"An unexpected error occurred\") from error_seen\n",
      "wandb.errors.Error: An unexpected error occurred\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 313, in _run_job\n",
      "    wandb.finish(exit_code=1)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 4119, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 420, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 361, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1961, in finish\n",
      "    return self._finish(exit_code, quiet)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1969, in _finish\n",
      "    tel.feature.finish = True\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 759, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 770, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gju6blcy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_activation_fn: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_reg: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_reg: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpred_activation_fn: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ty_dim: None\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "def log_normal(z, mu, logvar):\n",
    "    c = torch.tensor(2*np.pi, dtype=torch.float32) \n",
    "    return torch.tensor(-0.5, dtype=torch.float32)*torch.sum(torch.log(c) + logvar + (z - mu).pow(2) / logvar.exp(), dim=1)\n",
    "\n",
    "# KL divergence loss\n",
    "def labelled_loss(z, mu, logvar, mu_prior, logvar_prior):\n",
    "    c = torch.tensor(0.1, dtype=torch.float32)\n",
    "    return log_normal(z, mu, logvar) - log_normal(z, mu_prior, logvar_prior) - torch.log(c)\n",
    "\n",
    "# Derived by assuming posterior is Gaussian and prior is unit normal distribution.\n",
    "def kl_divergence_loss_fn(mu, logvar):\n",
    "        return torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1), dim=0)\n",
    "\n",
    "def train(train_subsampler, val_subsampler, model_type, run_dir, sweep_hyperparams=True, save_model=False, project_name=None, model_name=None, config=None):\n",
    "    if sweep_hyperparams:\n",
    "        run = wandb.init(job_type='training', resume=False, reinit=False, config=sweep_config)\n",
    "        config = wandb.config\n",
    "        input_dim = config.input_dim\n",
    "        hidden_dim = config.hidden_dim\n",
    "        y_dim = config.y_dim\n",
    "        dropout = config.dropout\n",
    "        l1_reg = config.l1_reg\n",
    "        l2_reg = config.l2_reg\n",
    "        latent_dim = config.latent_dim\n",
    "        num_layers = config.num_layers\n",
    "        activation_fn = config.activation_fn\n",
    "        pred_activation_fn = config.pred_activation_fn\n",
    "        dec_activation_fn = config.dec_activation_fn\n",
    "        lr = config.learning_rate\n",
    "        epochs = config.epochs\n",
    "        batch_size = config.batch_size\n",
    "    else:\n",
    "        run = wandb.init(project=project_name, name=model_name, job_type='training', resume=False, reinit=False, config=config)\n",
    "        input_dim = config['input_dim']['value']\n",
    "        hidden_dim = config['hidden_dim']['value']\n",
    "        y_dim = config['y_dim']['value']\n",
    "        dropout = config['dropout']['value']\n",
    "        l1_reg = config['l1_reg']['value']\n",
    "        l2_reg = config['l2_reg']['value']\n",
    "        latent_dim = config['latent_dim']['value']\n",
    "        num_layers = config['num_layers']['value']\n",
    "        activation_fn = config['activation_fn']['value']\n",
    "        pred_activation_fn = config['pred_activation_fn']['value']\n",
    "        dec_activation_fn = config['dec_activation_fn']['value']\n",
    "        lr = config['learning_rate']['value']\n",
    "        epochs = config['epochs']['value']\n",
    "        batch_size = config['batch_size']['value']\n",
    "    \n",
    "    if model_type == 'SupervisedSimpleAE':\n",
    "        model = SupervisedSimpleAE(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, pred_activation_fn, dec_activation_fn)\n",
    "    elif model_type == 'UnsupervisedSimpleAE':\n",
    "        model = UnsupervisedSimpleAE(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn)\n",
    "    elif model_type == 'SupervisedVAE':\n",
    "        model = SupervisedVAE(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "    elif model_type == 'UnsupervisedVAE':\n",
    "        model = UnsupervisedVAE(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "    elif model_type == 'GMVAE':\n",
    "        model = GMVAE(input_dim, y_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "    else:\n",
    "        raise ValueError('Invalid model type')\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_subsampler, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_subsampler, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_kl_loss_per_step = []\n",
    "        train_recon1_loss_per_step = []\n",
    "        train_recon2_loss_per_step = []\n",
    "        train_recon3_loss_per_step = []\n",
    "        train_recon4_loss_per_step = []\n",
    "        train_pred_loss_per_step = []\n",
    "        train_total_loss_per_step = []\n",
    "        val_kl_loss_per_step = []\n",
    "        val_recon1_loss_per_step = []\n",
    "        val_recon2_loss_per_step = []\n",
    "        val_recon3_loss_per_step = []\n",
    "        val_recon4_loss_per_step = []\n",
    "        val_pred_loss_per_step = []\n",
    "        val_total_loss_per_step = []\n",
    "        # for i, input in enumerate(train_dataloader):\n",
    "        # for i, (y, input) in enumerate(train_dataloader):\n",
    "        for i, (input1, input2, input3, input4) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Model 1\n",
    "            _, recon1, recon2, recon3, recon4 = model(torch.concat((input1, input2, input3, input4), dim=1))\n",
    "            # _, pred, reconst = model(input)\n",
    "            # _, reconst = model(input)\n",
    "            # train_loss1 = torch.nn.L1Loss(reduction='mean')(reconst1, input1)\n",
    "            # train_recon1_loss_per_step.append(train_loss1.item())\n",
    "            train_loss1 = torch.nn.CrossEntropyLoss(reduction='mean')(recon1, input1)\n",
    "            train_recon1_loss_per_step.append(train_loss1.item())\n",
    "\n",
    "            train_loss2 = torch.nn.CrossEntropyLoss(reduction='mean')(recon2, input2)\n",
    "            train_recon2_loss_per_step.append(train_loss2.item())\n",
    "\n",
    "            train_loss3 = torch.nn.CrossEntropyLoss(reduction='mean')(recon3, input3)\n",
    "            train_recon3_loss_per_step.append(train_loss3.item())\n",
    "\n",
    "            train_loss4 = torch.nn.L1Loss(reduction='mean')(recon4, input4)\n",
    "            train_recon4_loss_per_step.append(train_loss4.item())\n",
    "\n",
    "            # train_loss3 = torch.nn.L1Loss(reduction='mean')(y, pred)\n",
    "            # train_pred_loss_per_step.append(train_loss3.item())\n",
    "\n",
    "            enc_params = torch.cat([x.view(-1) for x in model.encoder.parameters()])\n",
    "            # pred_params = torch.cat([x.view(-1) for x in model.predictor.parameters()])\n",
    "            dec_params = torch.cat([x.view(-1) for x in model.decoder.parameters()])\n",
    "\n",
    "            l1_regularization = l1_reg * (torch.norm(enc_params, 1) + \n",
    "                                          torch.norm(dec_params, 1))\n",
    "            l2_regularization = l2_reg * (torch.norm(enc_params, 2) + \n",
    "                                          torch.norm(dec_params, 2))\n",
    "            \n",
    "            train_total_loss = train_loss1 + train_loss2 + train_loss3 + train_loss4 + l1_regularization + l2_regularization\n",
    "            # train_total_loss = train_loss1 + train_loss2 + train_loss3 + l1_regularization + l2_regularization\n",
    "            # train_total_loss = train_loss1 + train_loss2 + l1_regularization + l2_regularization\n",
    "            # train_total_loss = train_loss1 + l1_regularization + l2_regularization\n",
    "            train_total_loss_per_step.append(train_total_loss.item())\n",
    "\n",
    "            # # Model 2\n",
    "            # z, pred, reconst, mu, logvar = model(input)\n",
    "            # train_loss1 = kl_divergence_loss_fn(mu, logvar)\n",
    "            # train_kl_loss_per_step.append(train_loss1.item())\n",
    "            # train_loss2 = torch.nn.MSELoss(reduction='mean')(input, reconst)\n",
    "            # train_reconst_loss_per_step.append(train_loss2.item())\n",
    "            # train_loss3 = torch.nn.MSELoss(reduction='mean')(bandgaps.unsqueeze(dim=1), pred)\n",
    "            # train_pred_loss_per_step.append(train_loss3.item())\n",
    "            # train_total_loss = train_loss1 + train_loss2 + train_loss3\n",
    "            # train_total_loss_per_step.append(train_total_loss.item())\n",
    "\n",
    "            # # Model 3\n",
    "            # z, pred, reconst, mu, logvar, mu_prior, logvar_prior, qy_logit, qy = model(input)\n",
    "            # train_loss1 = torch.nn.CrossEntropyLoss(reduction='mean')(qy_logit, qy)\n",
    "            # train_loss2 = [None] * model.y_dim\n",
    "            # train_loss3 = [None] * model.y_dim\n",
    "            # train_loss4 = [None] * model.y_dim\n",
    "            # for i in range(model.y_dim):\n",
    "            #     # Take mean across the batch\n",
    "            #     train_loss2[i] = torch.mean(qy[:, i]*torch.nn.L1Loss(reduction='sum')(bandgaps.unsqueeze(dim=1), pred[i]), dtype=torch.float32)\n",
    "            #     train_loss3[i] = torch.mean(qy[:, i]*torch.nn.MSELoss(reduction='sum')(input, reconst[i]), dtype=torch.float32)\n",
    "            #     train_loss4[i] = torch.mean(qy[:, i]*labelled_loss(z[i], mu[i], logvar[i], mu_prior[i], logvar_prior[i]), dtype=torch.float32)\n",
    "            # train_pred_loss_per_step.append(torch.stack(train_loss2).sum().item())\n",
    "            # train_reconst_loss_per_step.append(torch.stack(train_loss3).sum().item())\n",
    "            # train_kl_loss_per_step.append(torch.stack(train_loss4).sum().item())\n",
    "            # train_total_loss = train_loss1 + torch.stack(train_loss2).sum() + torch.stack(train_loss3).sum() + torch.stack(train_loss4).sum()\n",
    "            # train_total_loss_per_step.append(train_total_loss.item())\n",
    "\n",
    "            train_total_loss.backward()\n",
    "            optimizer.step()\n",
    "        # if model_type == 'GMVAE':\n",
    "        #     wandb.log({'epoch':epoch, 'train_kl_loss_per_epoch':np.mean(train_kl_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'train_recon1_loss_per_epoch':np.mean(train_recon1_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'train_recon2_loss_per_epoch':np.mean(train_recon2_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'train_recon3_loss_per_epoch':np.mean(train_recon3_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'train_recon4_loss_per_epoch':np.mean(train_recon4_loss_per_step)})\n",
    "        # wandb.log({'epoch':epoch, 'train_pred_loss_per_epoch':np.mean(train_pred_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'train_total_loss_per_epoch':np.mean(train_total_loss_per_step)})\n",
    "\n",
    "        # Run the validation loop\n",
    "        # for i, input in enumerate(val_dataloader):\n",
    "        # for i, (y, input) in enumerate(val_dataloader):\n",
    "        # for i, (y, input1, input2) in enumerate(val_dataloader):\n",
    "        for i, (input1, input2, input3, input4) in enumerate(val_dataloader):\n",
    "            # Model 1\n",
    "            _, recon1, recon2, recon3, recon4 = model(torch.concat((input1, input2, input3, input4), dim=1))\n",
    "            # _, pred, reconst1, reconst2 = model(torch.concat((input1, input2), dim=1))\n",
    "            # _, pred, reconst = model(input)\n",
    "            # _, reconst = model(input)\n",
    "\n",
    "            # val_loss1 = torch.nn.L1Loss(reduction='mean')(recon1, input1)\n",
    "            # val_recon1_loss_per_step.append(val_loss1.item())\n",
    "            val_loss1 = torch.nn.CrossEntropyLoss(reduction='mean')(recon1, input1)\n",
    "            val_recon1_loss_per_step.append(val_loss1.item())\n",
    "\n",
    "            val_loss2 = torch.nn.CrossEntropyLoss(reduction='mean')(recon2, input2)\n",
    "            val_recon2_loss_per_step.append(val_loss2.item())\n",
    "\n",
    "            val_loss3 = torch.nn.CrossEntropyLoss(reduction='mean')(recon3, input3)\n",
    "            val_recon3_loss_per_step.append(val_loss3.item())\n",
    "\n",
    "            val_loss4 = torch.nn.L1Loss(reduction='mean')(recon4, input4)\n",
    "            val_recon4_loss_per_step.append(val_loss4.item())\n",
    "\n",
    "            # val_loss3 = torch.nn.L1Loss(reduction='mean')(y, pred)\n",
    "            # val_pred_loss_per_step.append(val_loss3.item())\n",
    "\n",
    "            val_total_loss = val_loss1 + val_loss2 + val_loss3 + val_loss4\n",
    "            val_total_loss_per_step.append(val_total_loss.item())\n",
    "            # val_total_loss = val_loss1 + val_loss2\n",
    "            # val_total_loss_per_step.append(val_total_loss.item())\n",
    "            # val_total_loss = val_loss1\n",
    "            # val_total_loss_per_step.append(val_total_loss.item())\n",
    "\n",
    "            # # Model 2\n",
    "            # z, pred, reconst, mu, logvar = model(input)\n",
    "            # val_loss1 = kl_divergence_loss_fn(mu, logvar)\n",
    "            # val_kl_loss_per_step.append(val_loss1.item())\n",
    "            # val_loss2 = torch.nn.MSELoss(reduction='mean')(input, reconst)\n",
    "            # val_reconst_loss_per_step.append(val_loss2.item())\n",
    "            # val_loss3 = torch.nn.MSELoss(reduction='mean')(bandgaps.unsqueeze(dim=1), pred)\n",
    "            # val_pred_loss_per_step.append(val_loss3.item())\n",
    "            # val_total_loss = val_loss1 + val_loss2 + val_loss3\n",
    "            # val_total_loss_per_step.append(val_total_loss.item())\n",
    "\n",
    "            # # Model 3\n",
    "            # z, pred, reconst, mu, logvar, mu_prior, logvar_prior, qy_logit, qy = model(input)\n",
    "            # val_loss1 = torch.nn.CrossEntropyLoss(reduction='mean')(qy_logit, qy)\n",
    "            # val_loss2 = [None] * model.y_dim\n",
    "            # val_loss3 = [None] * model.y_dim\n",
    "            # val_loss4 = [None] * model.y_dim\n",
    "            # for i in range(model.y_dim):\n",
    "            #     # Take mean across batch\n",
    "            #     val_loss2[i] = torch.mean(qy[:, i]*torch.nn.L1Loss(reduction='sum')(bandgaps.unsqueeze(dim=1), pred[i]), dtype=torch.float32)\n",
    "            #     val_loss3[i] = torch.mean(qy[:, i]*torch.nn.MSELoss(reduction='sum')(input, reconst[i]), dtype=torch.float32)\n",
    "            #     val_loss4[i] = torch.mean(qy[:, i]*labelled_loss(z[i], mu[i], logvar[i], mu_prior[i], logvar_prior[i]), dtype=torch.float32)\n",
    "            # val_pred_loss_per_step.append(torch.stack(val_loss2).sum().item())\n",
    "            # val_reconst_loss_per_step.append(torch.stack(val_loss3).sum().item())\n",
    "            # val_kl_loss_per_step.append(torch.stack(val_loss4).sum().item())\n",
    "            # val_total_loss = val_loss1 + torch.stack(val_loss2).sum() + torch.stack(val_loss3).sum() + torch.stack(val_loss4).sum()\n",
    "            # val_total_loss_per_step.append(val_total_loss.item())\n",
    "\n",
    "        # if model_type == 'GMVAE':\n",
    "        #     wandb.log({'epoch':epoch, 'val_kl_loss_per_epoch':np.mean(val_kl_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'val_recon1_loss_per_epoch': np.mean(val_recon1_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'val_recon2_loss_per_epoch': np.mean(val_recon2_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'val_recon3_loss_per_epoch': np.mean(val_recon3_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'val_recon4_loss_per_epoch': np.mean(val_recon4_loss_per_step)})\n",
    "        # wandb.log({'epoch':epoch, 'val_pred_loss_per_epoch': np.mean(val_pred_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'val_total_loss_per_epoch': np.mean(val_total_loss_per_step)})\n",
    "    run.finish()\n",
    "    # Save the model\n",
    "    if save_model:\n",
    "        model_dir = f'../runs/{run_dir}/{model_name}'\n",
    "        # if model dir does not exist create it\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model_path = model_dir + '/' + f'{model_name}.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # Save the scalers also in the model folder\n",
    "        # scaler_X1_path = f'../runs/perovskite_multiscale_dataset_v2/{model_name}/scaler_X1.pkl'\n",
    "        scaler_X4_path = f'../runs/perovskite_multiscale_dataset_v2/{model_name}/scaler_latentsfromAE1.pkl'\n",
    "        scaler_y_path = f'../runs/perovskite_multiscale_dataset_v2/{model_name}/scaler_y.pkl'\n",
    "        joblib.dump(scaler_X4, scaler_X4_path)\n",
    "        if model_type == 'SupervisedSimpleAE':\n",
    "            pass\n",
    "            # joblib.dump(scaler_y, scaler_y_path)\n",
    "    \n",
    "# If sweeping for hyperparams replace 'value' with 'values' \n",
    "    \n",
    "# USER INPUT HERE\n",
    "# -----------------------------------------------------------------\n",
    "# By default save_model is set to False for hyperparam runs.\n",
    "sweep_for_hyperparams = True\n",
    "model_name = 'UnsupSimpleAE_2_ldim4_peroveff2'\n",
    "run_dir = 'perovskite_multiscale_dataset_v2'\n",
    "save_model = False\n",
    "model_type = 'UnsupervisedSimpleAE'\n",
    "sweep_name = 'UnsupSimpleAE_2_ldim4_peroveff2'\n",
    "sweep_type = 'grid' # Select between 'bayes', 'grid', 'random' \n",
    "limit_num_trials_in_sweep = None # Typically 3*3*3=27 trials. Consider only (10% of space is explored) 0.1*81=8.1 ~ 8 trials\n",
    "num_folds = 5 # 494/5 = 98.8 in internal validation set\n",
    "val_split = 0.2 # num_folds*val_split must be 1 \n",
    "parameters = {\n",
    "            'input_dim':{\n",
    "                'value':X1_final.shape[1] + X2_final.shape[1] + X3_final.shape[1] + X4_final.shape[1]\n",
    "            },\n",
    "            'hidden_dim':{\n",
    "                'values':[25, 50, 75]\n",
    "            },\n",
    "            'latent_dim':{\n",
    "                'value':4\n",
    "            },\n",
    "            'y_dim':{\n",
    "                'value':None\n",
    "            },\n",
    "            'dropout':{\n",
    "                'value':0\n",
    "            },\n",
    "            'l1_reg':{\n",
    "                'value':0\n",
    "            },\n",
    "            'l2_reg':{\n",
    "                'value':0.001\n",
    "            },\n",
    "            'num_layers':{\n",
    "                'values':[1, 2, 3]\n",
    "            },\n",
    "            'activation_fn':{\n",
    "                'values':['tanh', 'relu', None]\n",
    "            },\n",
    "            'dec_activation_fn':{\n",
    "                'value':None\n",
    "            },\n",
    "            'pred_activation_fn':{\n",
    "                'value':None\n",
    "            },\n",
    "            'batch_size':{\n",
    "                'value':10\n",
    "            },\n",
    "            'learning_rate':{\n",
    "                'value':1e-3\n",
    "            },\n",
    "            'epochs':{\n",
    "                'value':1000\n",
    "            }\n",
    "        }\n",
    "\n",
    "# parameters = {\n",
    "#             'input_dim':{\n",
    "#                 'value':X1.shape[1] + X2.shape[1]\n",
    "#             },\n",
    "#             'hidden_dim':{\n",
    "#                 'value':50,\n",
    "#             },\n",
    "#             'latent_dim':{\n",
    "#                 'value':4\n",
    "#             },\n",
    "#             'y_dim':{\n",
    "#                 'value':0\n",
    "#             },\n",
    "#             'dropout':{\n",
    "#                 'value':0\n",
    "#             },\n",
    "#             'l1_reg':{\n",
    "#                 'value':0\n",
    "#             },\n",
    "#             'l2_reg':{\n",
    "#                 'value':0.001\n",
    "#             },\n",
    "#             'num_layers':{\n",
    "#                 'value':3\n",
    "#             },\n",
    "#             'activation_fn':{\n",
    "#                 'value':'relu'\n",
    "#             },\n",
    "#             'dec_activation_fn':{\n",
    "#                 'value':None\n",
    "#             },\n",
    "#             'pred_activation_fn':{\n",
    "#                 'value':'relu'\n",
    "#             },\n",
    "#             'batch_size':{\n",
    "#                 'value':1\n",
    "#             },\n",
    "#             'learning_rate':{\n",
    "#                 'value':1e-3\n",
    "#             },\n",
    "#             'epochs':{\n",
    "#                 'value':1000\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "# ----------------------------------------------------------------- \n",
    "\n",
    "if sweep_for_hyperparams:\n",
    "    sweep_config = {\n",
    "        'name':sweep_name,\n",
    "        'method':sweep_type,\n",
    "        'metric':{\n",
    "            'name':'val_total_loss_per_epoch',\n",
    "            'goal':'minimize'\n",
    "            },\n",
    "        'parameters':parameters\n",
    "    }\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(dataset)):\n",
    "        train_subsampler = torch.utils.data.Subset(dataset, train_indices)\n",
    "        val_subsampler = torch.utils.data.Subset(dataset, val_indices)\n",
    "        sweep_config['name'] = sweep_config['name'] + '_fold_' + str(fold)\n",
    "        sweep_id = wandb.sweep(sweep_config, project=project_name)\n",
    "        run_name = wandb.util.generate_id()\n",
    "        wandb.agent(sweep_id, lambda: train(train_subsampler, val_subsampler, model_type=model_type, run_dir=run_dir), project=project_name, count=limit_num_trials_in_sweep)\n",
    "        # Finish the sweep\n",
    "        wandb.finish()\n",
    "else:\n",
    "    num_samples = X1.shape[0]\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[:int((1- val_split)*num_samples)]\n",
    "    val_indices = indices[int((1- val_split)*num_samples):]\n",
    "    train_subsampler = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_subsampler = torch.utils.data.Subset(dataset, val_indices)\n",
    "    train(train_subsampler, val_subsampler, model_type=model_type, run_dir=run_dir, sweep_hyperparams=False, save_model=save_model, project_name=project_name, model_name=model_name, config=parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4600c",
   "metadata": {},
   "source": [
    "## Model Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276352fd",
   "metadata": {},
   "source": [
    "#### Plotting model performance vs latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cc61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For RL paper\n",
    "# # Grid data - UnsupervisedSimpleAE 1\n",
    "# latent_space = [1, 2, 4, 6, 8]\n",
    "# total_val_loss = [0.001025053068588022, 0.001063714546035044, 0.0011066086881328374, 0.0013437549932859838, 0.0009386805177200586]\n",
    "# total_train_loss = [0.007932848995551467, 0.008279352798126638, 0.004237618821207434, 0.004374776501208544, 0.004906855116132647]\n",
    "\n",
    "# # Grid data - Nonlinf5 SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6]\n",
    "# total_val_loss = [0.7463283464312553, 0.2002287097275257, 0.1977713629603386, 0.1788929458707571]\n",
    "# total_train_loss = [0.4705591835081578, 0.14468571869656444, 0.1250611103605479, 0.13816878804937005]\n",
    "\n",
    "# # Grid data - Sumf5 - SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6]\n",
    "# total_val_loss = [0.49156802892684937, 0.019491535145789385, 0.02250012196600437, 0.02030603913590312]\n",
    "# total_train_loss = [0.4140172880142927, 0.03587072214577347, 0.02835194836370647, 0.03037486143875867]\n",
    "\n",
    "# # Random data - UnsupervisedSimpleAE 1\n",
    "# latent_space = [2, 4, 6, 8]\n",
    "# total_val_loss = [0.6480237692594528, 0.4781555384397506, 0.24337586015462875, 0.002268550335429609]\n",
    "# total_train_loss = [0.6661303304135799, 0.4441600125283003, 0.20833437889814377, 0.007954166503623128]\n",
    "\n",
    "# # Random data - Nonlinf5 - SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6, 8, 10, 11, 12]\n",
    "# total_val_loss = [0.7916551381349564, 0.6637141406536102, 0.5525364577770233, 0.3102440983057022, 0.19166426360607147, 0.051493472419679165, 0.021430929424241185, 0.007555923308245838]\n",
    "# total_train_loss = [0.7504490427672863, 0.6266670003533363, 0.4413919039070606, 0.30615816451609135, 0.18379461765289307, 0.05851957411505282, 0.028894496499560773, 0.016192137030884624]\n",
    "\n",
    "# # Random data - Sumf5 - SupervisedSimpleAE 2\n",
    "# # Will have to change the predictor as only prediction loss is high, reconstruction is good.\n",
    "# latent_space = [1, 2, 4, 6, 8, 10, 11, 12]\n",
    "# total_val_loss = [1.4578111469745636, 1.4702374935150146, 1.383190006017685, 1.16259, 0.99866, 0.81431, 0.75846, 0.83324]\n",
    "# total_train_loss = [1.4289479702711103, 1.2744147181510923, 1.0854754857718945, 0.96673, 0.84347, 0.72946, 0.69708, 0.66834]\n",
    "\n",
    "# Arun2024\n",
    "latent_space =      [2,     4,     6,     8,     10,    12,    14]\n",
    "pred_val_loss =     [0.206, 0.178, 0.244, 0.227, 0.148, 0.233, 0.231]\n",
    "pred_train_loss =   [0.11,  0.076, 0.082, 0.067, 0.074, 0.071, 0.067]\n",
    "recont_val_loss =   [0.561, 0.069, 0.055, 0.050, 0.038, 0.046, 0.056]\n",
    "recont_train_loss = [0.234, 0.055, 0.037, 0.038, 0.037, 0.042, 0.039]\n",
    "# total_val_loss = [0.76786, 0.24755343379718917, \t0.24418, 0.27646, 0.18622, 0.27943, 0.28719]\n",
    "# total_train_loss = [0.38542, 0.16735203887741917, \t0.15132, 0.13772, 0.14288, 0.14528, 0.13803]\n",
    "\n",
    "# for 10 this is the best that can be done. Adding more layers or increasing the hidden dim or using non linea act does not work.\n",
    "# val : 0.7632711380720139\n",
    "# train : 0.7363427169620991\n",
    "\n",
    "# Total val loss vs SimpleAE latent space variation\n",
    "# latent_space = [2, 3, 4, 8, 12]\n",
    "# total_val_loss = [0.5776124358177185, 0.5138478517532349, 0.4121862232685089, 0.2896019071340561, 0.2887373447418213]\n",
    "\n",
    "# Plot the latent space vs total validation loss\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(latent_space, recont_val_loss, marker='o', linestyle='', label='val')\n",
    "plt.plot(latent_space, recont_train_loss, marker='o', linestyle='', label='train')\n",
    "plt.xlabel('Latent space dimension')\n",
    "plt.ylabel('Reconst. MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52d60a",
   "metadata": {},
   "source": [
    "#### Loading the torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load torch model\n",
    "model_name = 'best_SupSimpleAE_1_ldim4_arun2024'\n",
    "run_dir = 'perovskite_multiscale_dataset_v2'\n",
    "model_path = f'../runs/{run_dir}/{model_name}/' + model_name + '.pth'\n",
    "# model = UnsupervisedSimpleAE(parameters['input_dim']['value'],\n",
    "#                             parameters['hidden_dim']['value'], \n",
    "#                             parameters['dropout']['value'], \n",
    "#                             parameters['latent_dim']['value'], \n",
    "#                             parameters['num_layers']['value'], \n",
    "#                             parameters['activation_fn']['value'],\n",
    "#                             parameters['dec_activation_fn']['value'])\n",
    "model = SupervisedSimpleAE(parameters['input_dim']['value'],\n",
    "                            parameters['hidden_dim']['value'], \n",
    "                            parameters['dropout']['value'], \n",
    "                            parameters['latent_dim']['value'], \n",
    "                            parameters['num_layers']['value'], \n",
    "                            parameters['activation_fn']['value'],\n",
    "                            parameters['pred_activation_fn']['value'],\n",
    "                            parameters['dec_activation_fn']['value'])\n",
    "# model = VAE(parameters['input_dim']['value'],\n",
    "#             parameters['hidden_dim']['value'], \n",
    "#             parameters['dropout']['value'], \n",
    "#             parameters['latent_dim']['value'], \n",
    "#             parameters['num_layers']['value'], \n",
    "#             parameters['activation_fn']['value'])\n",
    "# model = GMVAE(parameters['input_dim']['value'],\n",
    "#                 parameters['y_dim']['value'],\n",
    "#                 parameters['hidden_dim']['value'], \n",
    "#                 parameters['dropout']['value'], \n",
    "#                 parameters['latent_dim']['value'], \n",
    "#                 parameters['num_layers']['value'], \n",
    "#                 parameters['activation_fn']['value'])\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce370e",
   "metadata": {},
   "source": [
    "#### Save the latents to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the latents to .csv file\n",
    "z, pred, _, _ = model(torch.cat((torch.from_numpy(X1_final), torch.from_numpy(X2_final)), dim=1))\n",
    "latent_filename = 'latents_from_PSC_efficiencies_dataset_2'\n",
    "\n",
    "# Data folder paths and file names\n",
    "dataset_folder_name = 'synthetic_dataset'\n",
    "dataset_file_name = 'synthetic_data_gridSamples_200_sumf5.csv'\n",
    "new_dataset_file_name = 'synthetic_data_gridSamples_200_sumf5_with_ae1_latents_concat.csv'\n",
    "run_folder_name = 'perovskite_multiscale_dataset_v2'\n",
    "model_folder_name = 'best_SupSimpleAE_1_ldim4_arun2024'\n",
    "AE_number = '1'\n",
    "\n",
    "dataset_folder = '../datasets/' + dataset_folder_name\n",
    "dataset_file = dataset_folder + '/' + dataset_file_name\n",
    "concatenated_dataset_file = dataset_folder + '/' + new_dataset_file_name\n",
    "\n",
    "run_folder = '../runs/' + run_dir\n",
    "latent_file = run_folder + '/' + model_name + '/' + latent_filename + '.csv'\n",
    "\n",
    "# Save the latents to .csv file\n",
    "z_df = pd.DataFrame(z.detach().numpy())\n",
    "pred_df = pd.DataFrame(pred.detach().numpy())\n",
    "# Conccaetnate the latents and the predictions\n",
    "z_pred_df = pd.concat([z_df, pred_df], axis=1)\n",
    "z_pred_df.to_csv(latent_file, index=False, header=False) \n",
    "\n",
    "# latents = pd.read_csv(latent_file, header=None, skiprows=None)\n",
    "# data = pd.read_csv(dataset_file)\n",
    "\n",
    "# for i in range(len(latents.columns)):\n",
    "#     data['AE'+ AE_number +'_latent_'+str(i)] = latents[i]\n",
    "\n",
    "# data.to_csv(concatenated_dataset_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba29d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find which 'z'is closest to the 'z' provided below\n",
    "# z_query = torch.tensor([0.26077228, 3.95919058, 0., 0., 0., 0., 1.19784881, 1.33860231], dtype=torch.float32)\n",
    "# z_query = z_query.unsqueeze(dim=0)\n",
    "# z_query = z_query.repeat(z.shape[0], 1)\n",
    "# dist = torch.nn.PairwiseDistance(p=1)\n",
    "# distances = dist(z, z_query)\n",
    "# closest_idx = torch.argmin(distances).item()\n",
    "# print(torch.min(distances))\n",
    "# print(f'Closest z to the query z is at index : {closest_idx}')\n",
    "# print(f'Closest z to the query z is : {z[closest_idx]}')\n",
    "# print(f'Reconst for query z is : {reconst[closest_idx]}')\n",
    "# print(f'INvert scaling for reconst : {scaler_X.inverse_transform(reconst[closest_idx].detach().numpy().reshape(1, -1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor(X_scaled_np32[1, :], requires_grad=True)\n",
    "print(input)\n",
    "baseline = torch.zeros_like(input)\n",
    "print(baseline)\n",
    "print(model(baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee664e",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1fe308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients, DeepLift, InputXGradient, Saliency\n",
    "import seaborn as sns\n",
    "\n",
    "def model_wrapper(input):\n",
    "    # z, pred, reconst = model(input)\n",
    "    z, pred, reconst1, reconst2 = model(input)\n",
    "    return pred\n",
    "\n",
    "# Create an instance of the IntegratedGradients class\n",
    "sal = Saliency(model_wrapper)\n",
    "ig = IntegratedGradients(model_wrapper)\n",
    "ixg = InputXGradient(model_wrapper)\n",
    "dl = DeepLift(model_wrapper)\n",
    "input = torch.cat((torch.from_numpy(X1_scaled_np32), torch.from_numpy(X2_np32)), dim=1)\n",
    "# attr_sal = sal.attribute(input, target=None)\n",
    "# attr_sal_np = attr_sal.detach().numpy()\n",
    "# attr_ixg = ig.attribute(input, baselines=0, target=None)\n",
    "# attr_ixg_np = attr_ixg.detach().numpy()\n",
    "attr_ig = ig.attribute(input, baselines=0, target=-1)\n",
    "attr_ig_np = attr_ig.detach().numpy()\n",
    "# attr_dl = dl.attribute(input, baselines=0, target=None)\n",
    "# attr_dl_np = attr_dl.detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "# # Plot the attributions\n",
    "using_boxplot = False\n",
    "if using_boxplot:\n",
    "    # Label the means on top of the bar in the boxplot\n",
    "    for i in range(attr_ig_np.shape[1]):\n",
    "        # plt.text(i+1, 1.5, '{:0.1f}'.format(np.mean(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "        # Plot the standard deviation\n",
    "        plt.text(i+1, 1.7, '{:0.1f}'.format(np.std(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "    # Plot the means and standard deviations of the attributions for each feature\n",
    "    plt.boxplot(attr_ig_np, showmeans=True, meanline=True)\n",
    "    plt.title('Integrated Gradients calc. wrt pred')\n",
    "    plt.show()\n",
    "else:\n",
    "    means = np.mean(attr_ig_np, axis=0)\n",
    "    std_dev = np.std(attr_ig_np, axis=0)\n",
    "    num_feats = attr_ig_np.shape[1]\n",
    "    # ax.bar(np.arange(num_feats), means, yerr=std_dev, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.scatter(np.arange(num_feats), means, label='mean', color='r', marker='.')\n",
    "    ax.errorbar(np.arange(num_feats), means, yerr=std_dev, fmt='o', capsize=5)\n",
    "    for i in range(attr_ig_np.shape[1]):\n",
    "        # plt.text(i+1, 1.5, '{:0.1f}'.format(np.mean(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "        # Plot the standard deviation\n",
    "        plt.text(i, 0.8, '{:0.1f}'.format(np.std(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "    ax.set_xticks(np.arange(num_feats))\n",
    "    ax.set_xticklabels(descriptors1 + descriptors2, rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "# # Matrix Plot model weights\n",
    "# for name, param in model.encoder.named_parameters():\n",
    "#     if name == 'layers.0.weight':\n",
    "#         ax = plt.figure(figsize=(9, 8))\n",
    "#         ax = sns.heatmap(param.detach().numpy(), annot=True, fmt='.3f', cmap='coolwarm')\n",
    "#         # Remove y axis labels\n",
    "#         ax.yticks([])\n",
    "#         ax.set_title('Encoder Layer 1 Weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95903c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing own version of integrated gradients\n",
    "input = torch.tensor(X_scaled_np32[1, :], requires_grad=True)\n",
    "print(input)\n",
    "baseline = torch.zeros_like(input)\n",
    "print(baseline)\n",
    "def interpolated_features(num_steps):\n",
    "    alphas = torch.linspace(0, 1, num_steps+1)\n",
    "    delta = input - baseline\n",
    "    return torch.stack([baseline + alpha*delta for alpha in alphas])\n",
    "\n",
    "def compute_gradients(interpolated_feats):\n",
    "    grads = []\n",
    "    for i in range(interpolated_feats.shape[0]):\n",
    "        input = interpolated_feats[i]\n",
    "        input = input.unsqueeze(dim=0)\n",
    "        z, pred, reconst = model(input)\n",
    "        print(pred.squeeze(dim=0))\n",
    "        pred.backward()\n",
    "        grads.append(input.grad)\n",
    "        pred = model(interpolated_feats[i].unsqueeze(dim=0))\n",
    "        pred.backward()\n",
    "        grads.append(input.grad)\n",
    "    return torch.stack(grads)\n",
    "\n",
    "computed_grads = compute_gradients(interpolated_features(10))\n",
    "plt.plot(torch.linspace(0, 1, 11), computed_grads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d183b19",
   "metadata": {},
   "source": [
    "#### 2D plots of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d823e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z, pred, reconst, mu, logvar = model(torch.from_numpy(elemental_properties))\n",
    "# z, pred, reconst, mu, logvar, mu_prior, logvar_prior, qy_logit, qy = model(torch.from_numpy(elemental_properties))\n",
    "\n",
    "# # Only for 2D latent plotting\n",
    "# plt.scatter(z[:, 0].detach().numpy(), z[:, 1].detach().numpy(), c=pred.detach().numpy(), cmap='viridis', s=10, alpha=0.5)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aadfbb5",
   "metadata": {},
   "source": [
    "### Observations for Unit normal prior\n",
    "- What we observe from the above example is that although multivariate Gaussian distribution are useful\n",
    "    as each dimension can encode a separate DOF which results in representations that are sturctured and disentangled, \n",
    "    they are unimodal and hence cannot encode complex representations. A natural extension is to then use a different\n",
    "    prior. Gaussain Mixture Model (GMM) is the next choice.\n",
    "- Latent space is segregated into different classes.\n",
    "- However, inference is non-trivial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
