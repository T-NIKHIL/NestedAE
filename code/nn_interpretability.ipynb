{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fc96aa-67d8-4aca-8ff5-77f162088b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 10\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "import copy\n",
    "import joblib\n",
    "import shutil\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "# User defined libraries\n",
    "from utils.custom_utils import set_global_random_seed\n",
    "from utils.dataset_utils import create_preprocessed_datasets\n",
    "# from inputs_3scale_perov_data import nn_inputs, dataset_inputs, train_inputs\n",
    "from inputs_syn_data.dataset_inputs import list_of_nn_datasets_dict\n",
    "from inputs_syn_data.nn_inputs import list_of_nn_params_dict\n",
    "from inputs_syn_data.train_inputs import list_of_nn_train_params_dict\n",
    "\n",
    "seed = 10\n",
    "set_global_random_seed(seed)\n",
    "\n",
    "# Plotting parameters\n",
    "fig_aspect_ratio = 1/1.3\n",
    "# # Font style\n",
    "# plt.rcParams.update({\n",
    "# \"text.usetex\":True,\n",
    "# \"font.family\":\"serif\",\n",
    "# \"font.serif\":[\"Computer Modern Roman\"]})\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.size'] = 5\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 5\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "# Create a Directed Graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "z_labels = ['$z_1$', '$z_2$', '$z_3$', '$z_4$', '$z_5$', '$z_6$', '$z_7$', '$z_8$']\n",
    "f1_labels = ['$f_1$', '$f_2$', '$f_3$', '$f_4$']\n",
    "\n",
    "for z in z_labels:\n",
    "    for f in f1_labels:\n",
    "        G.add_edge(z, f)\n",
    "\n",
    "G.add_edge('$f_1$', '$f_5$')\n",
    "G.add_edge('$f_2$', '$f_5$')\n",
    "G.add_edge('$f_3$', '$f_5$')\n",
    "G.add_edge('$f_4$', '$f_5$')\n",
    "\n",
    "# Create a layout for our nodes \n",
    "pos = {'$z_1$': (1, 1), '$z_2$': (2, 1), '$z_3$': (3, 1), '$z_4$': (4, 1), \n",
    "       '$z_5$': (5, 1), '$z_6$': (6, 1), '$z_7$': (7, 1), '$z_8$': (8, 1),\n",
    "       '$f_1$': (1.5, 2), '$f_2$': (3.5, 2), '$f_3$': (5.5, 2), '$f_4$': (7.5, 2),\n",
    "       '$f_5$': (4.5, 3)}\n",
    "\n",
    "# Draw the graph using the layout\n",
    "nx.draw(G, pos, with_labels=True, arrowsize=15, node_size=1000, font_size=20, node_color='skyblue', font_color='black', font_weight='bold')\n",
    "\n",
    "plt.subplots_adjust(left=0, right=2, top=2, bottom=0)\n",
    "# Save the plot to pdf \n",
    "plt.savefig('multiscale_graph.pdf', dpi=300, bbox_inches='tight', )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4600c",
   "metadata": {},
   "source": [
    "## Model Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276352fd",
   "metadata": {},
   "source": [
    "#### Plotting model performance vs latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cc61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Store the below loss values in .npy arrays and move them to the model directory\n",
    "\n",
    "# For RL paper\n",
    "# # Grid data - UnsupervisedSimpleAE 1\n",
    "# latent_space = [1, 2, 4, 6, 8]\n",
    "# total_val_loss = [0.001025053068588022, 0.001063714546035044, 0.0011066086881328374, 0.0013437549932859838, 0.0009386805177200586]\n",
    "# total_train_loss = [0.007932848995551467, 0.008279352798126638, 0.004237618821207434, 0.004374776501208544, 0.004906855116132647]\n",
    "\n",
    "# # Grid data - Nonlinf5 SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6]\n",
    "# total_val_loss = [0.7463283464312553, 0.2002287097275257, 0.1977713629603386, 0.1788929458707571]\n",
    "# total_train_loss = [0.4705591835081578, 0.14468571869656444, 0.1250611103605479, 0.13816878804937005]\n",
    "\n",
    "# # Grid data - Sumf5 - SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6]\n",
    "# total_val_loss = [0.49156802892684937, 0.019491535145789385, 0.02250012196600437, 0.02030603913590312]\n",
    "# total_train_loss = [0.4140172880142927, 0.03587072214577347, 0.02835194836370647, 0.03037486143875867]\n",
    "\n",
    "# # Random data - UnsupervisedSimpleAE 1\n",
    "# latent_space = [2, 4, 6, 8]\n",
    "# total_val_loss = [0.6480237692594528, 0.4781555384397506, 0.24337586015462875, 0.002268550335429609]\n",
    "# total_train_loss = [0.6661303304135799, 0.4441600125283003, 0.20833437889814377, 0.007954166503623128]\n",
    "\n",
    "# # Random data - Nonlinf5 - SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6, 8, 10, 11, 12]\n",
    "# total_val_loss = [0.7916551381349564, 0.6637141406536102, 0.5525364577770233, 0.3102440983057022, 0.19166426360607147, 0.051493472419679165, 0.021430929424241185, 0.007555923308245838]\n",
    "# total_train_loss = [0.7504490427672863, 0.6266670003533363, 0.4413919039070606, 0.30615816451609135, 0.18379461765289307, 0.05851957411505282, 0.028894496499560773, 0.016192137030884624]\n",
    "\n",
    "# # Random data - Sumf5 - SupervisedSimpleAE 2\n",
    "# # Will have to change the predictor as only prediction loss is high, reconstruction is good.\n",
    "# latent_space = [1, 2, 4, 6, 8, 10, 11, 12]\n",
    "# total_val_loss = [1.4578111469745636, 1.4702374935150146, 1.383190006017685, 1.16259, 0.99866, 0.81431, 0.75846, 0.83324]\n",
    "# total_train_loss = [1.4289479702711103, 1.2744147181510923, 1.0854754857718945, 0.96673, 0.84347, 0.72946, 0.69708, 0.66834]\n",
    "\n",
    "# Arun2024 (Input dim = 15 + 4 = 19)\n",
    "# latent_space =      [2,     4,     6,     8,     10,    12,    14]\n",
    "# pred_val_loss =     [0.206, 0.178, 0.244, 0.227, 0.148, 0.233, 0.231]\n",
    "# pred_train_loss =   [0.11,  0.076, 0.082, 0.067, 0.074, 0.071, 0.067]\n",
    "# recont_val_loss =   [0.561, 0.069, 0.055, 0.050, 0.038, 0.046, 0.056]\n",
    "# recont_train_loss = [0.234, 0.055, 0.037, 0.038, 0.037, 0.042, 0.039]\n",
    "# total_val_loss = [0.76786, 0.24755343379718917, \t0.24418, 0.27646, 0.18622, 0.27943, 0.28719]\n",
    "# total_train_loss = [0.38542, 0.16735203887741917, \t0.15132, 0.13772, 0.14288, 0.14528, 0.13803]\n",
    "\n",
    "# for 10 this is the best that can be done. Adding more layers or increasing the hidden dim or using non linea act does not work.\n",
    "# val : 0.7632711380720139\n",
    "# train : 0.7363427169620991\n",
    "run_dir = 'results_for_RL_paper'\n",
    "train_loss_matrix_path = f'../runs/{run_dir}/SupSimpleAE_2_ldim10_randomData_nonlinf5/train_total_loss.npy'\n",
    "val_loss_matrix_path = f'../runs/{run_dir}/SupSimpleAE_2_ldim10_randomData_nonlinf5/val_total_loss.npy'\n",
    "\n",
    "train_loss_matrix = np.load(train_loss_matrix_path)\n",
    "val_loss_matrix = np.load(val_loss_matrix_path)\n",
    "train_mean_losses = np.mean(train_loss_matrix, axis=0)\n",
    "train_std_losses = np.std(train_loss_matrix, axis=0)\n",
    "val_mean_losses = np.mean(val_loss_matrix, axis=0)\n",
    "val_std_losses = np.std(val_loss_matrix, axis=0)\n",
    "\n",
    "latent_space_to_sweep = [2, 4, 6, 8, 10, 12]\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Plot the latent space vs total validation loss\n",
    "plt.errorbar(latent_space_to_sweep, train_mean_losses, yerr=train_std_losses, label='train', marker='o', linestyle='-')\n",
    "plt.errorbar(latent_space_to_sweep, val_mean_losses, yerr=val_std_losses, label='val', marker='o', linestyle='-')\n",
    "# # Label the mean values on top with red color\n",
    "# for i, txt in enumerate(val_mean_losses):\n",
    "#     # plt.annotate(f'{txt:.3f}', (latent_space_to_sweep[i], val_mean_losses[i]), textcoords=\"offset points\", xytext=(0,15), ha='center', color='r')\n",
    "#     print(f'{latent_space_to_sweep[i]} : Val Std dev. : {val_std_losses[i]}')  \n",
    "#     print(f'{latent_space_to_sweep[i]} : Val Mean : {val_mean_losses[i]}')\n",
    "# for i, txt in enumerate(train_mean_losses):\n",
    "#     # plt.annotate(f'{txt:.3f}', (latent_space_to_sweep[i], train_mean_losses[i]), textcoords=\"offset points\", xytext=(0,-15), ha='center', color='b')\n",
    "#     print(f'{latent_space_to_sweep[i]} : Train Std dev. : {train_std_losses[i]}')  \n",
    "#     print(f'{latent_space_to_sweep[i]} : Train Mean : {train_mean_losses[i]}')\n",
    "# plt.plot(latent_space, total_train_loss, marker='o', linestyle='', label='train')\n",
    "# plt.plot(latent_space, total_val_loss, marker='o', linestyle='', label='val')\n",
    "plt.xlabel('Latent space dimension')\n",
    "plt.xticks(latent_space_to_sweep)\n",
    "# Set the tick labels\n",
    "plt.ylabel('Total MAE (Reconst. + Pred.)')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the subplot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('latent_space_vs_total_loss.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52d60a",
   "metadata": {},
   "source": [
    "#### Loading the torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "                'input_dim':{\n",
    "                    'value':X1_final.shape[1]\n",
    "                },\n",
    "                'hidden_dim':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'latent_dim':{\n",
    "                    'value':10\n",
    "                },\n",
    "                'y_dim':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'dropout':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'l1_reg':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'l2_reg':{\n",
    "                    'value':0.001\n",
    "                },\n",
    "                'num_layers':{\n",
    "                    'value':1\n",
    "                },\n",
    "                'activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'dec_activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'pred_activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'batch_size':{\n",
    "                    'value':10\n",
    "                },\n",
    "                'learning_rate':{\n",
    "                    'value':1e-3\n",
    "                },\n",
    "                'epochs':{\n",
    "                    'value':1500\n",
    "                }\n",
    "}\n",
    "\n",
    "# Load torch model\n",
    "ldim = parameters['latent_dim']['value']\n",
    "# model_name = f'{ae_name}_ldim{ldim}_{dataset_name}'\n",
    "# model_name = 'UnsupSimpleAE_3_ldim12_peroveff2_device_none_3_75_e2000'\n",
    "# model_name = 'SupSimpleAE_2_ldim2_gridData_nonlinf5'\n",
    "# model_name = 'best_SupSimpleAE_2_ldim2_gridData_sumf5'\n",
    "model_name = 'SupSimpleAE_2_ldim10_randomData_sumf5'\n",
    "run_dir = 'results_for_RL_paper'\n",
    "model_type = 'SupervisedSimpleAE'\n",
    "model_path = f'../runs/{run_dir}/{model_name}/' + model_name + '.pth'\n",
    "if model_type == 'UnsupervisedSimpleAE':\n",
    "    model = UnsupervisedSimpleAE(parameters['input_dim']['value'],\n",
    "                                parameters['hidden_dim']['value'], \n",
    "                                parameters['dropout']['value'], \n",
    "                                parameters['latent_dim']['value'], \n",
    "                                parameters['num_layers']['value'], \n",
    "                                parameters['activation_fn']['value'],\n",
    "                                parameters['dec_activation_fn']['value'])\n",
    "elif model_type == 'SupervisedSimpleAE':\n",
    "    model = SupervisedSimpleAE(parameters['input_dim']['value'],\n",
    "                                parameters['hidden_dim']['value'], \n",
    "                                parameters['dropout']['value'], \n",
    "                                parameters['latent_dim']['value'], \n",
    "                                parameters['num_layers']['value'], \n",
    "                                parameters['activation_fn']['value'],\n",
    "                                parameters['pred_activation_fn']['value'],\n",
    "                                parameters['dec_activation_fn']['value'])\n",
    "elif model_type == 'VAE':\n",
    "    model = UnsupervisedVAE(parameters['input_dim']['value'],\n",
    "                            parameters['hidden_dim']['value'], \n",
    "                            parameters['dropout']['value'], \n",
    "                            parameters['latent_dim']['value'], \n",
    "                            parameters['num_layers']['value'], \n",
    "                            parameters['activation_fn']['value'])\n",
    "elif model_type == 'GMVAE':\n",
    "    model = GMVAE(parameters['input_dim']['value'],\n",
    "                parameters['y_dim']['value'],\n",
    "                parameters['hidden_dim']['value'], \n",
    "                parameters['dropout']['value'], \n",
    "                parameters['latent_dim']['value'], \n",
    "                parameters['num_layers']['value'], \n",
    "                parameters['activation_fn']['value'])\n",
    "else:\n",
    "    pass\n",
    "# print(torch.load(model_path))\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce370e",
   "metadata": {},
   "source": [
    "#### Save the latents to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the latents to .csv file\n",
    "# z, pred, _, _ = model(torch.cat((torch.from_numpy(X1_final), torch.from_numpy(X2_final)), dim=1))\n",
    "z, _, _, _, _ = model(torch.concat((torch.from_numpy(X1_final), torch.from_numpy(X2_final), torch.from_numpy(X3_final), torch.from_numpy(X4_final)), dim=1))\n",
    "latent_filename = f'latents_from_{dataset_name}'\n",
    "\n",
    "# Data folder paths and file names\n",
    "dataset_folder_name = 'synthetic_dataset'\n",
    "dataset_file_name = 'synthetic_data_gridSamples_200_sumf5.csv'\n",
    "new_dataset_file_name = 'synthetic_data_gridSamples_200_sumf5_with_ae1_latents_concat.csv'\n",
    "run_folder_name = 'perovskite_multiscale_dataset_v2'\n",
    "model_folder_name = 'best_SupSimpleAE_1_ldim4_arun2024'\n",
    "AE_number = '1'\n",
    "\n",
    "dataset_folder = '../datasets/' + dataset_folder_name\n",
    "dataset_file = dataset_folder + '/' + dataset_file_name\n",
    "concatenated_dataset_file = dataset_folder + '/' + new_dataset_file_name\n",
    "\n",
    "run_folder = '../runs/' + run_dir\n",
    "latent_file = run_folder + '/' + model_name + '/' + latent_filename + '.csv'\n",
    "\n",
    "# Save the latents to .csv file\n",
    "z_df = pd.DataFrame(z.detach().numpy())\n",
    "# pred_df = pd.DataFrame(pred.detach().numpy())\n",
    "# Conccaetnate the latents and the predictions\n",
    "# z_pred_df = pd.concat([z_df, pred_df], axis=1)\n",
    "# z_pred_df = pd.DataFrame(z.detach().numpy())\n",
    "z_df.to_csv(latent_file, index=False, header=False) \n",
    "\n",
    "# latents = pd.read_csv(latent_file, header=None, skiprows=None)\n",
    "# data = pd.read_csv(dataset_file)\n",
    "\n",
    "# for i in range(len(latents.columns)):\n",
    "#     data['AE'+ AE_number +'_latent_'+str(i)] = latents[i]\n",
    "\n",
    "# data.to_csv(concatenated_dataset_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba29d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find which 'z'is closest to the 'z' provided below\n",
    "# z_query = torch.tensor([0.26077228, 3.95919058, 0., 0., 0., 0., 1.19784881, 1.33860231], dtype=torch.float32)\n",
    "# z_query = z_query.unsqueeze(dim=0)\n",
    "# z_query = z_query.repeat(z.shape[0], 1)\n",
    "# dist = torch.nn.PairwiseDistance(p=1)\n",
    "# distances = dist(z, z_query)\n",
    "# closest_idx = torch.argmin(distances).item()\n",
    "# print(torch.min(distances))\n",
    "# print(f'Closest z to the query z is at index : {closest_idx}')\n",
    "# print(f'Closest z to the query z is : {z[closest_idx]}')\n",
    "# print(f'Reconst for query z is : {reconst[closest_idx]}')\n",
    "# print(f'INvert scaling for reconst : {scaler_X.inverse_transform(reconst[closest_idx].detach().numpy().reshape(1, -1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor(X_scaled_np32[1, :], requires_grad=True)\n",
    "print(input)\n",
    "baseline = torch.zeros_like(input)\n",
    "print(baseline)\n",
    "print(model(baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee664e",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9a2f2",
   "metadata": {},
   "source": [
    "##### 1. Using Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1fe308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients, DeepLift, InputXGradient, Saliency\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def model_wrapper(input):\n",
    "    z, pred, reconst = model(input)\n",
    "    # z, pred, reconst1, reconst2 = model(input)\n",
    "    # z, recon1, recon2, recon3, recon4 = model(input)\n",
    "    return pred\n",
    "\n",
    "# Create an instance of the IntegratedGradients class\n",
    "sal = Saliency(model_wrapper)\n",
    "ig = IntegratedGradients(model_wrapper)\n",
    "ixg = InputXGradient(model_wrapper)\n",
    "dl = DeepLift(model_wrapper)\n",
    "\n",
    "input = torch.from_numpy(X1_final)\n",
    "# input = torch.cat((torch.from_numpy(X1_scaled_np32), torch.from_numpy(X2_np32)), dim=1)\n",
    "# input = torch.concat((torch.from_numpy(X1_final), torch.from_numpy(X2_final), torch.from_numpy(X3_final), torch.from_numpy(X4_final)), dim=1)\n",
    "\n",
    "# attr_sal = sal.attribute(input, target=None)\n",
    "# attr_sal_np = attr_sal.detach().numpy()\n",
    "# attr_ixg = ig.attribute(input, baselines=0, target=None)\n",
    "# attr_ixg_np = attr_ixg.detach().numpy()\n",
    "attr_ig = ig.attribute(input, baselines=0, target=None)\n",
    "attr_ig_np = attr_ig.detach().numpy()\n",
    "# attr_dl = dl.attribute(input, baselines=0, target=None)\n",
    "# attr_dl_np = attr_dl.detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "# # Plot the attributions\n",
    "using_boxplot = True\n",
    "if using_boxplot:\n",
    "    # Label the means on top of the bar in the boxplot\n",
    "    for i in range(attr_ig_np.shape[1]):\n",
    "        # plt.text(i+1, 1.5, '{:0.1f}'.format(np.mean(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "        # Plot the standard deviation\n",
    "        plt.text(i+1, 1.6, '{:0.1f}'.format(np.std(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "    # Plot the means and standard deviations of the attributions for each feature\n",
    "    plt.boxplot(attr_ig_np, showmeans=True, meanline=True)\n",
    "    ax.set_xticklabels(descriptors1, rotation=90)\n",
    "    plt.title('Integrated Gradients calc. wrt pred')\n",
    "    plt.show()\n",
    "else:\n",
    "    means = np.mean(attr_ig_np, axis=0)\n",
    "    std_dev = np.std(attr_ig_np, axis=0)\n",
    "    num_feats = attr_ig_np.shape[1]\n",
    "    # ax.bar(np.arange(num_feats), means, yerr=std_dev, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.scatter(np.arange(num_feats), means, label='mean', color='r', marker='.')\n",
    "    ax.errorbar(np.arange(num_feats), means, yerr=std_dev, fmt='o', capsize=5)\n",
    "    for i in range(attr_ig_np.shape[1]):\n",
    "        # plt.text(i+1, 1.5, '{:0.1f}'.format(np.mean(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "        # Plot the standard deviation\n",
    "        plt.text(i, 0.8, '{:0.1f}'.format(np.std(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "    ax.set_xticks(np.arange(num_feats))\n",
    "    # descriptors = ['DMF', 'DMF; DMSO', 'DMSO', 'DMSO; GBL', \n",
    "    #                '1', '1; 1', '1; 4', '2; 1', '3; 1', '3; 7', '4; 1', '7; 3',\n",
    "    #                '8; 1', '9; 1', 'Anisole', 'Chlorobenzene', 'Diethyl ether', \n",
    "    #                'Ethyl acetate', 'N2', 'Toluene', \n",
    "    #                'AE1_latent_0', 'AE1_latent_1', 'AE1_latent_2', 'AE1_latent_3']\n",
    "    descriptors = ['PET | ITO', 'SLG | FTO', 'SLG | ITO', \n",
    "                   'NiO-c', 'PEDOT:PSS', 'PTAA', 'Spiro-MeOTAD',\n",
    "                   'C60 | BCP', 'PCBM-60', 'PCBM-60 | BCP', 'PCBM-60 | ZnO-np',\n",
    "                   'SnO2-c', 'SnO2-np', 'TiO2-c', 'TiO2-c | TiO2-mp',\n",
    "                   'AE2_latent_0', 'AE2_latent_1', 'AE2_latent_2', 'AE2_latent_3',\n",
    "                   'AE2_latent_4', 'AE2_latent_5', 'AE2_latent_6', 'AE2_latent_7']\n",
    "    ax.set_xticklabels(descriptors, rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "# # Matrix Plot model weights\n",
    "# for name, param in model.encoder.named_parameters():\n",
    "#     if name == 'layers.0.weight':\n",
    "#         ax = plt.figure(figsize=(9, 8))\n",
    "#         ax = sns.heatmap(param.detach().numpy(), annot=True, fmt='.3f', cmap='coolwarm')\n",
    "#         # Remove y axis labels\n",
    "#         ax.yticks([])\n",
    "#         ax.set_title('Encoder Layer 1 Weights')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f252e",
   "metadata": {},
   "source": [
    "##### 2. Pearson Correlation Coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7be71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_wrapper(input):\n",
    "    z, pred, reconst = model(input)\n",
    "    # z, pred, reconst1, reconst2 = model(input)\n",
    "    # z, recon1, recon2, recon3, recon4 = model(input)\n",
    "    return pred\n",
    "\n",
    "\n",
    "pred = model_wrapper(torch.from_numpy(X1_final))\n",
    "corrcoefs = np.corrcoef(X1_final, y=pred.detach().numpy(), rowvar=False)\n",
    "\n",
    "# In the corr coefs change all values that lie between +- threhold to 0\n",
    "threshold = 0.1\n",
    "corrcoefs[np.abs(corrcoefs) < threshold] = 0\n",
    "\n",
    "# Make a color bar with 0 value as dark gray\n",
    "# cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "# cmap.set_bad(color='black')\n",
    "import matplotlib.colors as colors\n",
    "cmap = colors.LinearSegmentedColormap.from_list('mycmap', ['blue', 'gray', 'red'])\n",
    "norm = colors.Normalize(vmin=-1, vmax=1)\n",
    "\n",
    "# Matrix plot of corr coefs \n",
    "# plt.figure(figsize=(12,10))\n",
    "# Set figure size in inches\n",
    "plt.figure(figsize=(5, 3.85))\n",
    "\n",
    "sns.heatmap(corrcoefs, annot=False, cmap=cmap, norm=norm, fmt='.2f', annot_kws={\"color\": 'black', 'size':1})\n",
    "plt.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "\n",
    "plt.gca().xaxis.tick_top()\n",
    "\n",
    "plt.xticks(np.arange(X1_final.shape[1] + 1) + 0.5, labels=descriptors1 + ['f5_pred'], rotation=90)\n",
    "plt.yticks(np.arange(X1_final.shape[1] + 1) + 0.5, labels=descriptors1 + ['f5_pred'], rotation=0)\n",
    "\n",
    "#Adjust subplot size\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to pdf\n",
    "plt.savefig('corr_coefs.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd2c57",
   "metadata": {},
   "source": [
    "##### 3. Using kernel SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.vanilla_ae import VanillaAE\n",
    "from utils.custom_utils import read_from_pickle\n",
    "from inputs_perov_data.nn_inputs import list_of_nn_params_dict\n",
    "from inputs_perov_data.train_inputs import list_of_nn_train_params_dict\n",
    "from inputs_perov_data.dataset_inputs import list_of_nn_datasets_dict\n",
    "\n",
    "ae = 1\n",
    "\n",
    "ae_index = int(ae) - 1\n",
    "\n",
    "run_dir = '../runs/perovskite_multiscale_dataset_3'\n",
    "\n",
    "# # Read the ae params, train params and datasets\n",
    "# list_of_nn_params_dict = read_from_pickle('list_of_nn_params_dict.pkl', run_dir)\n",
    "# list_of_nn_train_params_dict = read_from_pickle('list_of_nn_train_params_dict.pkl', run_dir)\n",
    "# list_of_nn_datasets_dict = read_from_pickle('list_of_nn_datasets_dict.pkl', run_dir)\n",
    "\n",
    "nn_params_dict = list_of_nn_params_dict[ae_index]\n",
    "nn_train_params_dict = list_of_nn_train_params_dict[ae_index]\n",
    "nn_datasets_dict = list_of_nn_datasets_dict[ae_index]\n",
    "\n",
    "global_seed = nn_train_params_dict['global_seed']\n",
    "\n",
    "nn_save_dir = run_dir + '/' + nn_params_dict['model_type']\n",
    "print(nn_save_dir)\n",
    "\n",
    "ae = VanillaAE(nn_save_dir,\n",
    "                nn_params_dict,\n",
    "                nn_train_params_dict,\n",
    "                nn_datasets_dict)\n",
    "\n",
    "# Load model from checkpoint \n",
    "checkpoint_path = nn_save_dir + '/checkpoints/epoch=1188-total_val_loss=0.15.ckpt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "ae.load_from_checkpoint(checkpoint_path)\n",
    "ae.train(mode=False)\n",
    "\n",
    "def model_wrapper(input):\n",
    "    torch_input = torch.from_numpy(input)\n",
    "    input = {'all_props':torch_input}\n",
    "    submodule_outputs = ae(input)\n",
    "    pred = submodule_outputs['bg_pred'].detach().numpy()\n",
    "    return pred\n",
    "\n",
    "# # Load the training dataset\n",
    "# train_dataset_path = nn_save_dir + '/datasets/train_dataset.pt'\n",
    "# train_dataset = torch.load(train_dataset_path)\n",
    "# train_dataset_np = train_dataset[:]['all_props'].detach().numpy()\n",
    "\n",
    "# predict_dataset_path = nn_save_dir + '/datasets/predict_dataset.pt'\n",
    "# predict_dataset = torch.load(predict_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de75bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 200\n",
    "ground_truth_bg = ae.all_samples['bg'][sample_idx]\n",
    "print(ae.all_samples['all_props'][sample_idx].detach().numpy())\n",
    "model_pred_bg = model_wrapper(ae.all_samples['all_props'][sample_idx].detach().numpy())\n",
    "print(f'Ground truth bg : {ground_truth_bg}')\n",
    "print(f'Model predicted bg : {model_pred_bg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the inputs into one dataset, if only one input then skip\n",
    "combined = False\n",
    "background_dataset_gen = 'all_samples' # 'kmeans' or 'all_samples'\n",
    "# descriptors1 = ['A_ion_rad', 'A_at_wt', 'A_EA', 'A_IE', 'A_En',\n",
    "#                 'B_ion_rad', 'B_at_wt', 'B_EA', 'B_IE', 'B_En',\n",
    "#                 'X_ion_rad', 'X_at_wt', 'X_EA', 'X_IE', 'X_En']\n",
    "# descriptors2=['AE1_l0', 'AE1_l1', 'AE1_l2', 'AE1_l3', 'AE1_l4', 'AE1_l5', \n",
    "#                  'AE1_l6', 'AE1_l7', 'AE1_l8', 'AE1_l9', 'AE1_l10', 'AE1_l11']+\\\n",
    "#                 list(ae.datasets.variable_preprocessors['etm'].categories_[0]) +\\\n",
    "#                 list(ae.datasets.variable_preprocessors['htm'].categories_[0])\n",
    "\n",
    "# if combined:    \n",
    "#     dataset = torch.concat((ae.all_samples['latents'], ae.all_samples['etm'], ae.all_samples['htm']), dim=1)\n",
    "# else:\n",
    "#     dataset = ae.all_samples['all_props']\n",
    "\n",
    "dataset = X1_final\n",
    "\n",
    "# Using kmeans to cluster the data\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if background_dataset_gen == 'kmeans':\n",
    "    krange = np.arange(1, 10)\n",
    "    inertia = np.zeros(len(krange))\n",
    "\n",
    "    for k in krange:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto').fit(dataset)\n",
    "        if k == krange[-1]:\n",
    "            background_dataset = kmeans.cluster_centers_\n",
    "            # Change dtypes to np.float32\n",
    "            background_dataset = background_dataset.astype(np.float32)\n",
    "        inertia[k-1] = kmeans.inertia_\n",
    "    \n",
    "    # Plot elbow plot\n",
    "    plt.plot(krange, inertia, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "elif background_dataset_gen == 'all_samples':\n",
    "    # X100 = shap.utils.sample(combined_dataset.detach().numpy(), 100)\n",
    "    # background_dataset = shap.utils.sample(ae.all_samples['all_props'].detach().numpy(), len(ae.all_samples['all_props']))\n",
    "    background_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebfce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_explainer = shap.KernelExplainer(model_wrapper, data=background_dataset, link='identity', feature_names=descriptors1)\n",
    "shap_values = kernel_explainer.shap_values(dataset.detach().numpy())\n",
    "shap_values = np.squeeze(shap_values, axis=-1)\n",
    "shap.initjs()\n",
    "                \n",
    "shap.summary_plot(shap_values, features=dataset.detach().numpy(), feature_names=descriptors1, max_display=10, plot_type='dot', show=False, plot_size=(5.8, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137757f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plots for individual preeictions\n",
    "sample_idx = 0\n",
    "sample = ae.datasets.variable_preprocessors['all_props'].inverse_transform(ae.all_samples['all_props'][sample_idx].detach().numpy().reshape(1, -1))\n",
    "print(sample)\n",
    "# shap.plots.force(kernel_explainer.expected_value, shap_values[sample_idx], features=sample, feature_names=descriptors1)\n",
    "ground_truth_bg = ae.all_samples['bg'][sample_idx]\n",
    "model_pred_bg = model_wrapper(ae.all_samples['all_props'][sample_idx].detach().numpy())\n",
    "print(f'Ground truth bg : {ground_truth_bg}')\n",
    "print(f'Model predicted bg : {model_pred_bg}')\n",
    "shap.plots.force(kernel_explainer.expected_value, shap_values[sample_idx], features=sample, feature_names=descriptors1, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "descriptors1 = ['f1', 'f2', 'f3', 'f4', \n",
    "               'AE1_latent_0', 'AE1_latent_1', 'AE1_latent_2', 'AE1_latent_3',\n",
    "               'AE1_latent_4', 'AE1_latent_5', 'AE1_latent_6', 'AE1_latent_7']\n",
    "\n",
    "class modelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(modelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "    def forward(self, input):\n",
    "        # For kenrnal explainer\n",
    "        input = torch.from_numpy(input)\n",
    "        z, pred, reconst = self.model(input)\n",
    "        pred = pred.detach().numpy()\n",
    "        return pred\n",
    "    \n",
    "model_wrapper = modelWrapper(model)\n",
    "\n",
    "# explainer = shap.Explainer(model_wrapper, X100)\n",
    "kernel_explainer = shap.KernelExplainer(model=model_wrapper, data=background_dataset, link='identity', feature_names=descriptors1)\n",
    "# gradient_explainer = shap.GradientExplainer(model_wrapper, torch.from_numpy(X100))\n",
    "# deep_explainer = shap.DeepExplainer(model_wrapper, torch.from_numpy(X100))\n",
    "\n",
    "# Shaplye values for all the points in the dataset\n",
    "shap_values = kernel_explainer.shap_values(X1_final)\n",
    "# shap_values = explainer(X100)\n",
    "# shap_values = gradient_explainer.shap_values(torch.from_numpy(X100))\n",
    "# shap_values = deep_explainer.shap_values(torch.from_numpy(X100))\n",
    "shap_values = np.squeeze(shap_values, axis=-1)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "# Save the SHAP summary plot to pdf\n",
    "\n",
    "# For displaying for multiple samples. show=False is required to save the plot as a matplotlib figure\n",
    "shap.summary_plot(shap_values, features=X1_final, feature_names=descriptors1, max_display=10, plot_type='dot', show=False, plot_size=(5.8, 3.5))\n",
    "\n",
    "# plt.savefig('SHAP_summary_plot.pdf')\n",
    "\n",
    "# Explaining a single prediction\n",
    "# shap.waterfall_plot(shap.Explanation(values=shap_values[1], base_values=0, data=X1_final[1], feature_names=descriptors1))\n",
    "\n",
    "# Requires an explanation object to be passed\n",
    "# shap.plots.bar(shap.Explanation(values=shap_values[:], base_values=0, data=X1_final[:], feature_names=descriptors1))\n",
    "# shap.force_plot(kernel_explainer.expected_value, shap_values, descriptors1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95903c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing own version of integrated gradients\n",
    "input = torch.tensor(X_scaled_np32[1, :], requires_grad=True)\n",
    "print(input)\n",
    "baseline = torch.zeros_like(input)\n",
    "print(baseline)\n",
    "def interpolated_features(num_steps):\n",
    "    alphas = torch.linspace(0, 1, num_steps+1)\n",
    "    delta = input - baseline\n",
    "    return torch.stack([baseline + alpha*delta for alpha in alphas])\n",
    "\n",
    "def compute_gradients(interpolated_feats):\n",
    "    grads = []\n",
    "    for i in range(interpolated_feats.shape[0]):\n",
    "        input = interpolated_feats[i]\n",
    "        input = input.unsqueeze(dim=0)\n",
    "        z, pred, reconst = model(input)\n",
    "        print(pred.squeeze(dim=0))\n",
    "        pred.backward()\n",
    "        grads.append(input.grad)\n",
    "        pred = model(interpolated_feats[i].unsqueeze(dim=0))\n",
    "        pred.backward()\n",
    "        grads.append(input.grad)\n",
    "    return torch.stack(grads)\n",
    "\n",
    "computed_grads = compute_gradients(interpolated_features(10))\n",
    "plt.plot(torch.linspace(0, 1, 11), computed_grads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d183b19",
   "metadata": {},
   "source": [
    "#### 2D plots of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d823e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z, pred, reconst, mu, logvar = model(torch.from_numpy(elemental_properties))\n",
    "# z, pred, reconst, mu, logvar, mu_prior, logvar_prior, qy_logit, qy = model(torch.from_numpy(elemental_properties))\n",
    "\n",
    "# # Only for 2D latent plotting\n",
    "# plt.scatter(z[:, 0].detach().numpy(), z[:, 1].detach().numpy(), c=pred.detach().numpy(), cmap='viridis', s=10, alpha=0.5)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aadfbb5",
   "metadata": {},
   "source": [
    "### Observations for Unit normal prior\n",
    "- What we observe from the above example is that although multivariate Gaussian distribution are useful\n",
    "    as each dimension can encode a separate DOF which results in representations that are sturctured and disentangled, \n",
    "    they are unimodal and hence cannot encode complex representations. A natural extension is to then use a different\n",
    "    prior. Gaussain Mixture Model (GMM) is the next choice.\n",
    "- Latent space is segregated into different classes.\n",
    "- However, inference is non-trivial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
