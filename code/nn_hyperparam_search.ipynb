{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fc96aa-67d8-4aca-8ff5-77f162088b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "import copy\n",
    "import joblib\n",
    "import shutil\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "from wandb_api_key import api_key\n",
    "from utils.custom_utils import set_global_random_seed\n",
    "from utils.dataset_utils import create_preprocessed_datasets\n",
    "\n",
    "inputs_dir = 'inputs_syn_grid_lin_data'\n",
    "run_dir = 'syn_grid_lin_data'\n",
    "nn = 1\n",
    "mode = 'train'\n",
    "accelerator = 'cpu'\n",
    "kfolds =  5\n",
    "\n",
    "# Login to wandb. Create a wandb account and get the api key from the user settings tab\n",
    "user_name = 'nthota2'\n",
    "project_name = 'results_for_RL_paper'\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = 'hyperparam_search.ipynb'\n",
    "os.environ[\"WANDB_API_KEY\"] = api_key\n",
    "# dryrun = Does not store any weights and bias data locally\n",
    "# online = enables cloud syncing\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "\n",
    "# Plotting parameters\n",
    "fig_aspect_ratio = 1/1.3\n",
    "\n",
    "# # Font style\n",
    "# plt.rcParams.update({\n",
    "# \"text.usetex\":True,\n",
    "# \"font.family\":\"serif\",\n",
    "# \"font.serif\":[\"Computer Modern Roman\"]})\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.size'] = 5\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 5\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b24447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a run directory in '../runs' to store the training results\n",
    "if not os.path.exists(f'../runs/{run_dir}'):\n",
    "    os.makedirs(f'../runs/{run_dir}')\n",
    "# Find the inputs directory and import the dataset_inputs.py and train_inputs.py files\n",
    "sys.path.append(inputs_dir)\n",
    "from dataset_inputs import list_of_nn_datasets_dict\n",
    "from train_inputs import list_of_nn_train_params_dict\n",
    "# Go back to the original directory\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5a329",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "# Create a Directed Graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "z_labels = ['$z_1$', '$z_2$', '$z_3$', '$z_4$', '$z_5$', '$z_6$', '$z_7$', '$z_8$']\n",
    "f1_labels = ['$f_1$', '$f_2$', '$f_3$', '$f_4$']\n",
    "\n",
    "for z in z_labels:\n",
    "    for f in f1_labels:\n",
    "        G.add_edge(z, f)\n",
    "\n",
    "G.add_edge('$f_1$', '$f_5$')\n",
    "G.add_edge('$f_2$', '$f_5$')\n",
    "G.add_edge('$f_3$', '$f_5$')\n",
    "G.add_edge('$f_4$', '$f_5$')\n",
    "\n",
    "# Create a layout for our nodes \n",
    "pos = {'$z_1$': (1, 1), '$z_2$': (2, 1), '$z_3$': (3, 1), '$z_4$': (4, 1), \n",
    "       '$z_5$': (5, 1), '$z_6$': (6, 1), '$z_7$': (7, 1), '$z_8$': (8, 1),\n",
    "       '$f_1$': (1.5, 2), '$f_2$': (3.5, 2), '$f_3$': (5.5, 2), '$f_4$': (7.5, 2),\n",
    "       '$f_5$': (4.5, 3)}\n",
    "\n",
    "# Draw the graph using the layout\n",
    "nx.draw(G, pos, with_labels=True, arrowsize=15, node_size=1000, font_size=20, node_color='skyblue', font_color='black', font_weight='bold')\n",
    "\n",
    "plt.subplots_adjust(left=0, right=2, top=2, bottom=0)\n",
    "# Save the plot to pdf \n",
    "plt.savefig('multiscale_graph.pdf', dpi=300, bbox_inches='tight', )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32406c3",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a700ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the simple autoencoder\n",
    "randX = torch.rand(2, 2)\n",
    "# self, input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn\n",
    "simple_ae = UnsupervisedSimpleAE(15, 10, 0.01, 2, 3, 'tanh', None)\n",
    "print(simple_ae.decoder(randX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d1ec",
   "metadata": {},
   "source": [
    "### Deriving the KL divergence loss for unit normal prior\n",
    "\n",
    "- Lets start with any arbitrary distribution Q(z) and minimize the KL divergence of it with a distribution P(z|X)\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    D_{KL}(Q(z) || P(z|X)) & = \\int Q(z) \\log \\frac{Q(z)}{P(z|X)} dz \\\\ \\\\\n",
    "    D_{KL}(Q(z) || P(z|X)) & = E_{Q(z)}[ \\log \\frac{Q(z)}{P(z|X)} ] \\\\ \\\\\n",
    "    D_{KL}(Q(z) || P(z|X)) & = E_{Q(z)}[ \\log Q(z) - \\log P(z|X) ] \\\\ \\\\\n",
    "    D_{KL}(Q(z) || P(z|X)) & = E_{Q(z)}[ \\log Q(z) - \\log P(X|z) - \\log P(z) + \\log P(X) ] \\\\ \\\\\n",
    "    D_{KL}(Q(z) || P(z|X)) & = E_{Q(z)}[ \\log Q(z) - \\log P(X|z) - \\log P(z)] + \\log P(X) \\\\ \\\\\n",
    "    \\log P(X) - D_{KL}(Q(z) || P(z|X)) & =  E_{Q(z)}[\\log P(X|z)] - D_{KL}(Q(z) || P(z)) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- Now instead of choosing any distribution for Q(z), it makes sense to choose a distribution for the z variables that depends on X. Hence we can replace Q(z) with Q(z|X).\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\log P(X) - D_{KL}(Q(z|X) || P(z|X)) & =  E_{Q(z|X)}[\\log P(X|z)] - D_{KL}(Q(z|X) || P(z))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- The left hand side contains the terms that we want to maximize. The log probability density of X and an error term that measures the deviation between the approximate distribution (Q(z|X)) and the true probability distribution (P(z|X)). To note P(X) is a high dimensional intractable distribution and we don't have access to P(z|X). By having a large enough capacity for Q(z|X) we are pulling it closer to P(z|X), lower the KL divergence term until we are only optimizing for the log probability density of X. \n",
    "- The right hand side contains terms that can be optimized via gradient descent. The first term is the expected value of the log likelihood of the data given the latent variables. The second term is the KL divergence between the approximate distribution and the prior distribution. \n",
    "- Stochastic gradient descent can be performed on the right hand side by assuming some forms of the distribution. The most common form for the posterior and liklihood is a multivariate Gaussian distribution and for the prior is unit normal distribution. \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    D_{KL}(N(\\mu_0, \\Sigma_0) || N(\\mu_1, \\Sigma_1)) = \\frac{1}{2} ( \\text{tr}(\\Sigma_1^{-1} \\Sigma_0) + (\\mu_1 - \\mu_0)^T \\Sigma_1^{-1} (\\mu_1 - \\mu_0) - k + \\log \\frac{\\det \\Sigma_1}{\\det \\Sigma_0} )\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- 'k' is the dimensionality of the distribution. Substituting the prior as unit normal distribution, we get the KL divergence loss as\n",
    "$$\n",
    "\\begin{align*}\n",
    "    D_{KL}(N(\\mu (X), \\Sigma (X)) || N(O, I)) = \\frac{1}{2} ( \\text{tr}(\\Sigma (X)) + (\\mu (X))^T (\\mu (X)) - k - \\log \\det \\Sigma (X) )\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- To back propagate the errors to the the neural network that approximates Q(z|X), so that we get z's that correctly reproduce the data, we need to find a way that allows backpropagation to work. This is where the reparameterization trick comes in. It allows us to sample for 'z' while giving access to the neural networks that approximate the mean and covariance functions for  Q(z|X). $ z = \\mu (X) + \\Sigma (X) * \\epsilon $. Here $\\mu (X) and \\Sigma (X)$ are approximated by using neural networks and $\\epsilon$ is sampled from the unit normal distribution.\n",
    "- If any other distribution is to be modelled then the KL divergnce term must be modified accordingly and the appropriate reparameterization trick must be used.\n",
    "\n",
    "Reference:\n",
    "- Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014 https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "- Doersch, C. Tutorial on Variational Autoencoders. arXiv January 3, 2021. http://arxiv.org/abs/1606.05908.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cfc68",
   "metadata": {},
   "source": [
    "## Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf96a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "def log_normal(z, mu, logvar):\n",
    "    c = torch.tensor(2*np.pi, dtype=torch.float32) \n",
    "    return torch.tensor(-0.5, dtype=torch.float32)*torch.sum(torch.log(c) + logvar + (z - mu).pow(2) / logvar.exp(), dim=1)\n",
    "\n",
    "# KL divergence loss\n",
    "def labelled_loss(z, mu, logvar, mu_prior, logvar_prior):\n",
    "    c = torch.tensor(0.1, dtype=torch.float32)\n",
    "    return log_normal(z, mu, logvar) - log_normal(z, mu_prior, logvar_prior) - torch.log(c)\n",
    "\n",
    "# Derived by assuming posterior is Gaussian and prior is unit normal distribution.\n",
    "def kl_divergence_loss_fn(mu, logvar):\n",
    "        return torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1), dim=0)\n",
    "\n",
    "def train(train_subsampler, val_subsampler, model_type, run_dir, sweep_hyperparams=True, save_model=False, project_name=None, model_name=None, config=None):\n",
    "    if sweep_hyperparams:\n",
    "        run = wandb.init(job_type='training', resume=False, reinit=False, config=sweep_config)\n",
    "        config = wandb.config\n",
    "        input_dim = config.input_dim\n",
    "        hidden_dim = config.hidden_dim\n",
    "        y_dim = config.y_dim\n",
    "        dropout = config.dropout\n",
    "        l1_reg = config.l1_reg\n",
    "        l2_reg = config.l2_reg\n",
    "        latent_dim = config.latent_dim\n",
    "        num_layers = config.num_layers\n",
    "        activation_fn = config.activation_fn\n",
    "        pred_activation_fn = config.pred_activation_fn\n",
    "        dec_activation_fn = config.dec_activation_fn\n",
    "        lr = config.learning_rate\n",
    "        epochs = config.epochs\n",
    "        batch_size = config.batch_size\n",
    "    else:\n",
    "        run = wandb.init(project=project_name, name=model_name, id=model_name, job_type='training', resume=False, reinit=False, config=config)\n",
    "        input_dim = config['input_dim']['value']\n",
    "        hidden_dim = config['hidden_dim']['value']\n",
    "        y_dim = config['y_dim']['value']\n",
    "        dropout = config['dropout']['value']\n",
    "        l1_reg = config['l1_reg']['value']\n",
    "        l2_reg = config['l2_reg']['value']\n",
    "        latent_dim = config['latent_dim']['value']\n",
    "        num_layers = config['num_layers']['value']\n",
    "        activation_fn = config['activation_fn']['value']\n",
    "        pred_activation_fn = config['pred_activation_fn']['value']\n",
    "        dec_activation_fn = config['dec_activation_fn']['value']\n",
    "        lr = config['learning_rate']['value']\n",
    "        epochs = config['epochs']['value']\n",
    "        batch_size = config['batch_size']['value']\n",
    "    \n",
    "    if model_type == 'SupervisedSimpleAE':\n",
    "        model = SupervisedSimpleAE(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, pred_activation_fn, dec_activation_fn)\n",
    "    elif model_type == 'UnsupervisedSimpleAE':\n",
    "        model = UnsupervisedSimpleAE(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn, dec_activation_fn)\n",
    "    elif model_type == 'SupervisedVAE':\n",
    "        model = SupervisedVAE(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "    elif model_type == 'UnsupervisedVAE':\n",
    "        model = UnsupervisedVAE(input_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "    elif model_type == 'GMVAE':\n",
    "        model = GMVAE(input_dim, y_dim, hidden_dim, dropout, latent_dim, num_layers, activation_fn)\n",
    "    else:\n",
    "        raise ValueError('Invalid model type')\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_subsampler, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_subsampler, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_kl_loss_per_step = []\n",
    "\n",
    "        train_recon1_loss_per_step = []\n",
    "        train_recon2_loss_per_step = []\n",
    "        train_recon3_loss_per_step = []\n",
    "        train_recon4_loss_per_step = []\n",
    "\n",
    "        train_recon1_acc_per_step = []\n",
    "        train_recon2_acc_per_step = []\n",
    "        train_recon3_acc_per_step = []\n",
    "\n",
    "        train_pred_loss_per_step = []\n",
    "\n",
    "        train_total_loss_per_step = []\n",
    "\n",
    "        val_kl_loss_per_step = []\n",
    "\n",
    "        val_recon1_loss_per_step = []\n",
    "        val_recon2_loss_per_step = []\n",
    "        val_recon3_loss_per_step = []\n",
    "        val_recon4_loss_per_step = []\n",
    "\n",
    "        val_recon1_acc_per_step = []\n",
    "        val_recon2_acc_per_step = []\n",
    "        val_recon3_acc_per_step = []\n",
    "\n",
    "        val_pred_loss_per_step = []\n",
    "\n",
    "        val_total_loss_per_step = []\n",
    "\n",
    "        # for i, input in enumerate(train_dataloader):\n",
    "        for i, (y, input) in enumerate(train_dataloader):\n",
    "        # for i, (input1, input2, input3, input4) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## ------------------------ USER INPUT START ------------------------\n",
    "\n",
    "            # Model 1\n",
    "            # _, recon1, recon2, recon3, recon4 = model(torch.concat((input1, input2, input3, input4), dim=1))\n",
    "            _, pred, recon = model(input)\n",
    "            # _, reconst = model(input)\n",
    "            train_loss1 = torch.nn.L1Loss(reduction='mean')(recon, input)\n",
    "            train_recon1_loss_per_step.append(train_loss1.item())\n",
    "            \n",
    "            # train_loss1 = torch.nn.CrossEntropyLoss(reduction='mean')(recon1, input1)\n",
    "            # train_acc1_metric = MultilabelAccuracy(num_labels=3)\n",
    "            # train_acc1 = train_acc1_metric(recon1, input1)\n",
    "            # train_recon1_loss_per_step.append(train_loss1.item())\n",
    "            # train_recon1_acc_per_step.append(train_acc1.item())\n",
    "\n",
    "            # train_loss2 = torch.nn.CrossEntropyLoss(reduction='mean')(recon2, input2)\n",
    "            # train_acc2_metric = MultilabelAccuracy(num_labels=4)\n",
    "            # train_acc2 = train_acc2_metric(recon2, input2)\n",
    "            # train_recon2_loss_per_step.append(train_loss2.item())\n",
    "            # train_recon2_acc_per_step.append(train_acc2.item())\n",
    "\n",
    "            # train_loss3 = torch.nn.CrossEntropyLoss(reduction='mean')(recon3, input3)\n",
    "            # train_acc3_metric = MultilabelAccuracy(num_labels=8)\n",
    "            # train_acc3 = train_acc3_metric(recon3, input3)\n",
    "            # train_recon3_loss_per_step.append(train_loss3.item())\n",
    "            # train_recon3_acc_per_step.append(train_acc3.item())\n",
    "\n",
    "            # train_loss4 = torch.nn.L1Loss(reduction='mean')(pred, y)\n",
    "            # train_recon4_loss_per_step.append(train_loss4.item())\n",
    "\n",
    "            train_loss3 = torch.nn.L1Loss(reduction='mean')(pred, y)\n",
    "            train_pred_loss_per_step.append(train_loss3.item())\n",
    "\n",
    "            enc_params = torch.cat([x.view(-1) for x in model.encoder.parameters()])\n",
    "            pred_params = torch.cat([x.view(-1) for x in model.predictor.parameters()])\n",
    "            dec_params = torch.cat([x.view(-1) for x in model.decoder.parameters()])\n",
    "\n",
    "            l1_regularization = l1_reg * (torch.norm(enc_params, 1) + \n",
    "                                            torch.norm(pred_params, 1) +\n",
    "                                          torch.norm(dec_params, 1))\n",
    "            l2_regularization = l2_reg * (torch.norm(enc_params, 2) + \n",
    "                                            torch.norm(pred_params, 2) +\n",
    "                                          torch.norm(dec_params, 2))\n",
    "            \n",
    "            train_total_loss = train_loss1 + train_loss3 + l1_regularization + l2_regularization\n",
    "            # train_total_loss = train_loss1 + train_loss2 + train_loss3 + l1_regularization + l2_regularization\n",
    "            # train_total_loss = train_loss1 + train_loss2 + l1_regularization + l2_regularization\n",
    "            # train_total_loss = train_loss1 + l1_regularization + l2_regularization\n",
    "\n",
    "            ## ------------------------ USER INPUT END ------------------------\n",
    "\n",
    "            train_total_loss_per_step.append(train_total_loss.item())\n",
    "\n",
    "            # # Model 2\n",
    "            # z, pred, reconst, mu, logvar = model(input)\n",
    "            # train_loss1 = kl_divergence_loss_fn(mu, logvar)\n",
    "            # train_kl_loss_per_step.append(train_loss1.item())\n",
    "            # train_loss2 = torch.nn.MSELoss(reduction='mean')(input, reconst)\n",
    "            # train_reconst_loss_per_step.append(train_loss2.item())\n",
    "            # train_loss3 = torch.nn.MSELoss(reduction='mean')(bandgaps.unsqueeze(dim=1), pred)\n",
    "            # train_pred_loss_per_step.append(train_loss3.item())\n",
    "            # train_total_loss = train_loss1 + train_loss2 + train_loss3\n",
    "            # train_total_loss_per_step.append(train_total_loss.item())\n",
    "\n",
    "            # # Model 3\n",
    "            # z, pred, reconst, mu, logvar, mu_prior, logvar_prior, qy_logit, qy = model(input)\n",
    "            # train_loss1 = torch.nn.CrossEntropyLoss(reduction='mean')(qy_logit, qy)\n",
    "            # train_loss2 = [None] * model.y_dim\n",
    "            # train_loss3 = [None] * model.y_dim\n",
    "            # train_loss4 = [None] * model.y_dim\n",
    "            # for i in range(model.y_dim):\n",
    "            #     # Take mean across the batch\n",
    "            #     train_loss2[i] = torch.mean(qy[:, i]*torch.nn.L1Loss(reduction='sum')(bandgaps.unsqueeze(dim=1), pred[i]), dtype=torch.float32)\n",
    "            #     train_loss3[i] = torch.mean(qy[:, i]*torch.nn.MSELoss(reduction='sum')(input, reconst[i]), dtype=torch.float32)\n",
    "            #     train_loss4[i] = torch.mean(qy[:, i]*labelled_loss(z[i], mu[i], logvar[i], mu_prior[i], logvar_prior[i]), dtype=torch.float32)\n",
    "            # train_pred_loss_per_step.append(torch.stack(train_loss2).sum().item())\n",
    "            # train_reconst_loss_per_step.append(torch.stack(train_loss3).sum().item())\n",
    "            # train_kl_loss_per_step.append(torch.stack(train_loss4).sum().item())\n",
    "            # train_total_loss = train_loss1 + torch.stack(train_loss2).sum() + torch.stack(train_loss3).sum() + torch.stack(train_loss4).sum()\n",
    "            # train_total_loss_per_step.append(train_total_loss.item())\n",
    "\n",
    "            train_total_loss.backward()\n",
    "            optimizer.step()\n",
    "        # if model_type == 'GMVAE':\n",
    "        #     wandb.log({'epoch':epoch, 'train_kl_loss_per_epoch':np.mean(train_kl_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'train_recon1_loss_per_epoch':np.mean(train_recon1_loss_per_step)})\n",
    "        # wandb.log({'epoch':epoch, 'train_recon1_acc_per_epoch':np.mean(train_recon1_acc_per_step)})\n",
    "\n",
    "        # wandb.log({'epoch':epoch, 'train_recon2_loss_per_epoch':np.mean(train_recon2_loss_per_step)})\n",
    "        # wandb.log({'epoch':epoch, 'train_recon2_acc_per_epoch':np.mean(train_recon2_acc_per_step)})\n",
    "\n",
    "        # wandb.log({'epoch':epoch, 'train_recon3_loss_per_epoch':np.mean(train_recon3_loss_per_step)})\n",
    "        # wandb.log({'epoch':epoch, 'train_recon3_acc_per_epoch':np.mean(train_recon3_acc_per_step)})\n",
    "\n",
    "        # wandb.log({'epoch':epoch, 'train_recon4_loss_per_epoch':np.mean(train_recon4_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'train_pred_loss_per_epoch':np.mean(train_pred_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'train_total_loss_per_epoch':np.mean(train_total_loss_per_step)})\n",
    "\n",
    "        # Run the validation loop\n",
    "        # for i, input in enumerate(val_dataloader):\n",
    "        for i, (y, input) in enumerate(val_dataloader):\n",
    "        # for i, (y, input1, input2) in enumerate(val_dataloader):\n",
    "        # for i, (input1, input2, input3, input4) in enumerate(val_dataloader):\n",
    "\n",
    "            ## ------------------------ USER INPUT START ------------------------\n",
    "\n",
    "            # Model 1\n",
    "            # _, recon1, recon2, recon3, recon4 = model(torch.concat((input1, input2, input3, input4), dim=1))\n",
    "            # _, pred, reconst1, reconst2 = model(torch.concat((input1, input2), dim=1))\n",
    "            _, pred, recon = model(input)\n",
    "            # _, reconst = model(input)\n",
    "\n",
    "            val_loss1 = torch.nn.L1Loss(reduction='mean')(recon, input)\n",
    "            val_recon1_loss_per_step.append(val_loss1.item())\n",
    "\n",
    "            # val_loss1 = torch.nn.CrossEntropyLoss(reduction='mean')(recon1, input1)\n",
    "            # val_recon1_loss_per_step.append(val_loss1.item())\n",
    "            # val_acc1_metric = MultilabelAccuracy(num_labels=3)\n",
    "            # val_acc1 = val_acc1_metric(recon1, input1)\n",
    "            # val_recon1_acc_per_step.append(val_acc1.item())\n",
    "\n",
    "            # val_loss2 = torch.nn.CrossEntropyLoss(reduction='mean')(recon2, input2)\n",
    "            # val_recon2_loss_per_step.append(val_loss2.item())\n",
    "            # val_acc2_metric = MultilabelAccuracy(num_labels=4)\n",
    "            # val_acc2 = val_acc2_metric(recon2, input2)\n",
    "            # val_recon2_acc_per_step.append(val_acc2.item())\n",
    "\n",
    "            # val_loss3 = torch.nn.CrossEntropyLoss(reduction='mean')(recon3, input3)\n",
    "            # val_recon3_loss_per_step.append(val_loss3.item())\n",
    "            # val_acc3_metric = MultilabelAccuracy(num_labels=8)\n",
    "            # val_acc3 = val_acc3_metric(recon3, input3)\n",
    "            # val_recon3_acc_per_step.append(val_acc3.item())\n",
    "\n",
    "            # val_loss4 = torch.nn.L1Loss(reduction='mean')(recon4, input4)\n",
    "            # val_recon4_loss_per_step.append(val_loss4.item())\n",
    "\n",
    "            val_loss3 = torch.nn.L1Loss(reduction='mean')(pred, y)\n",
    "            val_pred_loss_per_step.append(val_loss3.item())\n",
    "\n",
    "            val_total_loss = val_loss1 + val_loss3\n",
    "\n",
    "            ## ------------------------ USER INPUT END ------------------------\n",
    "\n",
    "            val_total_loss_per_step.append(val_total_loss.item())\n",
    "            # val_total_loss = val_loss1 + val_loss2\n",
    "            # val_total_loss_per_step.append(val_total_loss.item())\n",
    "            # val_total_loss = val_loss1\n",
    "            # val_total_loss_per_step.append(val_total_loss.item())\n",
    "\n",
    "            # # Model 2\n",
    "            # z, pred, reconst, mu, logvar = model(input)\n",
    "            # val_loss1 = kl_divergence_loss_fn(mu, logvar)\n",
    "            # val_kl_loss_per_step.append(val_loss1.item())\n",
    "            # val_loss2 = torch.nn.MSELoss(reduction='mean')(input, reconst)\n",
    "            # val_reconst_loss_per_step.append(val_loss2.item())\n",
    "            # val_loss3 = torch.nn.MSELoss(reduction='mean')(bandgaps.unsqueeze(dim=1), pred)\n",
    "            # val_pred_loss_per_step.append(val_loss3.item())\n",
    "            # val_total_loss = val_loss1 + val_loss2 + val_loss3\n",
    "            # val_total_loss_per_step.append(val_total_loss.item())\n",
    "\n",
    "            # # Model 3\n",
    "            # z, pred, reconst, mu, logvar, mu_prior, logvar_prior, qy_logit, qy = model(input)\n",
    "            # val_loss1 = torch.nn.CrossEntropyLoss(reduction='mean')(qy_logit, qy)\n",
    "            # val_loss2 = [None] * model.y_dim\n",
    "            # val_loss3 = [None] * model.y_dim\n",
    "            # val_loss4 = [None] * model.y_dim\n",
    "            # for i in range(model.y_dim):\n",
    "            #     # Take mean across batch\n",
    "            #     val_loss2[i] = torch.mean(qy[:, i]*torch.nn.L1Loss(reduction='sum')(bandgaps.unsqueeze(dim=1), pred[i]), dtype=torch.float32)\n",
    "            #     val_loss3[i] = torch.mean(qy[:, i]*torch.nn.MSELoss(reduction='sum')(input, reconst[i]), dtype=torch.float32)\n",
    "            #     val_loss4[i] = torch.mean(qy[:, i]*labelled_loss(z[i], mu[i], logvar[i], mu_prior[i], logvar_prior[i]), dtype=torch.float32)\n",
    "            # val_pred_loss_per_step.append(torch.stack(val_loss2).sum().item())\n",
    "            # val_reconst_loss_per_step.append(torch.stack(val_loss3).sum().item())\n",
    "            # val_kl_loss_per_step.append(torch.stack(val_loss4).sum().item())\n",
    "            # val_total_loss = val_loss1 + torch.stack(val_loss2).sum() + torch.stack(val_loss3).sum() + torch.stack(val_loss4).sum()\n",
    "            # val_total_loss_per_step.append(val_total_loss.item())\n",
    "\n",
    "        # if model_type == 'GMVAE':\n",
    "        #     wandb.log({'epoch':epoch, 'val_kl_loss_per_epoch':np.mean(val_kl_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'val_recon1_loss_per_epoch': np.mean(val_recon1_loss_per_step)})\n",
    "        # wandb.log({'epoch':epoch, 'val_recon1_acc_per_epoch': np.mean(val_recon1_acc_per_step)})\n",
    "\n",
    "        # wandb.log({'epoch':epoch, 'val_recon2_loss_per_epoch': np.mean(val_recon2_loss_per_step)})\n",
    "        # wandb.log({'epoch':epoch, 'val_recon2_acc_per_epoch': np.mean(val_recon2_acc_per_step)})\n",
    "\n",
    "        # wandb.log({'epoch':epoch, 'val_recon3_loss_per_epoch': np.mean(val_recon3_loss_per_step)})\n",
    "        # wandb.log({'epoch':epoch, 'val_recon3_acc_per_epoch': np.mean(val_recon3_acc_per_step)})\n",
    "\n",
    "        # wandb.log({'epoch':epoch, 'val_recon4_loss_per_epoch': np.mean(val_recon4_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'val_pred_loss_per_epoch': np.mean(val_pred_loss_per_step)})\n",
    "        wandb.log({'epoch':epoch, 'val_total_loss_per_epoch': np.mean(val_total_loss_per_step)})\n",
    "    run.finish()\n",
    "    # Save the model\n",
    "    if save_model:\n",
    "        model_dir = f'../runs/{run_dir}/{model_name}'\n",
    "        # if model dir does not exist create it\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        model_path = model_dir + '/' + f'{model_name}.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # Save the scalers also in the model folder\n",
    "        # scaler_X1_path = f'../runs/perovskite_multiscale_dataset_v2/{model_name}/scaler_X1.pkl'\n",
    "        scaler_X4_path = f'../runs/{run_dir}/{model_name}/scaler_latentsfromAE2.pkl'\n",
    "        # scaler_y_path = f'../runs/perovskite_multiscale_dataset_v2/{model_name}/scaler_y.pkl'\n",
    "        joblib.dump(scaler_X1, scaler_X4_path)\n",
    "        if model_type == 'SupervisedSimpleAE':\n",
    "            pass\n",
    "            # joblib.dump(scaler_y, scaler_y_path)\n",
    "    \n",
    "    \n",
    "## ------------------------ USER INPUT START ------------------------\n",
    "# By default save_model is set to False for hyperparam runs.\n",
    "\n",
    "# Step 1\n",
    "sweep_for_hyperparams = False\n",
    "# Step 2\n",
    "sweep_for_latent = False\n",
    "# Step 3 : Save the best performing model\n",
    "save_model_on_local = True\n",
    "\n",
    "ae_name = 'SupSimpleAE_2'\n",
    "model_type = 'SupervisedSimpleAE'\n",
    "dataset_name = 'randomData_sumf5'\n",
    "run_dir = 'results_for_RL_paper'\n",
    "\n",
    "val_split = 0.2 # num_folds*val_split must be 1 \n",
    "\n",
    "if sweep_for_hyperparams:\n",
    "    sweep_type = 'grid' # Select between 'bayes', 'grid', 'random' \n",
    "    limit_num_trials_in_sweep = None # Typically 3*3*3=27 trials. Consider only (10% of space is explored) 0.1*81=8.1 ~ 8 trials\n",
    "    num_folds = 5 # 494/5 = 98.8 in internal validation set\n",
    "    parameters = {\n",
    "            'input_dim':{\n",
    "                'value':X1_final.shape[1] + X2_final.shape[1] + X3_final.shape[1] + X4_final.shape[1]\n",
    "            },\n",
    "            'hidden_dim':{\n",
    "                'values':[25, 50, 75]\n",
    "            },\n",
    "            'latent_dim':{\n",
    "                'value':4\n",
    "            },\n",
    "            'y_dim':{\n",
    "                'value':None\n",
    "            },\n",
    "            'dropout':{\n",
    "                'value':0\n",
    "            },\n",
    "            'l1_reg':{\n",
    "                'value':0\n",
    "            },\n",
    "            'l2_reg':{\n",
    "                'value':0.001\n",
    "            },\n",
    "            'num_layers':{\n",
    "                'values':[1, 2, 3]\n",
    "            },\n",
    "            'activation_fn':{\n",
    "                'values':['tanh', 'relu', None]\n",
    "            },\n",
    "            'dec_activation_fn':{\n",
    "                'value':None\n",
    "            },\n",
    "            'pred_activation_fn':{\n",
    "                'value':None\n",
    "            },\n",
    "            'batch_size':{\n",
    "                'value':10\n",
    "            },\n",
    "            'learning_rate':{\n",
    "                'value':1e-3\n",
    "            },\n",
    "            'epochs':{\n",
    "                'value':1000\n",
    "            }\n",
    "        }\n",
    "\n",
    "if sweep_for_latent or save_model_on_local:\n",
    "    losses_to_track = ['total']\n",
    "    latent_space_to_sweep = [2, 4, 6, 8, 10, 12]\n",
    "    seeds_to_sweep = [0, 1, 2, 3, 4]\n",
    "    parameters = {\n",
    "                'input_dim':{\n",
    "                    'value':X1_final.shape[1]\n",
    "                },\n",
    "                'hidden_dim':{\n",
    "                    'value':None,\n",
    "                },\n",
    "                'latent_dim':{\n",
    "                    'value':10\n",
    "                },\n",
    "                'y_dim':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'dropout':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'l1_reg':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'l2_reg':{\n",
    "                    'value':0.001\n",
    "                },\n",
    "                'num_layers':{\n",
    "                    'value':1\n",
    "                },\n",
    "                'activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'dec_activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'pred_activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'batch_size':{\n",
    "                    'value':10\n",
    "                },\n",
    "                'learning_rate':{\n",
    "                    'value':1e-3\n",
    "                },\n",
    "                'epochs':{\n",
    "                    'value':1500\n",
    "                }\n",
    "            }\n",
    "\n",
    "## ------------------------ USER INPUT END ------------------------\n",
    "\n",
    "if sweep_for_hyperparams:\n",
    "    ldim = parameters['latent_dim']['value']\n",
    "    sweep_config = {\n",
    "        'name': f'{ae_name}_ldim{ldim}_{dataset_name}',\n",
    "        'method':sweep_type,\n",
    "        'metric':{\n",
    "            'name':'val_total_loss_per_epoch',\n",
    "            'goal':'minimize'\n",
    "            },\n",
    "        'parameters':parameters\n",
    "    }\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=orig_seed)\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(dataset)):\n",
    "        train_subsampler = torch.utils.data.Subset(dataset, train_indices)\n",
    "        val_subsampler = torch.utils.data.Subset(dataset, val_indices)\n",
    "        sweep_config['name'] = sweep_config['name'] + '_fold_' + str(fold)\n",
    "        sweep_id = wandb.sweep(sweep_config, project=project_name)\n",
    "        run_name = wandb.util.generate_id()\n",
    "        wandb.agent(sweep_id, lambda: train(train_subsampler, val_subsampler, model_type=model_type, run_dir=run_dir), project=project_name, count=limit_num_trials_in_sweep)\n",
    "        # Finish the sweep\n",
    "        wandb.finish()\n",
    "elif sweep_for_latent:\n",
    "    # Create a dictionary to store the losses\n",
    "    loss_dict = {}\n",
    "    for loss_name in losses_to_track:\n",
    "        loss_dict.update({f'val_{loss_name}_loss':np.zeros((len(seeds_to_sweep), len(latent_space_to_sweep)))})\n",
    "        loss_dict.update({f'train_{loss_name}_loss':np.zeros((len(seeds_to_sweep), len(latent_space_to_sweep)))})\n",
    "    for seed in seeds_to_sweep:\n",
    "        for i, latent in enumerate(latent_space_to_sweep):\n",
    "            parameters['latent_dim']['value'] = latent\n",
    "            model_name = f'{ae_name}_ldim{latent}_{dataset_name}_seed{seed}'\n",
    "            print(f'Running model {model_name}')\n",
    "            num_samples = X1.shape[0]\n",
    "            indices = np.arange(num_samples)\n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "            np.random.shuffle(indices)\n",
    "            train_indices = indices[:int((1- val_split)*num_samples)]\n",
    "            val_indices = indices[int((1- val_split)*num_samples):]\n",
    "            train_subsampler = torch.utils.data.Subset(dataset, train_indices)\n",
    "            val_subsampler = torch.utils.data.Subset(dataset, val_indices)\n",
    "            train(train_subsampler, val_subsampler, model_type=model_type, run_dir=run_dir, sweep_hyperparams=False, save_model=save_model_on_local, project_name=project_name, model_name=model_name, config=parameters)\n",
    "            # Extract the losses from the wandb run\n",
    "            api = wandb.Api()     \n",
    "            run = api.run(f'{project_name}/{model_name}')\n",
    "            # Extract the losses\n",
    "            for loss_name in losses_to_track:\n",
    "                loss_dict[f'val_{loss_name}_loss'][seed, i] = run.summary[f'val_{loss_name}_loss_per_epoch']\n",
    "                loss_dict[f'train_{loss_name}_loss'][seed, i] = run.summary[f'train_{loss_name}_loss_per_epoch']\n",
    "    # Store the loss matrices in run directory\n",
    "    for loss_name in losses_to_track:\n",
    "        val_loss_path = f'../runs/{run_dir}/val_{loss_name}_loss.npy'\n",
    "        train_loss_path = f'../runs/{run_dir}/train_{loss_name}_loss.npy'\n",
    "        np.save(val_loss_path, loss_dict[f'val_{loss_name}_loss'])\n",
    "        np.save(train_loss_path, loss_dict[f'train_{loss_name}_loss'])\n",
    "    # recon4_val_loss_path = f'../runs/{run_dir}/val_recon4_loss_for_peroveff2_film_valsplit0p1_bs1.npy'\n",
    "    # recon4_train_loss_path = f'../runs/{run_dir}/train_recon4_loss_for_peroveff2_film_valsplit0p1_bs1.npy'\n",
    "    # total_val_loss_path = f'../runs/{run_dir}/val_total_loss_for_peroveff2_film_valsplit0p1_bs1.npy'\n",
    "    # total_train_loss_path = f'../runs/{run_dir}/train_total_loss_for_peroveff2_film_valsplit0p1_bs1.npy'\n",
    "    # np.save(recon4_val_loss_path, val_recon4_loss_for_peroveff2_film_valsplit0p1_bs1)\n",
    "    # np.save(recon4_train_loss_path, train_recon4_loss_for_peroveff2_film_valsplit0p1_bs1)\n",
    "    # np.save(total_val_loss_path, val_total_loss_for_peroveff2_film_valsplit0p1_bs1)\n",
    "    # np.save(total_train_loss_path, train_total_loss_for_peroveff2_film_valsplit0p1_bs1)\n",
    "    # Reset the random seed to what it was before\n",
    "    seed = orig_seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "elif save_model_on_local:\n",
    "    num_samples = X1.shape[0]\n",
    "    indices = np.arange(num_samples)\n",
    "    train_indices = indices[:int((1- val_split)*num_samples)]\n",
    "    val_indices = indices[int((1- val_split)*num_samples):]\n",
    "    train_subsampler = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_subsampler = torch.utils.data.Subset(dataset, val_indices)\n",
    "    ldim = parameters['latent_dim']['value']\n",
    "    model_name = f'{ae_name}_ldim{ldim}_{dataset_name}'\n",
    "    train(train_subsampler, val_subsampler, model_type=model_type, run_dir=run_dir, sweep_hyperparams=False, save_model=save_model_on_local, project_name=project_name, model_name=model_name, config=parameters)\n",
    "    # If any .npy files are found in the run directory transfer them into the model directory\n",
    "    for file in os.listdir(f'../runs/{run_dir}'):\n",
    "        if file.endswith('.npy'):\n",
    "            shutil.move(f'../runs/{run_dir}/{file}', f'../runs/{run_dir}/{model_name}/{file}')\n",
    "else:\n",
    "    print('Operation not supported')\n",
    "\n",
    "# Models for film scale perovskite dataset v2 trained using 90:10 split and batch size 10\n",
    "\n",
    "# paths_seed10 = ['nthota2/perovskite_dataset_v2/i0siejd3',\n",
    "#                 'nthota2/perovskite_dataset_v2/41lyo4zx',\n",
    "#                 'nthota2/perovskite_dataset_v2/090ev6lt',\n",
    "#                 'nthota2/perovskite_dataset_v2/4hx3g1ze',\n",
    "#                 'nthota2/perovskite_dataset_v2/5lxjh9yz',\n",
    "#                 'nthota2/perovskite_dataset_v2/plfhcevp',\n",
    "#                 'nthota2/perovskite_dataset_v2/s2blmq1p',\n",
    "#                 'nthota2/perovskite_dataset_v2/33kw47zq',\n",
    "#                 'nthota2/perovskite_dataset_v2/51g6co9z',\n",
    "#                 'nthota2/perovskite_dataset_v2/ea6e0vvg',\n",
    "#                 'nthota2/perovskite_dataset_v2/s1xzk0v8']\n",
    "\n",
    "# paths_seed1 = ['nthota2/perovskite_dataset_v2/661g95rw',\n",
    "#                'nthota2/perovskite_dataset_v2/0g449pn8',\n",
    "#                'nthota2/perovskite_dataset_v2/lqh9dg48',\n",
    "#                'nthota2/perovskite_dataset_v2/e7dgdq6i',\n",
    "#                'nthota2/perovskite_dataset_v2/26a8ng2u',\n",
    "#                'nthota2/perovskite_dataset_v2/ks0zvbhp',\n",
    "#                'nthota2/perovskite_dataset_v2/adx91d6o',\n",
    "#                'nthota2/perovskite_dataset_v2/901war6q',\n",
    "#                'nthota2/perovskite_dataset_v2/qwiryh15',\n",
    "#                'nthota2/perovskite_dataset_v2/krs81m9u',\n",
    "#                'nthota2/perovskite_dataset_v2/319183bd']\n",
    "\n",
    "# paths_seed2 = ['nthota2/perovskite_dataset_v2/mdshovqj',\n",
    "#                'nthota2/perovskite_dataset_v2/y3v0p2x1',\n",
    "#                'nthota2/perovskite_dataset_v2/st18wn73',\n",
    "#                'nthota2/perovskite_dataset_v2/t1ftdjr5',\n",
    "#                'nthota2/perovskite_dataset_v2/041zbojc',\n",
    "#                'nthota2/perovskite_dataset_v2/1v79q4r9',\n",
    "#                'nthota2/perovskite_dataset_v2/00tu85tg',\n",
    "#                'nthota2/perovskite_dataset_v2/4wx9bbt3',\n",
    "#                'nthota2/perovskite_dataset_v2/2v4pf9yo',\n",
    "#                'nthota2/perovskite_dataset_v2/jirnsqq2',\n",
    "#                'nthota2/perovskite_dataset_v2/8bgcj3id']\n",
    "\n",
    "# paths_seed3 = ['nthota2/perovskite_dataset_v2/9c91pcxl',\n",
    "#                'nthota2/perovskite_dataset_v2/iisquapr',\n",
    "#                'nthota2/perovskite_dataset_v2/f33cluje',\n",
    "#                'nthota2/perovskite_dataset_v2/kmx635x0',\n",
    "#                'nthota2/perovskite_dataset_v2/zcohntic',\n",
    "#                'nthota2/perovskite_dataset_v2/nx650722',\n",
    "#                'nthota2/perovskite_dataset_v2/yk3x5pn5',\n",
    "#                'nthota2/perovskite_dataset_v2/lt3yut3v',\n",
    "#                'nthota2/perovskite_dataset_v2/uwni8be0',\n",
    "#                'nthota2/perovskite_dataset_v2/9cpliop8',\n",
    "#                'nthota2/perovskite_dataset_v2/ptophhdq']\n",
    "\n",
    "# paths_seed4 = ['nthota2/perovskite_dataset_v2/g5som797',\n",
    "#                'nthota2/perovskite_dataset_v2/fgz3igxx',\n",
    "#                'nthota2/perovskite_dataset_v2/l3q1w43r',\n",
    "#                'nthota2/perovskite_dataset_v2/3shs46xm',\n",
    "#                'nthota2/perovskite_dataset_v2/iscztzx0',\n",
    "#                'nthota2/perovskite_dataset_v2/aeqbbo34',\n",
    "#                'nthota2/perovskite_dataset_v2/hful22lx',\n",
    "#                'nthota2/perovskite_dataset_v2/31bx1k6h',\n",
    "#                'nthota2/perovskite_dataset_v2/b7lr6u9d',\n",
    "#                'nthota2/perovskite_dataset_v2/9tv3phh1',\n",
    "#                'nthota2/perovskite_dataset_v2/oioxfv5e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c6f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print([2]*(3 + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4600c",
   "metadata": {},
   "source": [
    "## Model Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276352fd",
   "metadata": {},
   "source": [
    "#### Plotting model performance vs latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cc61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Store the below loss values in .npy arrays and move them to the model directory\n",
    "\n",
    "# For RL paper\n",
    "# # Grid data - UnsupervisedSimpleAE 1\n",
    "# latent_space = [1, 2, 4, 6, 8]\n",
    "# total_val_loss = [0.001025053068588022, 0.001063714546035044, 0.0011066086881328374, 0.0013437549932859838, 0.0009386805177200586]\n",
    "# total_train_loss = [0.007932848995551467, 0.008279352798126638, 0.004237618821207434, 0.004374776501208544, 0.004906855116132647]\n",
    "\n",
    "# # Grid data - Nonlinf5 SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6]\n",
    "# total_val_loss = [0.7463283464312553, 0.2002287097275257, 0.1977713629603386, 0.1788929458707571]\n",
    "# total_train_loss = [0.4705591835081578, 0.14468571869656444, 0.1250611103605479, 0.13816878804937005]\n",
    "\n",
    "# # Grid data - Sumf5 - SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6]\n",
    "# total_val_loss = [0.49156802892684937, 0.019491535145789385, 0.02250012196600437, 0.02030603913590312]\n",
    "# total_train_loss = [0.4140172880142927, 0.03587072214577347, 0.02835194836370647, 0.03037486143875867]\n",
    "\n",
    "# # Random data - UnsupervisedSimpleAE 1\n",
    "# latent_space = [2, 4, 6, 8]\n",
    "# total_val_loss = [0.6480237692594528, 0.4781555384397506, 0.24337586015462875, 0.002268550335429609]\n",
    "# total_train_loss = [0.6661303304135799, 0.4441600125283003, 0.20833437889814377, 0.007954166503623128]\n",
    "\n",
    "# # Random data - Nonlinf5 - SupervisedSimpleAE 2\n",
    "# latent_space = [1, 2, 4, 6, 8, 10, 11, 12]\n",
    "# total_val_loss = [0.7916551381349564, 0.6637141406536102, 0.5525364577770233, 0.3102440983057022, 0.19166426360607147, 0.051493472419679165, 0.021430929424241185, 0.007555923308245838]\n",
    "# total_train_loss = [0.7504490427672863, 0.6266670003533363, 0.4413919039070606, 0.30615816451609135, 0.18379461765289307, 0.05851957411505282, 0.028894496499560773, 0.016192137030884624]\n",
    "\n",
    "# # Random data - Sumf5 - SupervisedSimpleAE 2\n",
    "# # Will have to change the predictor as only prediction loss is high, reconstruction is good.\n",
    "# latent_space = [1, 2, 4, 6, 8, 10, 11, 12]\n",
    "# total_val_loss = [1.4578111469745636, 1.4702374935150146, 1.383190006017685, 1.16259, 0.99866, 0.81431, 0.75846, 0.83324]\n",
    "# total_train_loss = [1.4289479702711103, 1.2744147181510923, 1.0854754857718945, 0.96673, 0.84347, 0.72946, 0.69708, 0.66834]\n",
    "\n",
    "# Arun2024 (Input dim = 15 + 4 = 19)\n",
    "# latent_space =      [2,     4,     6,     8,     10,    12,    14]\n",
    "# pred_val_loss =     [0.206, 0.178, 0.244, 0.227, 0.148, 0.233, 0.231]\n",
    "# pred_train_loss =   [0.11,  0.076, 0.082, 0.067, 0.074, 0.071, 0.067]\n",
    "# recont_val_loss =   [0.561, 0.069, 0.055, 0.050, 0.038, 0.046, 0.056]\n",
    "# recont_train_loss = [0.234, 0.055, 0.037, 0.038, 0.037, 0.042, 0.039]\n",
    "# total_val_loss = [0.76786, 0.24755343379718917, \t0.24418, 0.27646, 0.18622, 0.27943, 0.28719]\n",
    "# total_train_loss = [0.38542, 0.16735203887741917, \t0.15132, 0.13772, 0.14288, 0.14528, 0.13803]\n",
    "\n",
    "# for 10 this is the best that can be done. Adding more layers or increasing the hidden dim or using non linea act does not work.\n",
    "# val : 0.7632711380720139\n",
    "# train : 0.7363427169620991\n",
    "run_dir = 'results_for_RL_paper'\n",
    "train_loss_matrix_path = f'../runs/{run_dir}/SupSimpleAE_2_ldim10_randomData_nonlinf5/train_total_loss.npy'\n",
    "val_loss_matrix_path = f'../runs/{run_dir}/SupSimpleAE_2_ldim10_randomData_nonlinf5/val_total_loss.npy'\n",
    "\n",
    "train_loss_matrix = np.load(train_loss_matrix_path)\n",
    "val_loss_matrix = np.load(val_loss_matrix_path)\n",
    "train_mean_losses = np.mean(train_loss_matrix, axis=0)\n",
    "train_std_losses = np.std(train_loss_matrix, axis=0)\n",
    "val_mean_losses = np.mean(val_loss_matrix, axis=0)\n",
    "val_std_losses = np.std(val_loss_matrix, axis=0)\n",
    "\n",
    "latent_space_to_sweep = [2, 4, 6, 8, 10, 12]\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Plot the latent space vs total validation loss\n",
    "plt.errorbar(latent_space_to_sweep, train_mean_losses, yerr=train_std_losses, label='train', marker='o', linestyle='-')\n",
    "plt.errorbar(latent_space_to_sweep, val_mean_losses, yerr=val_std_losses, label='val', marker='o', linestyle='-')\n",
    "# # Label the mean values on top with red color\n",
    "# for i, txt in enumerate(val_mean_losses):\n",
    "#     # plt.annotate(f'{txt:.3f}', (latent_space_to_sweep[i], val_mean_losses[i]), textcoords=\"offset points\", xytext=(0,15), ha='center', color='r')\n",
    "#     print(f'{latent_space_to_sweep[i]} : Val Std dev. : {val_std_losses[i]}')  \n",
    "#     print(f'{latent_space_to_sweep[i]} : Val Mean : {val_mean_losses[i]}')\n",
    "# for i, txt in enumerate(train_mean_losses):\n",
    "#     # plt.annotate(f'{txt:.3f}', (latent_space_to_sweep[i], train_mean_losses[i]), textcoords=\"offset points\", xytext=(0,-15), ha='center', color='b')\n",
    "#     print(f'{latent_space_to_sweep[i]} : Train Std dev. : {train_std_losses[i]}')  \n",
    "#     print(f'{latent_space_to_sweep[i]} : Train Mean : {train_mean_losses[i]}')\n",
    "# plt.plot(latent_space, total_train_loss, marker='o', linestyle='', label='train')\n",
    "# plt.plot(latent_space, total_val_loss, marker='o', linestyle='', label='val')\n",
    "plt.xlabel('Latent space dimension')\n",
    "plt.xticks(latent_space_to_sweep)\n",
    "# Set the tick labels\n",
    "plt.ylabel('Total MAE (Reconst. + Pred.)')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the subplot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('latent_space_vs_total_loss.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52d60a",
   "metadata": {},
   "source": [
    "#### Loading the torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "                'input_dim':{\n",
    "                    'value':X1_final.shape[1]\n",
    "                },\n",
    "                'hidden_dim':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'latent_dim':{\n",
    "                    'value':10\n",
    "                },\n",
    "                'y_dim':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'dropout':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'l1_reg':{\n",
    "                    'value':0\n",
    "                },\n",
    "                'l2_reg':{\n",
    "                    'value':0.001\n",
    "                },\n",
    "                'num_layers':{\n",
    "                    'value':1\n",
    "                },\n",
    "                'activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'dec_activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'pred_activation_fn':{\n",
    "                    'value':None\n",
    "                },\n",
    "                'batch_size':{\n",
    "                    'value':10\n",
    "                },\n",
    "                'learning_rate':{\n",
    "                    'value':1e-3\n",
    "                },\n",
    "                'epochs':{\n",
    "                    'value':1500\n",
    "                }\n",
    "}\n",
    "\n",
    "# Load torch model\n",
    "ldim = parameters['latent_dim']['value']\n",
    "# model_name = f'{ae_name}_ldim{ldim}_{dataset_name}'\n",
    "# model_name = 'UnsupSimpleAE_3_ldim12_peroveff2_device_none_3_75_e2000'\n",
    "# model_name = 'SupSimpleAE_2_ldim2_gridData_nonlinf5'\n",
    "# model_name = 'best_SupSimpleAE_2_ldim2_gridData_sumf5'\n",
    "model_name = 'SupSimpleAE_2_ldim10_randomData_nonlinf5'\n",
    "run_dir = 'results_for_RL_paper'\n",
    "model_type = 'SupervisedSimpleAE'\n",
    "model_path = f'../runs/{run_dir}/{model_name}/' + model_name + '.pth'\n",
    "if model_type == 'UnsupervisedSimpleAE':\n",
    "    model = UnsupervisedSimpleAE(parameters['input_dim']['value'],\n",
    "                                parameters['hidden_dim']['value'], \n",
    "                                parameters['dropout']['value'], \n",
    "                                parameters['latent_dim']['value'], \n",
    "                                parameters['num_layers']['value'], \n",
    "                                parameters['activation_fn']['value'],\n",
    "                                parameters['dec_activation_fn']['value'])\n",
    "elif model_type == 'SupervisedSimpleAE':\n",
    "    model = SupervisedSimpleAE(parameters['input_dim']['value'],\n",
    "                                parameters['hidden_dim']['value'], \n",
    "                                parameters['dropout']['value'], \n",
    "                                parameters['latent_dim']['value'], \n",
    "                                parameters['num_layers']['value'], \n",
    "                                parameters['activation_fn']['value'],\n",
    "                                parameters['pred_activation_fn']['value'],\n",
    "                                parameters['dec_activation_fn']['value'])\n",
    "elif model_type == 'VAE':\n",
    "    model = UnsupervisedVAE(parameters['input_dim']['value'],\n",
    "                            parameters['hidden_dim']['value'], \n",
    "                            parameters['dropout']['value'], \n",
    "                            parameters['latent_dim']['value'], \n",
    "                            parameters['num_layers']['value'], \n",
    "                            parameters['activation_fn']['value'])\n",
    "elif model_type == 'GMVAE':\n",
    "    model = GMVAE(parameters['input_dim']['value'],\n",
    "                parameters['y_dim']['value'],\n",
    "                parameters['hidden_dim']['value'], \n",
    "                parameters['dropout']['value'], \n",
    "                parameters['latent_dim']['value'], \n",
    "                parameters['num_layers']['value'], \n",
    "                parameters['activation_fn']['value'])\n",
    "else:\n",
    "    pass\n",
    "# print(torch.load(model_path))\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce370e",
   "metadata": {},
   "source": [
    "#### Save the latents to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the latents to .csv file\n",
    "# z, pred, _, _ = model(torch.cat((torch.from_numpy(X1_final), torch.from_numpy(X2_final)), dim=1))\n",
    "z, _, _, _, _ = model(torch.concat((torch.from_numpy(X1_final), torch.from_numpy(X2_final), torch.from_numpy(X3_final), torch.from_numpy(X4_final)), dim=1))\n",
    "latent_filename = f'latents_from_{dataset_name}'\n",
    "\n",
    "# Data folder paths and file names\n",
    "dataset_folder_name = 'synthetic_dataset'\n",
    "dataset_file_name = 'synthetic_data_gridSamples_200_sumf5.csv'\n",
    "new_dataset_file_name = 'synthetic_data_gridSamples_200_sumf5_with_ae1_latents_concat.csv'\n",
    "run_folder_name = 'perovskite_multiscale_dataset_v2'\n",
    "model_folder_name = 'best_SupSimpleAE_1_ldim4_arun2024'\n",
    "AE_number = '1'\n",
    "\n",
    "dataset_folder = '../datasets/' + dataset_folder_name\n",
    "dataset_file = dataset_folder + '/' + dataset_file_name\n",
    "concatenated_dataset_file = dataset_folder + '/' + new_dataset_file_name\n",
    "\n",
    "run_folder = '../runs/' + run_dir\n",
    "latent_file = run_folder + '/' + model_name + '/' + latent_filename + '.csv'\n",
    "\n",
    "# Save the latents to .csv file\n",
    "z_df = pd.DataFrame(z.detach().numpy())\n",
    "# pred_df = pd.DataFrame(pred.detach().numpy())\n",
    "# Conccaetnate the latents and the predictions\n",
    "# z_pred_df = pd.concat([z_df, pred_df], axis=1)\n",
    "# z_pred_df = pd.DataFrame(z.detach().numpy())\n",
    "z_df.to_csv(latent_file, index=False, header=False) \n",
    "\n",
    "# latents = pd.read_csv(latent_file, header=None, skiprows=None)\n",
    "# data = pd.read_csv(dataset_file)\n",
    "\n",
    "# for i in range(len(latents.columns)):\n",
    "#     data['AE'+ AE_number +'_latent_'+str(i)] = latents[i]\n",
    "\n",
    "# data.to_csv(concatenated_dataset_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba29d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find which 'z'is closest to the 'z' provided below\n",
    "# z_query = torch.tensor([0.26077228, 3.95919058, 0., 0., 0., 0., 1.19784881, 1.33860231], dtype=torch.float32)\n",
    "# z_query = z_query.unsqueeze(dim=0)\n",
    "# z_query = z_query.repeat(z.shape[0], 1)\n",
    "# dist = torch.nn.PairwiseDistance(p=1)\n",
    "# distances = dist(z, z_query)\n",
    "# closest_idx = torch.argmin(distances).item()\n",
    "# print(torch.min(distances))\n",
    "# print(f'Closest z to the query z is at index : {closest_idx}')\n",
    "# print(f'Closest z to the query z is : {z[closest_idx]}')\n",
    "# print(f'Reconst for query z is : {reconst[closest_idx]}')\n",
    "# print(f'INvert scaling for reconst : {scaler_X.inverse_transform(reconst[closest_idx].detach().numpy().reshape(1, -1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor(X_scaled_np32[1, :], requires_grad=True)\n",
    "print(input)\n",
    "baseline = torch.zeros_like(input)\n",
    "print(baseline)\n",
    "print(model(baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee664e",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9a2f2",
   "metadata": {},
   "source": [
    "##### 1. Using Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1fe308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients, DeepLift, InputXGradient, Saliency\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def model_wrapper(input):\n",
    "    z, pred, reconst = model(input)\n",
    "    # z, pred, reconst1, reconst2 = model(input)\n",
    "    # z, recon1, recon2, recon3, recon4 = model(input)\n",
    "    return pred\n",
    "\n",
    "# Create an instance of the IntegratedGradients class\n",
    "sal = Saliency(model_wrapper)\n",
    "ig = IntegratedGradients(model_wrapper)\n",
    "ixg = InputXGradient(model_wrapper)\n",
    "dl = DeepLift(model_wrapper)\n",
    "\n",
    "input = torch.from_numpy(X1_final)\n",
    "# input = torch.cat((torch.from_numpy(X1_scaled_np32), torch.from_numpy(X2_np32)), dim=1)\n",
    "# input = torch.concat((torch.from_numpy(X1_final), torch.from_numpy(X2_final), torch.from_numpy(X3_final), torch.from_numpy(X4_final)), dim=1)\n",
    "\n",
    "# attr_sal = sal.attribute(input, target=None)\n",
    "# attr_sal_np = attr_sal.detach().numpy()\n",
    "# attr_ixg = ig.attribute(input, baselines=0, target=None)\n",
    "# attr_ixg_np = attr_ixg.detach().numpy()\n",
    "attr_ig = ig.attribute(input, baselines=0, target=None)\n",
    "attr_ig_np = attr_ig.detach().numpy()\n",
    "# attr_dl = dl.attribute(input, baselines=0, target=None)\n",
    "# attr_dl_np = attr_dl.detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "# # Plot the attributions\n",
    "using_boxplot = True\n",
    "if using_boxplot:\n",
    "    # Label the means on top of the bar in the boxplot\n",
    "    for i in range(attr_ig_np.shape[1]):\n",
    "        # plt.text(i+1, 1.5, '{:0.1f}'.format(np.mean(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "        # Plot the standard deviation\n",
    "        plt.text(i+1, 1.6, '{:0.1f}'.format(np.std(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "    # Plot the means and standard deviations of the attributions for each feature\n",
    "    plt.boxplot(attr_ig_np, showmeans=True, meanline=True)\n",
    "    ax.set_xticklabels(descriptors1, rotation=90)\n",
    "    plt.title('Integrated Gradients calc. wrt pred')\n",
    "    plt.show()\n",
    "else:\n",
    "    means = np.mean(attr_ig_np, axis=0)\n",
    "    std_dev = np.std(attr_ig_np, axis=0)\n",
    "    num_feats = attr_ig_np.shape[1]\n",
    "    # ax.bar(np.arange(num_feats), means, yerr=std_dev, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.scatter(np.arange(num_feats), means, label='mean', color='r', marker='.')\n",
    "    ax.errorbar(np.arange(num_feats), means, yerr=std_dev, fmt='o', capsize=5)\n",
    "    for i in range(attr_ig_np.shape[1]):\n",
    "        # plt.text(i+1, 1.5, '{:0.1f}'.format(np.mean(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "        # Plot the standard deviation\n",
    "        plt.text(i, 0.8, '{:0.1f}'.format(np.std(attr_ig_np[:, i])), ha='center', va='bottom')\n",
    "    ax.set_xticks(np.arange(num_feats))\n",
    "    # descriptors = ['DMF', 'DMF; DMSO', 'DMSO', 'DMSO; GBL', \n",
    "    #                '1', '1; 1', '1; 4', '2; 1', '3; 1', '3; 7', '4; 1', '7; 3',\n",
    "    #                '8; 1', '9; 1', 'Anisole', 'Chlorobenzene', 'Diethyl ether', \n",
    "    #                'Ethyl acetate', 'N2', 'Toluene', \n",
    "    #                'AE1_latent_0', 'AE1_latent_1', 'AE1_latent_2', 'AE1_latent_3']\n",
    "    descriptors = ['PET | ITO', 'SLG | FTO', 'SLG | ITO', \n",
    "                   'NiO-c', 'PEDOT:PSS', 'PTAA', 'Spiro-MeOTAD',\n",
    "                   'C60 | BCP', 'PCBM-60', 'PCBM-60 | BCP', 'PCBM-60 | ZnO-np',\n",
    "                   'SnO2-c', 'SnO2-np', 'TiO2-c', 'TiO2-c | TiO2-mp',\n",
    "                   'AE2_latent_0', 'AE2_latent_1', 'AE2_latent_2', 'AE2_latent_3',\n",
    "                   'AE2_latent_4', 'AE2_latent_5', 'AE2_latent_6', 'AE2_latent_7']\n",
    "    ax.set_xticklabels(descriptors, rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "# # Matrix Plot model weights\n",
    "# for name, param in model.encoder.named_parameters():\n",
    "#     if name == 'layers.0.weight':\n",
    "#         ax = plt.figure(figsize=(9, 8))\n",
    "#         ax = sns.heatmap(param.detach().numpy(), annot=True, fmt='.3f', cmap='coolwarm')\n",
    "#         # Remove y axis labels\n",
    "#         ax.yticks([])\n",
    "#         ax.set_title('Encoder Layer 1 Weights')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f252e",
   "metadata": {},
   "source": [
    "##### 2. Pearson Correlation Coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7be71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_wrapper(input):\n",
    "    z, pred, reconst = model(input)\n",
    "    # z, pred, reconst1, reconst2 = model(input)\n",
    "    # z, recon1, recon2, recon3, recon4 = model(input)\n",
    "    return pred\n",
    "\n",
    "\n",
    "pred = model_wrapper(torch.from_numpy(X1_final))\n",
    "corrcoefs = np.corrcoef(X1_final, y=pred.detach().numpy(), rowvar=False)\n",
    "\n",
    "# In the corr coefs change all values that lie between +- threhold to 0\n",
    "threshold = 0.1\n",
    "corrcoefs[np.abs(corrcoefs) < threshold] = 0\n",
    "\n",
    "# Make a color bar with 0 value as dark gray\n",
    "# cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "# cmap.set_bad(color='black')\n",
    "import matplotlib.colors as colors\n",
    "cmap = colors.LinearSegmentedColormap.from_list('mycmap', ['blue', 'gray', 'red'])\n",
    "norm = colors.Normalize(vmin=-1, vmax=1)\n",
    "\n",
    "# Matrix plot of corr coefs \n",
    "# plt.figure(figsize=(12,10))\n",
    "# Set figure size in inches\n",
    "plt.figure(figsize=(5, 3.85))\n",
    "\n",
    "sns.heatmap(corrcoefs, annot=False, cmap=cmap, norm=norm, fmt='.2f', annot_kws={\"color\": 'black', 'size':1})\n",
    "plt.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "\n",
    "plt.gca().xaxis.tick_top()\n",
    "\n",
    "plt.xticks(np.arange(X1_final.shape[1] + 1) + 0.5, labels=descriptors1 + ['f5_pred'], rotation=90)\n",
    "plt.yticks(np.arange(X1_final.shape[1] + 1) + 0.5, labels=descriptors1 + ['f5_pred'], rotation=0)\n",
    "\n",
    "#Adjust subplot size\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to pdf\n",
    "plt.savefig('corr_coefs.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd2c57",
   "metadata": {},
   "source": [
    "##### 3. Using kernel SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.vanilla_ae import VanillaAE\n",
    "from utils.custom_utils import read_from_pickle\n",
    "from inputs_perov_data.nn_inputs import list_of_nn_params_dict\n",
    "from inputs_perov_data.train_inputs import list_of_nn_train_params_dict\n",
    "from inputs_perov_data.dataset_inputs import list_of_nn_datasets_dict\n",
    "\n",
    "ae = 1\n",
    "\n",
    "ae_index = int(ae) - 1\n",
    "\n",
    "run_dir = '../runs/perovskite_multiscale_dataset_3'\n",
    "\n",
    "# # Read the ae params, train params and datasets\n",
    "# list_of_nn_params_dict = read_from_pickle('list_of_nn_params_dict.pkl', run_dir)\n",
    "# list_of_nn_train_params_dict = read_from_pickle('list_of_nn_train_params_dict.pkl', run_dir)\n",
    "# list_of_nn_datasets_dict = read_from_pickle('list_of_nn_datasets_dict.pkl', run_dir)\n",
    "\n",
    "nn_params_dict = list_of_nn_params_dict[ae_index]\n",
    "nn_train_params_dict = list_of_nn_train_params_dict[ae_index]\n",
    "nn_datasets_dict = list_of_nn_datasets_dict[ae_index]\n",
    "\n",
    "global_seed = nn_train_params_dict['global_seed']\n",
    "\n",
    "nn_save_dir = run_dir + '/' + nn_params_dict['model_type']\n",
    "print(nn_save_dir)\n",
    "\n",
    "ae = VanillaAE(nn_save_dir,\n",
    "                nn_params_dict,\n",
    "                nn_train_params_dict,\n",
    "                nn_datasets_dict)\n",
    "\n",
    "# Load model from checkpoint \n",
    "checkpoint_path = nn_save_dir + '/checkpoints/last.ckpt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "ae.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "# # Load the training dataset\n",
    "# train_dataset_path = nn_save_dir + '/datasets/train_dataset.pt'\n",
    "# train_dataset = torch.load(train_dataset_path)\n",
    "# train_dataset_np = train_dataset[:]['all_props'].detach().numpy()\n",
    "\n",
    "# predict_dataset_path = nn_save_dir + '/datasets/predict_dataset.pt'\n",
    "# predict_dataset = torch.load(predict_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the inputs into one dataset, if only one input then skip\n",
    "combined = False\n",
    "background_dataset_gen = 'all_samples' # 'kmeans' or 'all_samples'\n",
    "descriptors1 = ['A_ion_rad', 'A_at_wt', 'A_EA', 'A_IE', 'A_En',\n",
    "                'B_ion_rad', 'B_at_wt', 'B_EA', 'B_IE', 'B_En',\n",
    "                'X_ion_rad', 'X_at_wt', 'X_EA', 'X_IE', 'X_En']\n",
    "# descriptors2=['AE1_l0', 'AE1_l1', 'AE1_l2', 'AE1_l3', 'AE1_l4', 'AE1_l5', \n",
    "#                  'AE1_l6', 'AE1_l7', 'AE1_l8', 'AE1_l9', 'AE1_l10', 'AE1_l11']+\\\n",
    "#                 list(ae.datasets.variable_preprocessors['etm'].categories_[0]) +\\\n",
    "#                 list(ae.datasets.variable_preprocessors['htm'].categories_[0])\n",
    "\n",
    "if combined:    \n",
    "    dataset = torch.concat((ae.all_samples['latents'], ae.all_samples['etm'], ae.all_samples['htm']), dim=1)\n",
    "else:\n",
    "    dataset = ae.all_samples['all_props']\n",
    "\n",
    "# Using kmeans to cluster the data\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if background_dataset_gen == 'kmeans':\n",
    "    krange = np.arange(1, 200)\n",
    "    inertia = np.zeros(len(krange))\n",
    "\n",
    "    for k in krange:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto').fit(dataset)\n",
    "        if k == krange[-1]:\n",
    "            background_dataset = kmeans.cluster_centers_\n",
    "            # Change dtypes to np.float32\n",
    "            background_dataset = background_dataset.astype(np.float32)\n",
    "        inertia[k-1] = kmeans.inertia_\n",
    "    \n",
    "    # Plot elbow plot\n",
    "    plt.plot(krange, inertia, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "elif background_dataset_gen == 'all_samples':\n",
    "    # X100 = shap.utils.sample(combined_dataset.detach().numpy(), 100)\n",
    "    background_dataset = shap.utils.sample(ae.all_samples['all_props'].detach().numpy(), len(ae.all_samples['all_props']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebfce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(modelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "    def forward(self, input):\n",
    "        # REWRITE BASED ON INPUTS FED TO MODEL !!\n",
    "        # input = {'latents':torch.from_numpy(input[:,:12]),\n",
    "        #          'etm':torch.from_numpy(input[:,12:19]),\n",
    "        #          'htm':torch.from_numpy(input[:,19:])} \n",
    "        input = {'all_props':torch.from_numpy(input)}\n",
    "        submodule_outputs = self.model(input)\n",
    "        #submodule_outputs_from_loaded = ae(ae.all_samples)\n",
    "        pred = submodule_outputs['bg_pred'].detach().numpy()\n",
    "        # print(f'This is the pred : {pred}')\n",
    "        return pred\n",
    "\n",
    "model_wrapper = modelWrapper(ae)\n",
    "kernel_explainer = shap.KernelExplainer(model_wrapper, data=background_dataset, link='identity', feature_names=descriptors1)\n",
    "shap_values = kernel_explainer.shap_values(dataset.detach().numpy())\n",
    "shap_values = np.squeeze(shap_values, axis=-1)\n",
    "shap.initjs()\n",
    "                \n",
    "shap.summary_plot(shap_values, features=dataset.detach().numpy(), feature_names=descriptors1, max_display=10, plot_type='dot', show=False, plot_size=(5.8, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SHAP force plot\n",
    "# shap.force_plot(kernel_explainer.expected_value, shap_values[34], features=ae.all_samples['all_props'].detach().numpy()[34], feature_names=descriptors1)\n",
    "shap.plots.force(kernel_explainer.expected_value, shap_values[34], features=ae.all_samples['all_props'].detach().numpy()[34], feature_names=descriptors1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Sample 100 points to use as the background dataset\n",
    "X100 = shap.utils.sample(X1_final, 100)\n",
    "\n",
    "class modelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(modelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "    def forward(self, input):\n",
    "        # For kenrnal explainer\n",
    "        input = torch.from_numpy(input)\n",
    "        z, pred, reconst = self.model(input)\n",
    "        pred = pred.detach().numpy()\n",
    "        return pred\n",
    "    \n",
    "model_wrapper = modelWrapper(model)\n",
    "\n",
    "# explainer = shap.Explainer(model_wrapper, X100)\n",
    "kernel_explainer = shap.KernelExplainer(model=model_wrapper, data=X100)\n",
    "# gradient_explainer = shap.GradientExplainer(model_wrapper, torch.from_numpy(X100))\n",
    "# deep_explainer = shap.DeepExplainer(model_wrapper, torch.from_numpy(X100))\n",
    "\n",
    "# Shaplye values for all the points in the dataset\n",
    "shap_values = kernel_explainer.shap_values(X1_final)\n",
    "# shap_values = explainer(X100)\n",
    "# shap_values = gradient_explainer.shap_values(torch.from_numpy(X100))\n",
    "# shap_values = deep_explainer.shap_values(torch.from_numpy(X100))\n",
    "shap_values = np.squeeze(shap_values, axis=-1)\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "# Save the SHAP summary plot to pdf\n",
    "\n",
    "# For displaying for multiple samples. show=False is required to save the plot as a matplotlib figure\n",
    "shap.summary_plot(shap_values, features=X1_final, feature_names=descriptors1, max_display=10, plot_type='dot', show=False, plot_size=(5.8, 3.5))\n",
    "\n",
    "plt.savefig('SHAP_summary_plot.pdf')\n",
    "\n",
    "# Explaining a single prediction\n",
    "# shap.waterfall_plot(shap.Explanation(values=shap_values[1], base_values=0, data=X1_final[1], feature_names=descriptors1))\n",
    "\n",
    "# Requires an explanation object to be passed\n",
    "# shap.plots.bar(shap.Explanation(values=shap_values[:], base_values=0, data=X1_final[:], feature_names=descriptors1))\n",
    "# shap.force_plot(kernel_explainer.expected_value, shap_values, descriptors1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95903c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing own version of integrated gradients\n",
    "input = torch.tensor(X_scaled_np32[1, :], requires_grad=True)\n",
    "print(input)\n",
    "baseline = torch.zeros_like(input)\n",
    "print(baseline)\n",
    "def interpolated_features(num_steps):\n",
    "    alphas = torch.linspace(0, 1, num_steps+1)\n",
    "    delta = input - baseline\n",
    "    return torch.stack([baseline + alpha*delta for alpha in alphas])\n",
    "\n",
    "def compute_gradients(interpolated_feats):\n",
    "    grads = []\n",
    "    for i in range(interpolated_feats.shape[0]):\n",
    "        input = interpolated_feats[i]\n",
    "        input = input.unsqueeze(dim=0)\n",
    "        z, pred, reconst = model(input)\n",
    "        print(pred.squeeze(dim=0))\n",
    "        pred.backward()\n",
    "        grads.append(input.grad)\n",
    "        pred = model(interpolated_feats[i].unsqueeze(dim=0))\n",
    "        pred.backward()\n",
    "        grads.append(input.grad)\n",
    "    return torch.stack(grads)\n",
    "\n",
    "computed_grads = compute_gradients(interpolated_features(10))\n",
    "plt.plot(torch.linspace(0, 1, 11), computed_grads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d183b19",
   "metadata": {},
   "source": [
    "#### 2D plots of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d823e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z, pred, reconst, mu, logvar = model(torch.from_numpy(elemental_properties))\n",
    "# z, pred, reconst, mu, logvar, mu_prior, logvar_prior, qy_logit, qy = model(torch.from_numpy(elemental_properties))\n",
    "\n",
    "# # Only for 2D latent plotting\n",
    "# plt.scatter(z[:, 0].detach().numpy(), z[:, 1].detach().numpy(), c=pred.detach().numpy(), cmap='viridis', s=10, alpha=0.5)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aadfbb5",
   "metadata": {},
   "source": [
    "### Observations for Unit normal prior\n",
    "- What we observe from the above example is that although multivariate Gaussian distribution are useful\n",
    "    as each dimension can encode a separate DOF which results in representations that are sturctured and disentangled, \n",
    "    they are unimodal and hence cannot encode complex representations. A natural extension is to then use a different\n",
    "    prior. Gaussain Mixture Model (GMM) is the next choice.\n",
    "- Latent space is segregated into different classes.\n",
    "- However, inference is non-trivial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
