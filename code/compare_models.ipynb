{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab8b0439-d920-4b04-b6b7-28dd0fff946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Custom scripts\n",
    "from utils.dataset_utils import create_preprocessed_datasets\n",
    "from inputs_perov_data_v2.dataset_inputs import list_of_nn_datasets_dict\n",
    "from utils.custom_utils import set_global_random_seed\n",
    "\n",
    "global_seed = 0\n",
    "set_global_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8131085",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "004bec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping creating dataset directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PCE'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_save_dir = '../runs/perovskite_multiscale_dataset_v2'\n",
    "if os.path.exists(nn_save_dir + '/datasets'):\n",
    "    print('Skipping creating dataset directory.')\n",
    "else:\n",
    "    nn_datasets_dict = list_of_nn_datasets_dict[0]\n",
    "    test_split = None\n",
    "    mode = 'train'\n",
    "    kfolds = 5\n",
    "    create_preprocessed_datasets(nn_save_dir, \n",
    "                                    nn_datasets_dict,\n",
    "                                    global_seed,\n",
    "                                    test_split=test_split,\n",
    "                                    mode=mode,\n",
    "                                    kfolds=kfolds)\n",
    "\n",
    "descriptors = list(list_of_nn_datasets_dict[0]['train']['PSC_eff_v2']['variables'].keys())\n",
    "target = descriptors[-1]\n",
    "descriptors.pop(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b99e92",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76abcb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.017}\n",
      "[ 1.61717631e+00  3.32099175e-02  0.00000000e+00 -5.31447559e-02\n",
      " -0.00000000e+00  0.00000000e+00  2.21938199e-01 -2.21568666e+00\n",
      " -0.00000000e+00  6.17198810e-02  2.13807178e+00  3.81043781e-05\n",
      " -0.00000000e+00 -4.43501243e-04 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.36399251e+00\n",
      "  0.00000000e+00  6.09655303e-01  1.94417583e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -1.85304640e-01  1.18441418e+00  2.18728477e+00\n",
      " -2.18009688e-01 -3.28641855e-01 -1.11336919e+00 -2.63491451e+00\n",
      "  3.90516275e-04  4.04922582e-01]\n",
      "Train R^2 : -12.45765265577068\n",
      "Test R^2 : -11.614273449360475\n",
      "{'alpha': 0.012}\n",
      "[ 1.01713116e+00  0.00000000e+00  0.00000000e+00 -6.46406174e-01\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.46046739e+00\n",
      "  0.00000000e+00  7.03672087e-02  2.03185365e+00  1.33107017e-04\n",
      " -0.00000000e+00 -8.71222690e-04 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.16070061e+00\n",
      "  0.00000000e+00  7.75670770e-01  2.14105416e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -2.10630121e-01  9.05138765e-01  2.17426091e+00\n",
      " -0.00000000e+00 -5.99267850e-01 -1.53512546e+00 -2.71595138e+00\n",
      "  0.00000000e+00  6.41405669e-01]\n",
      "Train R^2 : -11.639255686679098\n",
      "Test R^2 : -15.732598908339773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.247e+02, tolerance: 7.549e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.014000000000000002}\n",
      "[ 1.31934815e+00  1.55580010e-01  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -2.40348424e+00\n",
      "  2.51375603e-03  7.00197438e-02  2.11721600e+00  0.00000000e+00\n",
      " -0.00000000e+00 -4.90059708e-04 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.92479918e+00\n",
      " -0.00000000e+00  5.38541816e-01  2.22415642e+00 -4.80398126e-01\n",
      "  0.00000000e+00 -0.00000000e+00  1.42044565e+00  2.25651265e+00\n",
      " -4.83281944e-01 -1.77597243e-01 -2.08151101e+00 -2.89393091e+00\n",
      "  8.10250639e-02  2.27788432e-01]\n",
      "Train R^2 : -11.742055479473951\n",
      "Test R^2 : -13.889126751710364\n",
      "{'alpha': 0.014000000000000002}\n",
      "[ 1.24544457e+00  1.54505619e-01  0.00000000e+00 -5.58792260e-02\n",
      " -0.00000000e+00  0.00000000e+00  1.99635416e-01 -2.07565589e+00\n",
      " -0.00000000e+00  5.95049626e-02  2.09845300e+00  4.30555638e-05\n",
      " -0.00000000e+00 -6.44501544e-04 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.78891746e+00\n",
      "  0.00000000e+00  1.11749227e+00  1.23650796e+00 -8.10084935e-01\n",
      "  1.65222627e-01 -1.00062905e+00  1.95317152e+00  2.58029873e+00\n",
      " -6.19096617e-03 -1.56432086e-01 -1.51461615e+00 -2.69693856e+00\n",
      "  4.70507504e-01  1.80103555e-01]\n",
      "Train R^2 : -12.383738667547517\n",
      "Test R^2 : -11.265339435928587\n",
      "{'alpha': 0.017}\n",
      "[ 1.36785927e+00  0.00000000e+00  0.00000000e+00 -2.51184660e-01\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -2.00358554e+00\n",
      "  1.10900697e-01  3.98625363e-01  2.08105692e+00  0.00000000e+00\n",
      " -0.00000000e+00 -4.45426859e-04 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.42250686e+00\n",
      "  0.00000000e+00  3.11879361e-01  1.74972550e+00 -6.75177710e-01\n",
      " -0.00000000e+00 -0.00000000e+00  1.54551400e+00  2.97626637e+00\n",
      " -0.00000000e+00  0.00000000e+00 -5.24093091e-01 -1.75007164e+00\n",
      "  5.06464340e-01  4.31712554e-02]\n",
      "Train R^2 : -11.826525124017056\n",
      "Test R^2 : -14.156407346423247\n"
     ]
    }
   ],
   "source": [
    "lasso_results = []\n",
    "lasso_train_cod = []\n",
    "lasso_test_cod = []\n",
    "# Concatenate all the dictionary values with the key specified as the descriptor\n",
    "for i in range(kfolds):\n",
    "    train_dataset = torch.load(f'{nn_save_dir}/datasets/train_dataset_fold_{i}.pt')\n",
    "    val_dataset = torch.load(f'{nn_save_dir}/datasets/val_dataset_fold_{i}.pt')\n",
    "\n",
    "    X_train = torch.cat([train_dataset[:][descriptor] for descriptor in descriptors], dim=1).detach().numpy()\n",
    "    y_train = train_dataset[:][target].detach().numpy().ravel()\n",
    "    X_test = torch.cat([val_dataset[:][descriptor] for descriptor in descriptors], dim=1).detach().numpy()\n",
    "    y_test = val_dataset[:][target].detach().numpy().ravel()\n",
    "\n",
    "    lasso = Lasso(random_state=global_seed)\n",
    "    search = GridSearchCV(lasso,{'alpha':np.arange(0.001,0.1,0.001)}, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    lasso_parameters = search.best_params_\n",
    "    coefficients = search.best_estimator_.coef_\n",
    "\n",
    "    lasso_results.append(search)\n",
    "    print(lasso_parameters)\n",
    "    print(coefficients)\n",
    "    lasso_train_cod.append(search.score(X_train, y_train))\n",
    "    lasso_test_cod.append(search.score(X_test, y_test))\n",
    "    print(f'Fold {i}')\n",
    "    print(f'Train R^2 : {lasso_train_cod[-1]}')\n",
    "    print(f'Test R^2 : {lasso_test_cod[-1]}')\n",
    "    \n",
    "# Save search to pickle\n",
    "pickle.dump(lasso_results, open(f'{nn_save_dir}/lasso_results.pkl', 'wb'))\n",
    "pickle.dump(lasso_train_cod, open(f'{nn_save_dir}/lasso_train_cod.pkl', 'wb'))\n",
    "pickle.dump(lasso_test_cod, open(f'{nn_save_dir}/lasso_test_cod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e52214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Train R^2 : 0.8113484588667679\n",
      "Test R^2 : 0.5636766075954437\n",
      "Train Loss : 1.4152355185354097\n",
      "Test Loss : 2.2245287252821777\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute `loss_` was deprecated in version 1.1 and will be removed in 1.3.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train R^2 : 0.7958265124058295\n",
      "Test R^2 : 0.6102684810675147\n",
      "Train Loss : 1.4859802795263821\n",
      "Test Loss : 2.6921415598171397\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute `loss_` was deprecated in version 1.1 and will be removed in 1.3.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "Train R^2 : 0.799960167145499\n",
      "Test R^2 : 0.5399171933392033\n",
      "Train Loss : 1.3713412793015893\n",
      "Test Loss : 2.4637450316965452\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute `loss_` was deprecated in version 1.1 and will be removed in 1.3.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n",
      "Train R^2 : 0.7968480786950437\n",
      "Test R^2 : 0.6274673249957221\n",
      "Train Loss : 1.5659464599253106\n",
      "Test Loss : 2.2675800268635204\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute `loss_` was deprecated in version 1.1 and will be removed in 1.3.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n",
      "Train R^2 : 0.7958182205413917\n",
      "Test R^2 : 0.5436314756311713\n",
      "Train Loss : 1.420663238707411\n",
      "Test Loss : 2.8351282842667263\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilthota/miniconda3/envs/nestedae/lib/python3.9/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute `loss_` was deprecated in version 1.1 and will be removed in 1.3.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gbregressor_results = []\n",
    "gbregressor_train_cod = []\n",
    "gbregressor_test_cod = []\n",
    "for i in range(kfolds):\n",
    "    train_dataset = torch.load(f'{nn_save_dir}/datasets/train_dataset_fold_{i}.pt')\n",
    "    val_dataset = torch.load(f'{nn_save_dir}/datasets/val_dataset_fold_{i}.pt')\n",
    "\n",
    "    X_train = torch.cat([train_dataset[:][descriptor] for descriptor in descriptors], dim=1).detach().numpy()\n",
    "    y_train = train_dataset[:][target].detach().numpy().ravel()\n",
    "    X_test = torch.cat([val_dataset[:][descriptor] for descriptor in descriptors], dim=1).detach().numpy()\n",
    "    y_test = val_dataset[:][target].detach().numpy().ravel()\n",
    "\n",
    "    gbregressor = GradientBoostingRegressor(random_state=global_seed, n_estimators=200, learning_rate=0.01, max_depth=20, subsample=0.5, loss='absolute_error')\n",
    "    gbregressor.fit(X_train, y_train)\n",
    "\n",
    "    gbregressor_results.append(gbregressor)\n",
    "    gbregressor_train_cod.append(gbregressor.score(X_train, y_train))\n",
    "    gbregressor_test_cod.append(gbregressor.score(X_test, y_test))\n",
    "    print(f'Fold {i}')\n",
    "    print(f'Train R^2 : {gbregressor_train_cod[-1]}')\n",
    "    print(f'Test R^2 : {gbregressor_test_cod[-1]}')\n",
    "    print(f'Train Loss : {gbregressor.train_score_[-1]}')\n",
    "    print(f'Test Loss : {gbregressor.loss_(y_test, gbregressor.predict(X_test))}')\n",
    "    print('\\n')\n",
    "\n",
    "# Save search to pickle\n",
    "pickle.dump(gbregressor_results, open(f'{nn_save_dir}/gbregressor_results.pkl', 'wb'))\n",
    "pickle.dump(gbregressor_train_cod, open(f'{nn_save_dir}/gbregressor_train_cod.pkl', 'wb'))\n",
    "pickle.dump(gbregressor_test_cod, open(f'{nn_save_dir}/gbregressor_test_cod.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc0a2e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Train R^2 : 0.5754964097034966\n",
      "Test R^2 : 0.4732361949694095\n",
      "Train Loss : 2.4476897533866713\n",
      "Test Loss : 2.3208716261330355\n",
      "\n",
      "\n",
      "Fold 1\n",
      "Train R^2 : 0.5765299746761042\n",
      "Test R^2 : 0.5877961706661152\n",
      "Train Loss : 2.3324877670448836\n",
      "Test Loss : 2.7645098891761033\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Train R^2 : 0.5879285966830929\n",
      "Test R^2 : 0.5005570609479452\n",
      "Train Loss : 2.354083686978085\n",
      "Test Loss : 2.5604169334972706\n",
      "\n",
      "\n",
      "Fold 3\n",
      "Train R^2 : 0.5907766553442368\n",
      "Test R^2 : 0.5499663185503176\n",
      "Train Loss : 2.3734653750412993\n",
      "Test Loss : 2.4413497878293984\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Train R^2 : 0.5724630396864618\n",
      "Test R^2 : 0.4830237154156276\n",
      "Train Loss : 2.340109636681176\n",
      "Test Loss : 2.9641579471351416\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svr_results = []\n",
    "svr_train_cod = []\n",
    "svr_test_cod = []\n",
    "\n",
    "for i in range(kfolds):\n",
    "    train_dataset = torch.load(f'{nn_save_dir}/datasets/train_dataset_fold_{i}.pt')\n",
    "    val_dataset = torch.load(f'{nn_save_dir}/datasets/val_dataset_fold_{i}.pt')\n",
    "\n",
    "    X_train = torch.cat([train_dataset[:][descriptor] for descriptor in descriptors], dim=1).detach().numpy()\n",
    "    y_train = train_dataset[:][target].detach().numpy().ravel()\n",
    "    X_test = torch.cat([val_dataset[:][descriptor] for descriptor in descriptors], dim=1).detach().numpy()\n",
    "    y_test = val_dataset[:][target].detach().numpy().ravel()\n",
    "\n",
    "    svr = SVR(kernel='rbf', gamma='scale', C=1.0, epsilon=0.1)\n",
    "    svr.fit(X_train, y_train)\n",
    "\n",
    "    svr_results.append(svr)\n",
    "    svr_train_cod.append(svr.score(X_train, y_train))\n",
    "    svr_test_cod.append(svr.score(X_test, y_test))\n",
    "    print(f'Fold {i}')\n",
    "    print(f'Train R^2 : {svr_train_cod[-1]}')\n",
    "    print(f'Test R^2 : {svr_test_cod[-1]}')\n",
    "    print(f'Train Loss : {mean_absolute_error(y_train, svr.predict(X_train))}')\n",
    "    print(f'Test Loss : {mean_absolute_error(y_test, svr.predict(X_test))}')\n",
    "    print('\\n')\n",
    "\n",
    "# Save search to pickle\n",
    "pickle.dump(svr_results, open(f'{nn_save_dir}/svr_results.pkl', 'wb'))\n",
    "pickle.dump(svr_train_cod, open(f'{nn_save_dir}/svr_train_cod.pkl', 'wb'))\n",
    "pickle.dump(svr_test_cod, open(f'{nn_save_dir}/svr_test_cod.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
